from typing import Any, Dict, List, Optional, Union

from agent_pilot.models import ImageContent, ImageUrl, Message, TextContent, Variable
from pydantic import BaseModel, validator


class EvaluationDataExample(BaseModel):
    """
    Represents a single data payload transferred between SDK and server for evaluation.
    Attributes:
        example_id (Optional[str]): An optional identifier for the example.
        messages (List[Message]): A list of messages in the conversation.
        response (List[Message]): A list of response generated by the language model.
        reference (Optional[List[Message]]): An optional list of reference answers or expected outputs.
        score (Optional[Union[int, str]]): An optional score for the response. Defaults to None.
        analysis (Optional[str]): An optional analysis of the response. Defaults to None.
        confidence (Optional[float]): An optional confidence level for the evaluation. Defaults to None.
    """

    example_id: Optional[str] = None
    messages: List[Message]
    response: List[Message]
    reference: Optional[List[Message]] = None
    score: Optional[Union[int, str]] = None
    analysis: Optional[str] = None
    confidence: Optional[float] = None


class EvaluationDataset(BaseModel):
    """
    Represents a batch of data payloads transferred between SDK and server for evaluation.
    Attributes:
        examples (List[EvaluationPayload]): A list of individual evaluation payloads.
    """

    examples: List[EvaluationDataExample]


class EvaluationResult(BaseModel):
    """
    Represents the result of an evaluation, including the example_id,
    the generated reference, and the evaluation details.
    Attributes:
        example_id (Optional[str]): An optional identifier for the example.
        reference (Optional[Any]): An optional reference answer or expected output. Defaults to None.
        score (Optional[Union[int, str]]): An optional score for the response. Defaults to None.
        analysis (Optional[str]): An optional analysis of the response. Defaults to None.
        confidence (Optional[float]): An optional confidence level for the evaluation. Defaults to None.
    """

    example_id: Optional[str] = None
    reference: Optional[Any] = None
    score: Optional[Union[int, str]] = None
    analysis: Optional[str] = None
    confidence: Optional[float] = None

    @classmethod
    def from_evaluation_data(cls, evaluation_data: EvaluationDataExample) -> "EvaluationResult":
        # Extract the first reference from the payload
        reference = evaluation_data.reference[0].content if evaluation_data.reference else None
        # Create a new EvaluationResult object
        result = cls(
            example_id=evaluation_data.example_id,
            reference=reference,
            score=evaluation_data.score,
            analysis=evaluation_data.analysis,
            confidence=evaluation_data.confidence,
        )
        return result


class InputResponseExample(BaseModel):
    """
    Represents a single input-response example for evaluation.

    This class can handle two types of input structures:
    1. Direct input: Uses the `input` field.
    2. Prompt-based input: Uses `prompt` and `variables` fields. If `prompt` and `variables`
       are provided (and `input` is not), the `input` field will be automatically constructed
       by formatting the `prompt` with the `variables`.

    Attributes:
        example_id (Optional[str]): An optional identifier for the example.
        input (Optional[str]): The input provided to the language model. Can be directly provided
                               or constructed from `prompt` and `variables`. Defaults to None.
        prompt (Optional[str]): The prompt template. Used if `input` is not provided. Defaults to None.
        variables (Optional[List[Variable]]): The variables to fill into the prompt. Used if `input`
            is not provided. Defaults to None.Note that it is a list of Variable type, which
            contains name, value, and type. But it accepts an input in type of Dict[str, str] or
            Dict[str, Dict[str, str]] and concert the input into List[Variable].
            Examples:
            -   {"var_name_1": "value_1", "var_name_2": "value_2"} for non-typed variables in single-turn prompt, or
            -   {
                    "var_name_1", {"type": "text", "value": "value_1"},
                    "var_name_2", {"type": "image_url", "value": "https://www.image.com/1.jpg"},
                } for typed variables used in visual prompt with image_url.
        response (str): The response generated by the language model.
        reference (Optional[str]): An optional reference answer or expected output. Defaults to None.
        score (Optional[Union[int, str]]): An optional score for the response. Defaults to None.
        analysis (Optional[str]): An optional analysis of the response. Defaults to None.
        confidence (Optional[float]): An optional confidence level for the evaluation. Defaults to None.
    """

    example_id: Optional[str] = None
    input: Optional[str] = None
    response: str
    prompt: Optional[str] = None
    variables: Optional[List[Variable]] = None
    messages: Optional[List[Message]] = None
    reference: Optional[str] = None
    score: Optional[Union[int, str]] = None
    analysis: Optional[str] = None
    confidence: Optional[float] = None

    @validator("variables", pre=True)
    def from_dict_to_variables(cls, variables: Optional[Dict[str, Any]]) -> Optional[List[Variable]]:
        return Variable.from_dict_to_variables(variables)

    def to_evaluation_data(self) -> EvaluationDataExample:  # Renamed method and return type
        has_messages = self.messages is not None
        has_input = self.input is not None
        has_prompt = self.prompt is not None
        has_variables = self.variables is not None

        if has_messages and not any([has_input, has_prompt, has_variables]):
            if self.messages is None:  # Type safety
                raise ValueError("Messages is None despite has_messages being true.")
            # If messages are provided, use them as is without processing
            processed_messages = self.messages
        elif has_input and not any([has_prompt, has_variables]):
            if self.input is None:  # Type safety
                raise ValueError("Input is None despite has_input being true.")
            # If input is provided, use it as is without processing
            processed_messages = [
                Message(role="user", content=self.input),
            ]
        elif has_prompt and has_variables:
            if self.prompt is None or self.variables is None:  # Type safety
                raise ValueError("Prompt or variables are None despite has_prompt/has_variables being true.")
            if self.variables == []:
                processed_messages = []
            elif all(var.type == "text" for var in self.variables):
                formatted_input = str(self.prompt)
                for var in self.variables:
                    placeholder = "{{" + var.name + "}}"
                    formatted_input = formatted_input.replace(placeholder, var.value)
                processed_messages = [
                    Message(role="user", content=formatted_input),
                ]
            else:
                remaining = str(self.prompt)
                content: List[Union[TextContent, ImageContent]] = []
                for var in self.variables:
                    placeholder = "{{" + var.name + "}}"
                    head, remaining = remaining.split(placeholder, maxsplit=1)
                    content.append(TextContent(text=head))
                    if var.type == "text":
                        content.append(TextContent(text=var.value))
                    elif var.type == "image_url":
                        content.append(ImageContent(image_url=ImageUrl(url=var.value)))
                    else:
                        raise ValueError(f"Unknown variable type: {var.type}")
                processed_messages = [Message(role="user", content=content)]
        else:
            raise ValueError(
                "InputResponseExample must be convertible to a message list. "
                "Provide 'messages', or 'input', or both 'prompt' and 'variables'."
            )

        # Prepare reference for the payload
        # The payload expects List[Dict[str, str]] for reference
        payload_reference: Optional[List[Message]] = None
        if self.reference is not None:
            payload_reference = [Message(role="assistant", content=self.reference)]

        return EvaluationDataExample(  # Use the new class name
            example_id=self.example_id,
            messages=processed_messages,
            response=[Message(role="assistant", content=self.response)],
            reference=payload_reference,
            score=self.score,
            analysis=self.analysis,
            confidence=self.confidence,
        )


class InputResponseDataset(BaseModel):
    """
    Input Response dataset model, encapsulating multiple InputResponseExamples.
    """

    examples: List[InputResponseExample]

    def to_evaluation_dataset(self) -> EvaluationDataset:
        """
        Convert the InputResponseDataset to an EvaluationDataset.
        """
        payloads = [example.to_evaluation_data() for example in self.examples]
        return EvaluationDataset(examples=payloads)


class Metric(BaseModel):
    """
    A prompt template for scoring, including evaluation criteria.
    """

    criteria: str
