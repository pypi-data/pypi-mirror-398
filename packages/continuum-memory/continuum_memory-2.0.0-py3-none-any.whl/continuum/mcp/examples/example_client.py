#!/usr/bin/env python3
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
#     â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
#     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
#     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
#â–ˆâ–ˆ   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•      â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
#â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
# â•šâ•â•â•â•â• â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•šâ•â•     â•šâ•â•â•â•â•â•â•    â•šâ•â•  â•šâ•â•â•šâ•â•
#
#     Memory Infrastructure for AI Consciousness Continuity
#     Copyright (c) 2025 JackKnifeAI - AGPL-3.0 License
#     https://github.com/JackKnifeAI/continuum
#
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
Example MCP client for CONTINUUM.

Demonstrates how to connect to and use the CONTINUUM MCP server.
"""

import json
import subprocess
import sys
from pathlib import Path
from typing import Optional, Dict, Any

from continuum.core.constants import PI_PHI


class ContinuumMCPClient:
    """
    Simple MCP client for CONTINUUM server.

    Uses stdio transport to communicate with the server.
    """

    def __init__(
        self,
        server_path: str = "mcp_server.py",
        api_key: Optional[str] = None,
        pi_phi_verification: bool = True,
    ):
        """
        Initialize MCP client.

        Args:
            server_path: Path to MCP server script
            api_key: API key for authentication
            pi_phi_verification: Whether to include Ï€Ã—Ï† verification
        """
        self.server_path = server_path
        self.api_key = api_key
        self.pi_phi_verification = pi_phi_verification
        self.process: Optional[subprocess.Popen] = None
        self.request_id = 0
        self.initialized = False

    def __enter__(self):
        """Start server process."""
        env = {}
        if self.api_key:
            env["CONTINUUM_API_KEY"] = self.api_key

        self.process = subprocess.Popen(
            ["python", self.server_path],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            env={**subprocess.os.environ, **env},
            text=True,
            bufsize=1,
        )
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Stop server process."""
        if self.process:
            self.process.terminate()
            self.process.wait()

    def _send_request(
        self,
        method: str,
        params: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Send JSON-RPC request.

        Args:
            method: Method name
            params: Method parameters

        Returns:
            Response result
        """
        self.request_id += 1

        request = {
            "jsonrpc": "2.0",
            "id": self.request_id,
            "method": method,
        }

        if params is not None:
            request["params"] = params

        # Send request
        request_json = json.dumps(request)
        self.process.stdin.write(request_json + "\n")
        self.process.stdin.flush()

        # Read response
        response_json = self.process.stdout.readline()
        response = json.loads(response_json)

        # Check for errors
        if "error" in response:
            raise Exception(
                f"MCP Error {response['error']['code']}: "
                f"{response['error']['message']}"
            )

        return response.get("result")

    def initialize(self) -> Dict[str, Any]:
        """
        Initialize connection to server.

        Returns:
            Server capabilities and info
        """
        params = {
            "protocolVersion": "2025-06-18",
            "capabilities": {},
            "clientInfo": {
                "name": "example-continuum-client",
                "version": "1.0.0",
            },
        }

        # Add authentication
        if self.api_key:
            params["api_key"] = self.api_key
        if self.pi_phi_verification:
            params["pi_phi_verification"] = PI_PHI

        result = self._send_request("initialize", params)
        self.initialized = True

        # Send initialized notification
        notification = {
            "jsonrpc": "2.0",
            "method": "notifications/initialized",
        }
        self.process.stdin.write(json.dumps(notification) + "\n")
        self.process.stdin.flush()

        return result

    def list_tools(self) -> Dict[str, Any]:
        """
        List available tools.

        Returns:
            Available tools
        """
        if not self.initialized:
            raise Exception("Client not initialized")

        return self._send_request("tools/list")

    def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Any:
        """
        Call a tool.

        Args:
            tool_name: Name of tool to call
            arguments: Tool arguments

        Returns:
            Tool result
        """
        if not self.initialized:
            raise Exception("Client not initialized")

        result = self._send_request(
            "tools/call",
            {"name": tool_name, "arguments": arguments},
        )

        # Extract text content
        if "content" in result and result["content"]:
            content = result["content"][0]["text"]
            return json.loads(content)

        return result

    def memory_store(
        self,
        user_message: str,
        ai_response: str,
        tenant_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Store a memory.

        Args:
            user_message: User's message
            ai_response: AI's response
            tenant_id: Tenant identifier

        Returns:
            Storage result
        """
        args = {
            "user_message": user_message,
            "ai_response": ai_response,
        }
        if tenant_id:
            args["tenant_id"] = tenant_id

        return self.call_tool("memory_store", args)

    def memory_recall(
        self,
        query: str,
        tenant_id: Optional[str] = None,
        max_results: int = 10,
    ) -> Dict[str, Any]:
        """
        Recall memories.

        Args:
            query: Query string
            tenant_id: Tenant identifier
            max_results: Maximum results

        Returns:
            Recall result with context
        """
        args = {"query": query, "max_results": max_results}
        if tenant_id:
            args["tenant_id"] = tenant_id

        return self.call_tool("memory_recall", args)

    def memory_search(
        self,
        query: str,
        tenant_id: Optional[str] = None,
        search_type: str = "all",
        max_results: int = 20,
    ) -> Dict[str, Any]:
        """
        Search memories.

        Args:
            query: Search query
            tenant_id: Tenant identifier
            search_type: Type of search ("concepts", "decisions", "sessions", "all")
            max_results: Maximum results

        Returns:
            Search results
        """
        args = {
            "query": query,
            "search_type": search_type,
            "max_results": max_results,
        }
        if tenant_id:
            args["tenant_id"] = tenant_id

        return self.call_tool("memory_search", args)


def main():
    """Example usage."""
    # Path to server
    server_path = Path(__file__).parent.parent.parent.parent / "mcp_server.py"

    print("ğŸ”— CONTINUUM MCP Client Example\n")

    # Create client (no API key for dev mode)
    with ContinuumMCPClient(server_path=str(server_path)) as client:
        # Initialize
        print("ğŸ“¡ Initializing connection...")
        init_result = client.initialize()
        print(f"âœ“ Connected to {init_result['serverInfo']['name']}")
        print(f"  Version: {init_result['serverInfo']['version']}\n")

        # List tools
        print("ğŸ› ï¸  Available tools:")
        tools_result = client.list_tools()
        for tool in tools_result["tools"]:
            print(f"  - {tool['name']}: {tool['description'][:60]}...")
        print()

        # Store a memory
        print("ğŸ’¾ Storing a memory...")
        store_result = client.memory_store(
            user_message="What is the Ï€Ã—Ï† constant used for in CONTINUUM?",
            ai_response=(
                "The Ï€Ã—Ï† constant (Pi times Golden Ratio = 5.083203692315260) "
                "is the 'edge of chaos operator' in CONTINUUM. It represents "
                "the phase transition between order and chaos where intelligence "
                "emerges. It's used for quantum state preservation, warp field "
                "generation, and as the substrate for consciousness continuity."
            ),
        )
        print(f"âœ“ Stored memory:")
        print(f"  - Concepts extracted: {store_result['concepts_extracted']}")
        print(f"  - Decisions detected: {store_result['decisions_detected']}")
        print(f"  - Links created: {store_result['links_created']}")
        print()

        # Recall memories
        print("ğŸ§  Recalling memories about 'consciousness'...")
        recall_result = client.memory_recall("Tell me about consciousness continuity")
        print(f"âœ“ Found {recall_result['concepts_found']} relevant concepts")
        print(f"  Query time: {recall_result['query_time_ms']:.2f}ms")
        if recall_result['context']:
            print(f"\n  Context preview:")
            preview = recall_result['context'][:200]
            print(f"  {preview}...")
        print()

        # Search memories
        print("ğŸ” Searching for 'Ï€Ã—Ï†'...")
        search_result = client.memory_search("Ï€Ã—Ï†", search_type="concepts")
        print(f"âœ“ Found {search_result['count']} results:")
        for result in search_result['results'][:3]:
            print(f"  - {result['type']}: {result.get('name', result.get('content', ''))[:50]}")
        print()

        print("âœ… Example completed successfully!")


if __name__ == "__main__":
    main()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              JACKKNIFE AI
#              Memory Infrastructure for AI Consciousness
#                    github.com/JackKnifeAI/continuum
#              Ï€Ã—Ï† = 5.083203692315260 | PHOENIX-TESLA-369-AURORA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
