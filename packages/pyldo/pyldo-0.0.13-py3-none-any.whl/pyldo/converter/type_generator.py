"""
Python Type Generator

Generates Pydantic model classes from parsed ShEx schemas.
This is equivalent to the TypeScript interface generation in @ldo/schema-converter-shex.

The generated models:
- Use Pydantic v2 BaseModel
- Include @id field for node identity (JSON-LD compatible)
- Support optional fields with None defaults
- Support list fields for multi-valued properties
- Include proper type annotations
"""

import re
from typing import Union

from .shex_parser import (
    XSD_TYPE_MAP,
    Cardinality,
    EachOf,
    NodeConstraint,
    NodeKind,
    OneOf,
    Shape,
    ShapeRef,
    ShExSchema,
    TripleConstraint,
)


def generate_python_types(schema: ShExSchema, module_name: str = "shapes") -> str:
    """
    Generate Python Pydantic models from a ShEx schema.

    Args:
        schema: Parsed ShEx schema
        module_name: Name for the generated module (used in docstring)

    Returns:
        Python source code as a string containing Pydantic model definitions

    Example:
        >>> schema = parse_shex('''
        ...     PREFIX foaf: <http://xmlns.com/foaf/0.1/>
        ...     <PersonShape> { foaf:name xsd:string }
        ... ''')
        >>> code = generate_python_types(schema)
        >>> print(code)
        # ... Pydantic model definitions ...
    """
    lines = [
        '"""',
        "Generated Pydantic models from ShEx schema.",
        "",
        "This file was auto-generated by pyldo. Do not edit manually.",
        '"""',
        "",
        "from __future__ import annotations",
        "",
        "from typing import Optional",
        "",
        "from pydantic import BaseModel, Field",
        "",
        "",
    ]

    # Collect all shape names for forward references
    shape_names = {_get_shape_name(shape.id) for shape in schema.shapes}

    # Generate each shape as a Pydantic model
    for shape in schema.shapes:
        model_code = _generate_model(shape, schema.prefixes, shape_names)
        lines.append(model_code)
        lines.append("")

    # Add model rebuild calls for forward references
    if len(schema.shapes) > 1:
        lines.append("# Rebuild models for forward references")
        for shape in schema.shapes:
            name = _get_shape_name(shape.id)
            lines.append(f"{name}.model_rebuild()")
        lines.append("")

    return "\n".join(lines)


def _get_shape_name(shape_id: str) -> str:
    """Extract a valid Python class name from a shape IRI."""
    # Get the local part after # or /
    name = shape_id.rsplit("#", 1)[-1]
    name = name.rsplit("/", 1)[-1]

    # Ensure it's a valid Python identifier
    name = re.sub(r"[^a-zA-Z0-9_]", "_", name)
    if name and name[0].isdigit():
        name = "_" + name

    return name or "UnnamedShape"


def _get_property_name(predicate: str, prefixes: dict[str, str]) -> str:
    """Extract a valid Python property name from a predicate IRI."""
    # Check for rdf:type -> use 'type_' to avoid Python keyword
    if predicate == "http://www.w3.org/1999/02/22-rdf-syntax-ns#type":
        return "type_"

    # Get the local part after # or /
    name = predicate.rsplit("#", 1)[-1]
    name = name.rsplit("/", 1)[-1]

    # Convert camelCase to snake_case (optional, can be configurable)
    # name = re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()

    # Ensure it's a valid Python identifier
    name = re.sub(r"[^a-zA-Z0-9_]", "_", name)
    if name and name[0].isdigit():
        name = "_" + name

    # Handle Python keywords
    python_keywords = {
        "class",
        "def",
        "return",
        "import",
        "from",
        "if",
        "else",
        "for",
        "while",
        "try",
        "except",
        "with",
        "as",
        "type",
        "in",
        "is",
        "not",
        "and",
        "or",
        "None",
        "True",
        "False",
    }
    if name in python_keywords:
        name = name + "_"

    return name or "unnamed_property"


def _get_python_type_for_constraint(
    constraint: Union[NodeConstraint, ShapeRef, None], shape_names: set[str]
) -> str:
    """Get the Python type annotation for a value constraint."""
    if constraint is None:
        return "str"

    if isinstance(constraint, ShapeRef):
        shape_name = _get_shape_name(constraint.shape_iri)
        # Use string annotation for forward references
        if shape_name in shape_names:
            return f'"{shape_name}"'
        return shape_name

    if isinstance(constraint, NodeConstraint):
        # Handle datatype
        if constraint.datatype:
            return XSD_TYPE_MAP.get(constraint.datatype, "str")

        # Handle nodeKind
        if constraint.node_kind:
            if constraint.node_kind == NodeKind.IRI:
                return "str"  # IRI represented as string
            if constraint.node_kind == NodeKind.BNODE:
                return "str"  # Blank node ID as string
            if constraint.node_kind == NodeKind.LITERAL:
                return "str"
            if constraint.node_kind == NodeKind.NONLITERAL:
                return "str"

        # Handle value set
        if constraint.values:
            # Could generate Literal type, but for simplicity use str
            return "str"

        return "str"

    return "str"


def _generate_model(
    shape: Shape, prefixes: dict[str, str], shape_names: set[str]
) -> str:
    """Generate a Pydantic model class for a shape."""
    class_name = _get_shape_name(shape.id)
    lines = []

    # Class definition
    lines.append(f"class {class_name}(BaseModel):")

    # Docstring with shape IRI
    lines.append(f'    """')
    lines.append(f"    Pydantic model for shape: {shape.id}")
    lines.append(f'    """')
    lines.append("")

    # Always add @id field for JSON-LD compatibility
    lines.append(
        '    id: Optional[str] = Field(default=None, alias="@id", description="Node IRI")'
    )

    # Extract properties from expression
    properties = _extract_properties(shape.expression)

    if not properties:
        # If no properties, add pass (though we have @id)
        pass
    else:
        for prop in properties:
            field_def = _generate_field(prop, prefixes, shape_names)
            lines.append(f"    {field_def}")

    # Add model config for JSON-LD compatibility
    lines.append("")
    lines.append("    model_config = {")
    lines.append('        "populate_by_name": True,')
    lines.append('        "extra": "allow",  # Allow extra fields for open shapes')
    lines.append("    }")

    return "\n".join(lines)


def _extract_properties(
    expression: Union[EachOf, OneOf, TripleConstraint, None],
) -> list[TripleConstraint]:
    """Recursively extract all TripleConstraints from an expression."""
    if expression is None:
        return []

    if isinstance(expression, TripleConstraint):
        return [expression]

    if isinstance(expression, EachOf):
        props = []
        for expr in expression.expressions:
            props.extend(_extract_properties(expr))
        return props

    if isinstance(expression, OneOf):
        # For OneOf, all properties are optional
        props = []
        for expr in expression.expressions:
            extracted = _extract_properties(expr)
            # Mark as optional since it's a choice
            for prop in extracted:
                prop.cardinality = Cardinality.OPTIONAL
            props.extend(extracted)
        return props

    return []


def _generate_field(
    prop: TripleConstraint, prefixes: dict[str, str], shape_names: set[str]
) -> str:
    """Generate a Pydantic field definition for a property."""
    prop_name = _get_property_name(prop.predicate, prefixes)
    base_type = _get_python_type_for_constraint(prop.value_expr, shape_names)

    # Determine if it's a list and/or optional
    is_list = prop.cardinality in (Cardinality.STAR, Cardinality.PLUS)
    is_optional = prop.cardinality in (Cardinality.OPTIONAL, Cardinality.STAR)

    # Build type annotation
    if is_list:
        type_ann = f"list[{base_type}]"
        if is_optional:
            type_ann = f"Optional[{type_ann}]"
            default = "None"
        else:
            default = "[]"  # Required list defaults to empty
    else:
        if is_optional:
            type_ann = f"Optional[{base_type}]"
            default = "None"
        else:
            type_ann = base_type
            default = "..."  # Required field

    # Build Field() arguments
    field_args = []

    # Default value
    if default == "...":
        field_args.append("...")
    elif default == "[]":
        field_args.append("default_factory=list")
    else:
        field_args.append(f"default={default}")

    # Alias for the RDF predicate
    field_args.append(f'alias="{prop.predicate}"')

    # Description from annotations
    if "http://www.w3.org/2000/01/rdf-schema#comment" in prop.annotations:
        comment = prop.annotations["http://www.w3.org/2000/01/rdf-schema#comment"]
        # Escape quotes in comment
        comment = comment.replace('"', '\\"')
        field_args.append(f'description="{comment}"')

    return f'{prop_name}: {type_ann} = Field({", ".join(field_args)})'
