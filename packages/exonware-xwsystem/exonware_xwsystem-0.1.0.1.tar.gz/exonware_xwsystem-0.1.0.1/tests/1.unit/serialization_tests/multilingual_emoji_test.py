#!/usr/bin/env python3
"""
Comprehensive test of mixed languages and emojis in BSON serialization.
Tests the most complex Unicode scenarios possible.
"""

def test_multilingual_emojis():
    """Test extreme Unicode complexity with multiple languages and emojis."""
    
    try:
        from exonware.xwsystem.io.serialization import BsonSerializer
        
        print("ğŸŒ MULTILINGUAL + EMOJI BSON TEST")
        print("=" * 50)
        
        # Extreme multilingual test data
        complex_data = {
            # Mix of Arabic, English, Chinese, Japanese, Russian, Hebrew, Hindi
            "greeting": "Hello Ù…Ø±Ø­Ø¨Ø§ ä½ å¥½ ã“ã‚“ã«ã¡ã¯ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ ×©×œ×•× à¤¨à¤®à¤¸à¥à¤¤à¥‡ ğŸŒğŸŒğŸŒ",
            
            # Languages with numbers and symbols
            "mixed_numbers": "English123 Ø¹Ø±Ø¨ÙŠÙ¤Ù¥Ù¦ ä¸­æ–‡789 Ñ€ÑƒÑÑĞºĞ¸Ğ¹012 ×¢×‘×¨×™×ª345 ğŸ”¢ğŸ“Š",
            
            # Complex emojis (including skin tones and combined emojis)
            "emojis": "ğŸ‘‹ğŸ½ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ³ï¸â€ğŸŒˆğŸ§‘ğŸ¾â€ğŸ’»ğŸ‘©ğŸ»â€ğŸ”¬ğŸ‰ğŸ¥³ğŸŠâœ¨ğŸ’«â­ğŸŒŸğŸ’¥",
            
            # Religious and cultural symbols
            "symbols": "â˜ªï¸âœï¸ğŸ•‰ï¸â˜¯ï¸ğŸ”¯âš›ï¸ğŸ› Î± Î² Î³ Î´ Îµ Î¶ Î· Î¸ Î¹ Îº Î» Î¼ Î½ Î¾ Î¿ Ï€ Ï Ïƒ Ï„ Ï… Ï† Ï‡ Ïˆ Ï‰",
            
            # Mathematical and scientific symbols
            "math": "âˆ‘âˆ†âˆ‡âˆâ‰ˆâ‰ â‰¤â‰¥Â±âˆ“âˆ´âˆµâˆˆâˆ‰âˆ©âˆªâŠ‚âŠƒâŠ†âŠ‡âˆ§âˆ¨Â¬â†’â†”âˆ€âˆƒâˆ…â„â„‚â„•â„¤â„šâˆ‚âˆ«âˆ®âˆ",
            
            # Currency symbols from different countries
            "currency": "$ â‚¬ Â£ Â¥ â‚¹ â‚½ â‚© â‚ª ï·¼ â‚´ â‚¦ â‚¨ â‚± â‚¡ â‚« â‚µ ğŸ’°ğŸ’´ğŸ’µğŸ’¶ğŸ’·ğŸ’¸",
            
            # Nested structure with mixed content
            "nested": {
                "arabic_city": "Ø§Ù„Ø±ÙŠØ§Ø¶ ğŸ›ï¸",
                "chinese_food": "åŒ—äº¬çƒ¤é¸­ ğŸ¦†ğŸ¥¢",
                "japanese_culture": "ä¾ ğŸ—¾â›©ï¸ğŸŒ",
                "russian_winter": "Ğ·Ğ¸Ğ¼Ğ° â„ï¸ğŸ»ğŸ‡·ğŸ‡º",
                "indian_spices": "à¤®à¤¸à¤¾à¤²à¤¾ ğŸŒ¶ï¸ğŸ›",
                "mixed_celebration": "ğŸ‰ Party Ø­ÙÙ„Ø© æ´¾å¯¹ ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ Ğ²ĞµÑ‡ĞµÑ€Ğ¸Ğ½ĞºĞ° ××¡×™×‘×” à¤ªà¤¾à¤°à¥à¤Ÿà¥€ ğŸŠ"
            },
            
            # Text with special Unicode categories
            "special": "ğŸ”€ğŸ”ğŸ”‚ğŸ”ƒğŸ”„ğŸ”…ğŸ”†ğŸ”‡ğŸ”ˆğŸ”‰ğŸ”Š â™ ï¸â™£ï¸â™¥ï¸â™¦ï¸ ğŸƒğŸ´ğŸ€„ ğŸ“±ğŸ’»âŒšğŸ“ºğŸ“»",
            
            # Mixed RTL and LTR text (Arabic + English)
            "rtl_ltr_mix": "This is English then Ø¹Ø±Ø¨ÙŠ Ù†Øµ here and English again Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© and back to English ğŸ”„",
            
            # Extreme length with all languages
            "long_text": "ğŸŒ Global message: " + 
                        "English: Welcome to our world! " +
                        "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ Ø¹Ø§Ù„Ù…Ù†Ø§! " +
                        "ä¸­æ–‡: æ¬¢è¿æ¥åˆ°æˆ‘ä»¬çš„ä¸–ç•Œ! " +
                        "æ—¥æœ¬èª: ç§ãŸã¡ã®ä¸–ç•Œã¸ã‚ˆã†ã“ã! " +
                        "Ğ ÑƒÑÑĞºĞ¸Ğ¹: Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Ğ½Ğ°Ñˆ Ğ¼Ğ¸Ñ€! " +
                        "×¢×‘×¨×™×ª: ×‘×¨×•×›×™× ×”×‘××™× ×œ×¢×•×œ×× ×•! " +
                        "à¤¹à¤¿à¤¨à¥à¤¦à¥€: à¤¹à¤®à¤¾à¤°à¥€ à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤®à¥‡à¤‚ à¤†à¤ªà¤•à¤¾ à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤¹à¥ˆ! " +
                        "ğŸ‰ğŸŠâœ¨ğŸ’«â­ğŸŒŸ"
        }
        
        print("ğŸ“ ORIGINAL Complex Data:")
        for key, value in complex_data.items():
            if len(str(value)) > 100:
                print(f"   {key}: {str(value)[:100]}... [truncated]")
            else:
                print(f"   {key}: {value}")
        
        # Test serialization
        serializer = BsonSerializer()
        
        print(f"\nğŸ”„ Testing BSON Serialization...")
        
        # Binary serialization
        print("   1ï¸âƒ£ Binary serialization...")
        binary_result = serializer.dumps_binary(complex_data)
        print(f"      Result: {len(binary_result)} bytes")
        
        # Base64 serialization  
        print("   2ï¸âƒ£ Base64 serialization...")
        text_result = serializer.dumps(complex_data)
        print(f"      Result: {len(text_result)} ASCII characters")
        print(f"      Preview: {text_result[:50]}...")
        
        # Test round-trips
        print(f"\nğŸ”„ Testing Round-trips...")
        
        print("   3ï¸âƒ£ Binary round-trip...")
        restored_binary = serializer.loads_bytes(binary_result)
        
        print("   4ï¸âƒ£ Base64 round-trip...")
        restored_text = serializer.loads(text_result)
        
        # Detailed verification
        print(f"\nâœ… VERIFICATION Results:")
        
        all_perfect = True
        differences = []
        
        for key in complex_data:
            original = complex_data[key]
            binary_restored = restored_binary[key]
            text_restored = restored_text[key]
            
            binary_match = original == binary_restored
            text_match = original == text_restored
            
            if not binary_match:
                differences.append(f"Binary mismatch in '{key}'")
                all_perfect = False
                
            if not text_match:
                differences.append(f"Text mismatch in '{key}'")
                all_perfect = False
            
            # Show detailed comparison for first few fields
            if key in ['greeting', 'emojis', 'rtl_ltr_mix']:
                print(f"\n   ğŸ” Field '{key}':")
                print(f"      Original: '{original}'")
                print(f"      Binary:   '{binary_restored}' {'âœ…' if binary_match else 'âŒ'}")
                print(f"      Base64:   '{text_restored}' {'âœ…' if text_match else 'âŒ'}")
        
        # Final results
        print(f"\nğŸ¯ FINAL RESULT:")
        if all_perfect:
            print("   ğŸ‰ PERFECT SUCCESS! All languages and emojis preserved!")
            print("   âœ… Arabic, Chinese, Japanese, Russian, Hebrew, Hindi - ALL PERFECT")
            print("   âœ… Complex emojis with skin tones - PERFECT")
            print("   âœ… Mathematical symbols - PERFECT") 
            print("   âœ… Currency symbols - PERFECT")
            print("   âœ… RTL/LTR mixed text - PERFECT")
            print("   âœ… Nested structures - PERFECT")
            print("   âœ… Both binary and base64 round-trips - PERFECT")
        else:
            print("   âŒ ISSUES FOUND:")
            for diff in differences:
                print(f"      â€¢ {diff}")
        
        # Character count analysis
        total_chars = sum(len(str(v)) for v in complex_data.values())
        print(f"\nğŸ“Š STATISTICS:")
        print(f"   â€¢ Total characters tested: {total_chars}")
        print(f"   â€¢ Languages: Arabic, English, Chinese, Japanese, Russian, Hebrew, Hindi")
        print(f"   â€¢ Special content: Emojis, Math symbols, Currency, RTL/LTR mixing")
        print(f"   â€¢ Binary BSON size: {len(binary_result)} bytes")
        print(f"   â€¢ Base64 text size: {len(text_result)} characters")
        print(f"   â€¢ Compression ratio: {len(text_result)/total_chars:.2f}x")
        
        return all_perfect
        
    except ImportError as e:
        print(f"âŒ BSON not available: {e}")
        return False
    except Exception as e:
        print(f"âŒ Error during test: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ Starting Multilingual + Emoji Test...\n")
    success = test_multilingual_emojis()
    print(f"\nğŸ Test completed: {'ğŸ‰ SUCCESS' if success else 'âŒ FAILED'}")
