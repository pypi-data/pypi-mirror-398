[project]
name = "londonaicentre-llama-serve" 
description = "Serve llama models locally"
authors = [
    { name = "Dr. Joe Zhang", email = "jzhang@nhs.net" },
    { name = "Martin Chapman", email = "contact@martinchapman.co.uk" },
]
readme = "README.md"
version = "1.1.3"
requires-python = ">=3.12"
license = "LicenseRef-Proprietary"
license-files = [ "LICENSE.md" ]
dependencies = [
    "httpx>=0.28.1",
    "pydantic>=2.12.4",
    "pydantic-settings>=2.11.0",
    "tqdm>=4.67.1",
    "vllm>=0.11.0",
]
[dependency-groups]
dev = [
    "httpx>=0.28.1",
    "pydantic>=2.12.4",
    "pydantic-settings>=2.11.0",
    "tqdm>=4.67.1",
    "types-tqdm>=4.67.0.20250809",
    "flake8>=7.3.0",
    "mypy>=1.18.2",
    "pytest>=8.4.2",
    "tox>=4.30.2",
    "tox-uv>=1.28.0",
    "black>=25.9.0",
    "twine>=6.2.0",
    "build>=1.3.0",
]
[project.scripts]
"llamaserve" = "llamaserve:run"
[build-system]
requires = ["setuptools>=80.9.0"]
build-backend = "setuptools.build_meta"
[tool.setuptools]
package-data = {"llamaserve" = ["py.typed"]}
[tool.pytest.ini_options]
pythonpath = ["src"]
log_cli = "true"
log_cli_level = "DEBUG"
