# Ungraph ‚Äî Investigaci√≥n t√©cnico-cient√≠fica

**Resumen:**
Las arquitecturas modernas de Retrieval-Augmented Generation (RAG) enfrentan desaf√≠os en la construcci√≥n de grafos de conocimiento confiables y trazables. Este trabajo propone el patr√≥n Extract-Transform-Inference (ETI) como evoluci√≥n del tradicional ETL, a√±adiendo una fase expl√≠cita de inferencia que genera hechos normalizados con trazabilidad PROV-O. 

Presentamos una implementaci√≥n parcial de ETI en la librer√≠a Ungraph, que construye Lexical Graphs sobre Neo4j integrando chunking estrat√©gico, embeddings vectoriales y patrones GraphRAG b√°sicos. La implementaci√≥n actual cubre las fases Extract y Transform; la fase Inference se implementa mediante extracci√≥n transductiva b√°sica de entidades nombradas (NER) usando spaCy, generando facts simples de menci√≥n y relaciones de co-ocurrencia.

El dise√±o experimental propone evaluar la efectividad mediante experimentos reproducibles en cuatro dominios (financiero, biom√©dico, cient√≠fico y general), comparando pipelines control (ET) versus ETI en m√©tricas de recuperaci√≥n (recall@k, MRR), calidad de QA (F1), precisi√≥n de inferencia y tasa de hallucination. Los resultados experimentales completos est√°n pendientes de ejecuci√≥n.

El patr√≥n ETI proporciona un marco coherente para construir sistemas de conocimiento confiables, integrando principios de ingenier√≠a del conocimiento, Web sem√°ntica (ontolog√≠as, PROV) y neuro-symbolic computing.

## Objetivo
Formalizar y documentar, con rigor cient√≠fico y reproducible, los experimentos y resultados que soportan las decisiones de dise√±o de Ungraph (estrategias de chunking, pipelines h√≠bridos de recuperaci√≥n, uso de Neo4j como almac√©n vectorial vs alternativas, y la ontolog√≠a propuesta para `File`/`Page`/`Chunk`).

## Alcance de la investigaci√≥n
- Evaluaciones emp√≠ricas de estrategias de chunking (fixed-size, lexical, semantic, hierarchical) por dominio (financiero, biomedicina, papers cient√≠ficos, negocio).  
- Comparaci√≥n de estrategias de recuperaci√≥n: vector-only, text-only, hybrid, hybrid + graph expansion + LM reranker.  
- Benchmarks de indexaci√≥n/vector search: Neo4j vector indexes vs FAISS/Milvus/Weaviate (latencia, recall, coste).  
- Formalizaci√≥n ontol√≥gica (`File`, `Page`, `Chunk`) y mapeos a vocabularios est√°ndar (schema.org, PROV-O).  
- Reproducibilidad: scripts, Opik experiment configs y OpenAI Evals para evaluaciones model-graded y human-in-the-loop.

## Metodolog√≠a (resumen)
1. Preparaci√≥n de datasets (EDGAR/financial filings, BioASQ/PubMedQA, arXiv subsets, internal SOPs).  
2. Implementaci√≥n de variantes (chunkers, retrievers, pattern execution).  
3. Ejecuci√≥n de experimentos E1‚ÄìE4 con harness Opik y registro de m√©tricas (recall@k, MRR, QA-F1, inference accuracy, hallucination rate, latency).  
4. An√°lisis estad√≠stico y reporte reproducible (notebooks, tablas y gr√°ficos).

## Research Questions e Hip√≥tesis

### Research Questions

**RQ1: Efectividad de la Fase de Inferencia**
¬øA√±adir una fase expl√≠cita de inferencia (I) mejora la calidad de recuperaci√≥n y respuesta de preguntas comparado con pipelines que solo realizan extracci√≥n y transformaci√≥n (ET)?

**RQ2: Tipos de Inferencia por Dominio**
¬øQu√© tipo de inferencia (LM-only, symbolic-only, neuro-symbolic) es m√°s efectiva para diferentes dominios de conocimiento (financiero, biom√©dico, cient√≠fico, general)?

**RQ3: Trade-off Trazabilidad vs Performance**
¬øLa trazabilidad completa con PROV-O mejora la confianza y explicabilidad del sistema sin sacrificar significativamente el rendimiento (latencia, throughput)?

**Nota**: Estas research questions guiar√°n los experimentos futuros una vez completada la implementaci√≥n de la fase Inference. Para v0.1.0, se implementa solo extracci√≥n transductiva b√°sica (NER con spaCy); las capacidades avanzadas de inferencia est√°n planificadas para v0.2+.

### Hip√≥tesis Experimentales

- **H1**: ETI (con Inference) > ET (sin Inference) en recall@k y QA-F1
- **H2**: Semantic chunking > Recursive chunking para dominios t√©cnicos
- **H3**: Parent-Child retrieval > Basic retrieval para preguntas que requieren contexto
- **H4**: [Futuro] Hybrid inference > LM-only para precisi√≥n de facts extra√≠dos

### Metodolog√≠a experimental ‚Äî Protocolo reproducible üß™

**Objetivo:** Definir un protocolo replicable paso a paso para ejecutar y evaluar comparativas entre pipelines control (ET) y ETI y sus variantes (LM‚Äëonly, symbolic‚Äëonly, neuro‚Äësymbolic). Todas las ejecuciones deben grabar metadatos de entorno, seeds y bundles PROV para trazabilidad.

1) Entorno reproducible
- Usar entorno virtual (`python -m venv .venv` o Conda) y fijar Python (ej. 3.11). Ejecutar `pip freeze > requirements.txt` y capturar el hash de commit: `git rev-parse --short HEAD`.
- Registrar: SO, versiones de paquetes, URI de bases (Neo4j), OPIK env var present (no incluir llaves en artefactos), y `RANDOM_SEED` en env.

2) Adquisici√≥n y preparaci√≥n de datasets
- EDGAR/10‚ÄëK: script `scripts/fetch_edgar.py --out data/edgar/` (parseo, segmentaci√≥n por secciones).  
- BioASQ/PubMedQA: usar dumps oficiales o APIs; almacenar en `data/biomed/` con manifest JSON (sha256 checksums).  
- arXiv subsets: extraer por query (arXiv category) y guardar metadatos.  
- Generar tabla `experiments/datasets.csv` (placeholder) con columnas: dataset, URL, license, n_documents, n_chunks_estimated, notes.

3) Definir pipelines y variantes
- Pipelines: ET (Extract + Transform) y ETI (Extract + Transform + Inference).  
- Variantes de inferencia: `lm-only`, `symbolic-only`, `neuro-symbolic`.
- Implementar cada pipeline como un `dag` reproducible; los configs estar√°n en `experiments/<domain>/<pipeline>.yaml`.

4) Configuraci√≥n Opik (plantilla)
- Crear `experiments/finance/etik_finance_opik.yaml` con placeholders. No incluir OPIK_API_KEY en repositorio; usar variables de entorno.

Ejemplo (plantilla, no incluir secretos):

```yaml
experiment_name: finance_eti_v1
dataset: edgar
pipeline: ETI
inference: lm-only
opik:
  api_key: ${OPIK_API_KEY}
  model: openai-xyz
  timeout: 60
seeds:
  random_seed: 42
output:
  dir: experiments/finance_eti_v1/
```

5) Ejecuci√≥n (comandos reproducibles)
- Ejemplo: `python scripts/run_experiment.py --config experiments/finance/finance_eti_v1.yaml --seed 42 --out experiments/finance_eti_v1/`
- Cada ejecuci√≥n debe escribir un `metadata.json` con: seed, git_hash, timestamp, pipeline, config path, host, package versions.

6) Salida y artefactos
- Guardar: embeddings (binary/ndjson), `chunks.jsonl`, `inferred_facts.jsonl` (tripletas), `prov_bundle.json` (PROV), `evaluation/` con outputs y logs.
- Los hechos inferidos deben incluir campos: subject, predicate, object, confidence, provenance_ref.

7) M√©tricas y evaluaci√≥n autom√°tica
- Recuperaci√≥n: recall@k, MRR.  
- QA: F1 (micro/macro) sobre conjuntos anotados.  
- Inferencia: precision, recall, F1 sobre facts anotados (TP/FP/FN).  
- Hallucination rate: proportion of generated facts judged as ungrounded by annotators.  
- Coherencia de grafo: medidas de inconsistencia (contradicciones) y cobertura de ontolog√≠a.
- Definir scripts en `scripts/evaluate.py --pred inferred_facts.jsonl --gold gold_facts.jsonl --metrics all`.

8) Evaluaci√≥n humana (protocolo)
- Sampling: seleccionar N facts por pipeline (stratificado por confianza y dominio).  
- Instrucciones de anotadores: verificar si el hecho est√° expl√≠cito/entailed por la fuente y marcar fuente URL/loc.
- Medir inter-annotator agreement (Cohen's kappa) y adjudicar desacuerdos.

9) An√°lisis estad√≠stico
- Comparar pares (ET vs ETI) usando bootstrap resampling para intervalos de confianza y test de hip√≥tesis (paired t-test o Wilcoxon seg√∫n normalidad). Reportar p‚Äëvalues y tama√±o de efecto (Cohen's d).

10) Publicaci√≥n y reproducibilidad
- Publicar notebooks (convertir a HTML con `jupyter nbconvert --to html`) y subir a `docs/` y GitHub (tagged release). Registrar DOI en Zenodo para la release con los notebooks y datasets que puedan compartirse.
- Incluir `experiments/<id>/prov_bundle.json` para que terceros puedan auditar derivaciones.

> Nota: Las plantillas de configs y scripts estar√°n en `experiments/templates/` y se actualizar√°n con cada revisi√≥n; **no** se publicar√°n resultados hasta ejecutar los experimentos y validar las m√©tricas con los or√°culos y evaluaciones humanas.

  

## Entregables esperados
- Documento final con: motivaci√≥n, estado del arte, metodolog√≠a, resultados experimentales, discusi√≥n, limitaciones y recomendaciones.  
- Ficheros reproducibles (scripts, Opik configs, eval templates), notebooks y datasets anotados.  
- Ontolog√≠a publicada (`docs/ontology.md` + `ontology.owl` + JSON-LD examples).

## Relaci√≥n con las tareas del proyecto
Esta tarea final est√° registrada en el checklist maestro `_NET_STEPS.md` (ver `project/Instructions/_NET_STEPS.md`) como la tarea de documentaci√≥n t√©cnico-cient√≠fica que culmina el ciclo de investigaci√≥n y desarrollo. Debe incluir todas las referencias y evidencia recogida en la fase de evaluaci√≥n.

## Referencias (iniciales)
- Lewis et al. [1] - RAG (Retrieval-Augmented Generation)
- Peng et al. [2] - GraphRAG Survey
- Neo4j GraphRAG Patterns Catalog [3]
- W3C PROV [4] - Provenance y trazabilidad
- Zhong et al. [5] - Surveys de construcci√≥n de KG
- d'Avila Garcez et al. [6] - Neuro-Symbolic Computing
- Rowley [7], Ackoff [8], Zins [9] - DIKW Hierarchy
- Miller 1956 [10]; Thalmann et al. 2019 [11] (chunking)

## Patr√≥n: Extracci√≥n ‚Äî Transformaci√≥n ‚Äî Inferencia (ETI)

### Definici√≥n Formal del Patr√≥n ETI

**Definici√≥n 1 (Pipeline ETI):**
Un pipeline ETI es una tupla P = (E, T, I, O, M) donde:

- **E (Extractors)**: Conjunto de extractores {e‚ÇÅ, e‚ÇÇ, ..., e‚Çô} donde cada 
  e·µ¢: Sources ‚Üí Documents produce documentos estructurados con metadatos.

- **T (Transformers)**: Conjunto de transformadores {t‚ÇÅ, t‚ÇÇ, ..., t‚Çò} donde cada 
  t‚±º: Documents ‚Üí Chunks produce chunks con embeddings y anotaciones sem√°nticas.

- **I (Inference)**: Conjunto de modelos de inferencia {i‚ÇÅ, i‚ÇÇ, ..., i‚Çñ} donde cada 
  i‚Çñ: Chunks ‚Üí (Facts ‚à™ Relations ‚à™ Explanations) genera artefactos de conocimiento 
  con se√±ales de confianza y trazabilidad.

- **O (Ontology)**: Esquema formal que define tipos de entidades, relaciones permitidas, 
  constraints y mapeos a vocabularios est√°ndar (schema.org, PROV-O).

- **M (Metadata)**: Estructura PROV-O que registra provenance de cada artefacto, 
  incluyendo: entidades derivadas, actividades ejecutadas, agentes responsables y timestamps.

**Propiedades del Pipeline ETI:**
1. **Trazabilidad**: Todo fact f ‚àà Facts tiene prov:wasDerivedFrom apuntando a su chunk fuente
2. **Validabilidad**: Todo fact f puede ser verificado contra source s mediante provenance chain
3. **Composabilidad**: Pipelines ETI pueden encadenarse (salida de I‚Çñ ‚Üí entrada de E·µ¢‚Çä‚ÇÅ)
4. **Reproducibilidad**: Dado mismo input + config + seed ‚Üí mismo output

### Comparaci√≥n ETL vs ETI

| Aspecto | ETL (Tradicional) | ETI (Propuesto) |
|---------|-------------------|-----------------|
| **Fases** | Extract, Transform, Load | Extract, Transform, **Infer** |
| **Objetivo** | Preparar datos para almacenamiento | Construir conocimiento trazable |
| **Artefactos** | Datos estructurados | Facts, relaciones, explicaciones |
| **Trazabilidad** | Limitada (metadatos b√°sicos) | Completa (PROV-O) |
| **Validaci√≥n** | Verificaci√≥n de formato | Validaci√≥n de conocimiento |
| **Razonamiento** | No incluye | Incluye inferencia expl√≠cita |

**Descripci√≥n:**
El patr√≥n *Extracci√≥n ‚Äî Transformaci√≥n ‚Äî Inferencia* (ETI) se propone como la evoluci√≥n natural del cl√°sico ETL en el contexto de la ingenier√≠a del conocimiento y de las arquitecturas GraphRAG. ETI articula tres fases obligatorias en pipelines de conocimiento: 1) **Extracci√≥n** de fuentes crudas y metadatos; 2) **Transformaci√≥n** mediante chunking, normalizaci√≥n, enriquecimiento sem√°ntico y linking; 3) **Inferencia** donde modelos (LM/ML/razonadores simb√≥licos) generan hechos, relaciones, deducciones y explicaciones que alimentan los grafos y los √≠ndices vectoriales.

**Justificaci√≥n y posici√≥n en el art√≠culo:**
Esta hip√≥tesis es central para la investigaci√≥n: defendemos que a√±adir una fase expl√≠cita de inferencia (no meramente transductiva) distingue las soluciones de *knowledge engineering* modernas de los pipelines ETL tradicionales y mejora la calidad y utilidad de los artefactos (embeddings, nodos/aristas, tripletas). La hip√≥tesis **no debe eliminarse**: ser√° validada mediante experimentos y ablations en los que compararemos pipelines con y sin la fase de inferencia.

**Arquitectura propuesta y artefactos:**
- Extracci√≥n: parsers y connectors que producen `File`/`Page` y metadatos (timestamps, autor√≠a, contexto).  
- Transformaci√≥n: chunkers (fixed, lexical, hierarchical, semantic), normalizadores, detectores de idioma, y generadores de embeddings; salida: `Chunk` con anotaciones sem√°nticas.  
- Inferencia: modelos que extraen relaciones/facts, resuelven ambig√ºedad, hacen mapping a la ontolog√≠a (`File`/`Page`/`Chunk`), y generan aristas y propiedades para el grafo; salida: nodos, aristas, tripletas RDF/JSON-LD y se√±ales de confianza.

**Estado de Implementaci√≥n (v0.1.0):**
La implementaci√≥n actual de Ungraph incluye una fase de inferencia b√°sica que realiza extracci√≥n transductiva de entidades nombradas (NER) mediante spaCy. Esta fase genera facts simples de menci√≥n `(chunk_id, "MENTIONS", entity_name)` y relaciones b√°sicas de co-ocurrencia. **Nota importante**: Esta implementaci√≥n es un primer paso hacia inferencia no transductiva completa. Las capacidades avanzadas de inferencia (resoluci√≥n de ambig√ºedad, normalizaci√≥n de entidades, relaciones sem√°nticas complejas, razonamiento sobre el grafo) est√°n planificadas para versiones futuras (v0.2+) y ser√°n validadas experimentalmente como parte de la investigaci√≥n propuesta.

**Ejemplo (finanzas):**
1. Extracci√≥n: descarga y parseo de 10‚ÄëK/EDGAR.  
2. Transformaci√≥n: chunking por secciones y extracci√≥n de tablas, embeddings por chunk.  
3. Inferencia: LM que extrae hechos financieros (ingresos, activos) y relaciones (empresa‚Äësubsidiaria), normaliza entidades y crea/actualiza nodos y relaciones en el grafo.

**Clarificaci√≥n: Extracci√≥n vs Inferencia**

Es importante distinguir entre extracci√≥n transductiva e inferencia no transductiva:

- **Extracci√≥n transductiva** (implementada en v0.1.0): Identifica entidades expl√≠citas en el texto mediante NER. Ejemplo: "Apple Inc." aparece en texto ‚Üí Entity "Apple Inc." con tipo ORGANIZATION. Esta es una operaci√≥n de reconocimiento de patrones que no genera conocimiento nuevo.

- **Inferencia no transductiva** (planificada para v0.2+): Deduce relaciones impl√≠citas, resuelve ambig√ºedad mediante contexto, normaliza variantes de entidades, y genera conocimiento nuevo mediante razonamiento. Ejemplos:
  - Resoluci√≥n de ambig√ºedad: "Apple" en contexto financiero ‚Üí ORGANIZATION (no FRUIT)
  - Normalizaci√≥n: "Apple Inc.", "Apple", "AAPL" ‚Üí misma entidad normalizada
  - Relaciones sem√°nticas: "Tim Cook lidera Apple" ‚Üí WORKS_FOR(Tim Cook, Apple), CEO_OF(Tim Cook, Apple)
  - Razonamiento transitivo: Si A ‚Üí B y B ‚Üí C, entonces A ‚Üí C

La implementaci√≥n actual (v0.1.0) realiza extracci√≥n transductiva b√°sica. La inferencia no transductiva completa ser√° implementada y validada experimentalmente en versiones futuras.

**Medici√≥n y evaluaci√≥n experimental:**
Evaluaremos ETI mediante m√©tricas cl√°sicas y espec√≠ficas: recall@k y MRR en tareas de recuperaci√≥n, QA‚ÄëF1 en pipelines RAG, *inference accuracy* (precisi√≥n/recall sobre hechos extra√≠dos), tasa de *hallucination*, coherencia de grafo y coste/latencia. Proponemos estudios de ablation (sin inferencia vs con inferencia) para cuantificar su impacto en las tareas downstream.

**Relaci√≥n con otros componentes del estudio:**
ETI conecta directamente con: estrategias de chunking (fase Transformaci√≥n), patrones GraphRAG (uso de grafos y expansi√≥n), la ontolog√≠a `File`/`Page`/`Chunk` y las evaluaciones reproducibles (notebooks y Opik configs). Las decisiones implementadas en Ungraph (ingestores, chunkers, retrievers) est√°n dise√±adas para soportar y evaluar ETI.

## Filosof√≠a y justificaci√≥n epistemol√≥gica del ETI

**Resumen filos√≥fico:**
ETI toma como punto de partida cl√°sicas reflexiones sobre la transici√≥n *data ‚Üí information ‚Üí knowledge* (DIKW; Ackoff [8]; Rowley [7]; Zins [9]) y propone transformar los pipelines de preparaci√≥n de datos en procesos que expl√≠citamente construyen artefactos justificables y utilizables para razonamiento autom√°tico (con fiabilidad y trazabilidad). En t√©rminos epistemol√≥gicos, ETI busca convertir informaci√≥n estructurada (estructuras y anotaciones) en *creencias justificadas* (hechos, relaciones y reglas) que puedan sostener inferencias y decisiones automatizadas.

**Apoyos bibliogr√°ficos clave:**
- DIKW y los debates sobre la naturaleza de conocimiento (Ackoff [8]; Rowley [7]; Zins [9]) muestran la necesidad de procesos que no s√≥lo estructuren datos sino que produzcan conocimiento justificable (ver discusi√≥n DIKW y cr√≠ticas). (v√©ase: DIKW reviews, 1989‚Äì2007).  
- Provenance y trazabilidad (W3C PROV [4]) son esenciales para que las inferencias sean evaluables, reproducibles y confiables; PROV formaliza c√≥mo representar entidades, actividades y agentes involucrados en la construcci√≥n de hechos (W3C PROV, 2013).
- Workflows de construcci√≥n de Knowledge Graphs muestran que la comunidad distingue etapas (IE ‚Üí KBC ‚Üí KG refinement) y discute la integraci√≥n de extracci√≥n y razonamiento [5].
- RAG [1] y GraphRAG [2] muestran que integrar memoria no‚Äëparam√©trica y grafos mejora el grounding factual y reduce la tasa de hallucination; ETI extiende estos enfoques al incorporar una fase expl√≠cita de inferencia que genera relaciones verificadas y trazables.
- Neuro‚Äësymbolic surveys [6] justifican el valor de combinar modelos estad√≠sticos (LMs) con razonamiento simb√≥lico para obtener explicabilidad y control sobre inferencias.

**Argumento metodol√≥gico y experimental (resumen):**
1. Hip√≥tesis: a√±adir una fase de inferencia que produzca hechos normalizados y con trazabilidad mejora la utilidad de los artefactos de conocimiento (mayor precision/recall en QA y recuperaci√≥n, menor tasa de hallucination y mayor coherencia de grafo).  
2. Protocolo: definir pipelines control (ET, no I) vs ETI y medir: inference accuracy (micro/macro), downstream QA‚ÄëF1, recall@k, MRR, hallucination rate, y m√©tricas de trazabilidad/provenance coverage (PROV con mediciones cuantificables).  
3. Ablations: tipos de inferencia (LM-only, symbolic-only, neuro-symbolic) y su impacto; evaluaci√≥n por dominio (finanzas, biomedicina, papers cient√≠ficos) y por nivel de confianza.

**Criterios de rigor cient√≠fico:**
- Usar datasets p√∫blicos y reproducibles, scripts y configs Opik, Evals autom√°ticos y evaluaciones humanas para facts cr√≠ticos; publicar notebooks y JSON-LD/PROV outputs para verificaci√≥n externa.  
- Auditar inferencias contra or√°culos o conjuntos anotados (fact‚Äëlevel labels) y reportar intervalos de confianza y an√°lisis de error (tipo de error: omisi√≥n vs comisi√≥n/hallucination).

**Impacto conceptual:**
ETI emerge como patr√≥n que combina principios de la ingenier√≠a del conocimiento, la Web sem√°ntica (ontolog√≠as y PROV), y pr√°cticas modernas de ML/LM (RAG/GraphRAG, neuro‚Äësymbolic), ofreciendo un marco coherente para construir *sistemas de conocimiento confiables y explicables*.

---

*Estado:* Esta p√°gina contiene ahora la descripci√≥n de alcance y la estructura que seguir√° el trabajo cient√≠fico; el borrador final se completar√° despu√©s de ejecutar los experimentos y consolidar resultados (ver `_NET_STEPS.md` para seguimiento).

## Estructura del art√≠culo y placeholders de resultados

Para que este documento mantenga un estilo y rigor acad√©mico (tipo paper cient√≠fico), se ha reescrito la organizaci√≥n como sigue. **Importante:** no se inventan resultados; todas las secciones marcadas como *Resultados* o *Hallazgos* contienen placeholders que ser√°n completados solamente tras la ejecuci√≥n de los experimentos reproducibles y la recolecci√≥n de m√©tricas.

1. Introducci√≥n y motivaci√≥n ‚Äî exposici√≥n del problema y la hip√≥tesis ETI (ya incluida).  
2. Estado del arte ‚Äî revisi√≥n de RAG/GraphRAG, DIKW, provenance y t√©cnicas de construcci√≥n de KGs (referencias a continuaci√≥n).  
3. Dise√±o del patr√≥n ETI ‚Äî definici√≥n formal, arquitectura, artefactos y casos de uso (secci√≥n ETI).  
4. Metodolog√≠a experimental ‚Äî datasets (EDGAR/10‚ÄëK, BioASQ/PubMedQA, arXiv subsets, SOPs), configuraciones (Opik), pipelines (ET, ETI, variantes neuro‚Äësimb√≥licas), m√©tricas y criterios de evaluaci√≥n.  
   - *Placeholders:* tablas con descripci√≥n de datasets y configuraciones de experimentos (TBD).

### Dise√±o Experimental: Matriz de Componentes

Para evaluar el patr√≥n ETI, dise√±amos un espacio experimental multidimensional que combina diferentes componentes disponibles en Ungraph:

**Componentes del Espacio Experimental:**

- **Chunking**: {recursive, semantic, lexical, hierarchical}
- **Embedding**: {all-MiniLM-L6-v2, otros modelos HuggingFace}
- **Retrieval**: {basic, parent_child, hybrid, graph_enhanced_vector}
- **Inference**: {none, ner-only} (v0.1.0 implementa solo ner-only con spaCy)
- **Domain**: {finance, biomedical, scientific, general}

**Matriz de Experimentos Prioritarios:**

| ID | Chunking | Embedding | Retrieval | Inference | Domain | Prioridad |
|----|----------|-----------|-----------|-----------|--------|-----------|
| E1 | `recursive` | `all-MiniLM-L6-v2` | `basic` | `ner-only` | `finance` | üî¥ Alta |
| E2 | `recursive` | `all-MiniLM-L6-v2` | `parent_child` | `ner-only` | `finance` | üî¥ Alta |
| E3 | `semantic` | `all-MiniLM-L6-v2` | `hybrid` | `ner-only` | `biomedical` | üü° Media |
| E4 | `lexical` | `all-MiniLM-L6-v2` | `graph_enhanced_vector` | `ner-only` | `scientific` | üü° Media |
| E5 | `hierarchical` | `all-MiniLM-L6-v2` | `community_summary` | `ner-only` | `general` | üü¢ Baja |

**Ablation Studies (Control vs ETI):**

| Baseline | Variante | Diferencia | Objetivo |
|----------|----------|------------|----------|
| ET (sin I) | ETI (con I) | Fase Inference | Medir impacto de inferencia |
| `basic` retrieval | `parent_child` | Patr√≥n retrieval | Medir impacto de contexto |
| `recursive` chunking | `semantic` chunking | Estrategia chunking | Medir impacto de chunking |

**Nota**: Para release v0.1.0, solo se implementa `ner-only` (spaCy). Implementaciones LLM (`lm-only`, `hybrid`) est√°n documentadas como alternativas futuras (v0.2+) y ser√°n validadas experimentalmente.  
5. Experimentos y resultados ‚Äî comparativas control/ETI y ablations (LM‚Äëonly, symbolic‚Äëonly, neuro‚Äësymbolic).  
   - *Resultados (placeholder):* (i) inference accuracy ‚Äî TBD; (ii) QA‚ÄëF1 y recall@k ‚Äî TBD; (iii) tasas de hallucination y coste/latencia ‚Äî TBD.  
6. Discusi√≥n y limitaciones ‚Äî an√°lisis cualitativo de errores, impacto de trazabilidad (PROV) y consideraciones √©ticas.  
7. Conclusiones y trabajos futuros ‚Äî validaci√≥n de la hip√≥tesis ETI y roadmap experimental.

> Nota: Todas las figuras, tablas y valores num√©ricos se incluir√°n solamente despu√©s de ejecutar los experimentos mencionados y compilar los notebooks/Opik configs reproducibles. No se a√±adir√° ninguna cifra hasta ese momento.

## Referencias

1. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., & Riedel, S. (2020). Retrieval‚ÄëAugmented Generation for Knowledge‚ÄëIntensive NLP Tasks. arXiv:2005.11401. https://arxiv.org/abs/2005.11401

2. Peng, B., Zhu, Y., Liu, Y., Bo, X., Shi, H., Hong, C., & Tang, S. (2024). Graph Retrieval‚ÄëAugmented Generation: A Survey. arXiv:2408.08921. https://arxiv.org/abs/2408.08921

3. Neo4j, Inc. (2024). GraphRAG Patterns Catalog. https://graphrag.com/reference/

4. W3C Provenance Working Group. (2013). PROV‚ÄëOverview. W3C Note. https://www.w3.org/TR/prov-overview/

5. Zhong, L., Wu, J., Li, Q., & Peng, H. (2023). A Comprehensive Survey on Automatic Knowledge Graph Construction. arXiv:2302.05019. https://arxiv.org/abs/2302.05019

6. d'Avila Garcez, A., Gori, M., Lamb, L. C., Serafini, L., Spranger, M., & Tran, S. N. (2019). Neural‚ÄëSymbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning. arXiv:1905.06088. https://arxiv.org/abs/1905.06088

7. Rowley, J. (2007). The Wisdom Hierarchy: Representations of the DIKW Hierarchy. Journal of Information & Communication Science. https://doi.org/10.1177/0165551506070706

8. Ackoff, R. (1989). From Data to Wisdom. Journal of Applied Systems Analysis.

9. Zins, C. (2007). Conceptual Approaches for Defining Data, Information, and Knowledge. Journal of the American Society for Information Science and Technology, 58(4), 479‚Äì493. https://doi.org/10.1002/asi.20508

10. Miller, G. A. (1956). The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information. Psychological Review, 63(2), 81‚Äì97. https://doi.org/10.1037/h0043158

11. Thalmann, M., Souza, A. S., & Oberauer, K. (2019). How does chunking help working memory? Journal of Experimental Psychology. https://psycnet.apa.org/record/2018-18179-001

**BibTeX:** `article/references.bib` contiene las entradas BibTeX para las referencias listadas.

**Notas (enlaces directos):**
[1]: https://arxiv.org/abs/2005.11401
[2]: https://arxiv.org/abs/2408.08921
[3]: https://graphrag.com/reference/
[4]: https://www.w3.org/TR/prov-overview/
[5]: https://arxiv.org/abs/2302.05019
[6]: https://arxiv.org/abs/1905.06088
[7]: https://doi.org/10.1177/0165551506070706
[8]: (Ackoff 1989)
[9]: https://doi.org/10.1002/asi.20508
[10]: https://doi.org/10.1037/h0043158
[11]: https://psycnet.apa.org/record/2018-18179-001

---

*Estado:* Se ha a√±adido la bibliograf√≠a en formato APA numerada y un listado de enlaces directos; la BibTeX fuente est√° disponible en `article/references.bib`. Los placeholders de resultados esperan la ejecuci√≥n de experimentos reproducibles antes de su completado.