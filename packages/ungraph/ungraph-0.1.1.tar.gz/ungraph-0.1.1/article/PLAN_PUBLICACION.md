# Plan de Publicaci√≥n - Ungraph v0.1.0 (Release Completo ETI)

**Objetivo**: Preparar primera versi√≥n publicable del art√≠culo con implementaci√≥n completa del patr√≥n ETI (Extract-Transform-Inference).

**Principio**: Implementar fase de inferencia m√≠nima viable y organizar dise√±o experimental con matriz de componentes disponibles.

**Estado**: Este documento es el **faro principal** para todas las acciones del release v0.1.0. Toda la informaci√≥n relevante est√° consolidada aqu√≠.

**Estado Actual del Release v0.1.0**: ‚úÖ **IMPLEMENTACI√ìN Y DOCUMENTACI√ìN COMPLETAS** - Solo falta validaci√≥n final.

---

## üöÄ Gu√≠a R√°pida: Publicaci√≥n en TestPyPI

**Pasos esenciales para publicar en TestPyPI:**

1. **Preparar credenciales:**
   - Crear cuenta en https://test.pypi.org/account/register/
   - Generar API token en https://test.pypi.org/manage/account/#api-tokens
   - Configurar token: `export UV_PUBLISH_TOKEN="pypi-xxxxxxxxxxxxx"`

2. **Build del paquete:**
   ```bash
   uv build
   ```

3. **Publicar en TestPyPI:**
   ```bash
   uv publish --publish-url https://test.pypi.org/legacy/ --token $UV_PUBLISH_TOKEN dist/*
   ```

4. **Verificar instalaci√≥n desde TestPyPI:**
   ```bash
   pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ ungraph==0.1.0
   ```

**Nota:** Ver secci√≥n completa "Validaciones para PyPI Build" (l√≠nea 647) para checklist detallado.

---

## üìä An√°lisis: C√≥digo vs Documentaci√≥n

### ‚úÖ Lo que S√ç est√° implementado

1. **Extract (E)**: ‚úÖ
   - `LangChainDocumentLoaderService` - carga documentos
   - Soporte Markdown, TXT, Word
   - Detecci√≥n de encoding

2. **Transform (T)**: ‚úÖ
   - `ChunkingService` - m√∫ltiples estrategias
   - `EmbeddingService` - HuggingFace embeddings
   - Persistencia en Neo4j (File ‚Üí Page ‚Üí Chunk)

3. **B√∫squeda GraphRAG b√°sica**: ‚úÖ
   - Basic Retriever
   - Parent-Child Retriever
   - Hybrid Search
   - Metadata Filtering

4. **Arquitectura**: ‚úÖ
   - Clean Architecture implementada
   - Tests funcionando
   - API p√∫blica (`ungraph.ingest_document()`, `ungraph.search()`)

### ‚úÖ Lo que YA est√° implementado (Release Completo)

1. **Inference (I) expl√≠cita**: ‚úÖ COMPLETO
   - ‚úÖ Servicio de inferencia (interfaz + implementaci√≥n `SpacyInferenceService`)
   - ‚úÖ Extracci√≥n de facts/relations estructurada
   - ‚úÖ Generaci√≥n de facts simples (MENTIONS) y relaciones de co-ocurrencia
   - ‚úÖ Persistencia de facts en Neo4j

2. **PROV-O integrado**: ‚úÖ COMPLETO (b√°sico)
   - ‚úÖ Trazabilidad b√°sica (wasDerivedFrom) implementada
   - ‚úÖ Integraci√≥n con c√≥digo principal
   - ‚úÖ Trazabilidad end-to-end autom√°tica (Fact ‚Üí Chunk ‚Üí Document)

3. **Experimentos reales**: üü¢ BAJO (puede ser planificado)
   - ‚ö†Ô∏è Solo demos con datos mock
   - ‚ùå No hay datasets reales (EDGAR, BioASQ, etc.)
   - ‚ùå No hay m√©tricas calculadas
   - **Para release**: Dise√±o experimental completo con matriz de componentes

4. **Ontolog√≠a formal**: üü¢ BAJO
   - ‚ùå No existe `docs/ontology.md` formal
   - ‚ùå No existe `docs/ontology.owl`
   - ‚ö†Ô∏è Solo estructura impl√≠cita en c√≥digo
   - **Para release**: Documentaci√≥n m√≠nima de ontolog√≠a File/Page/Chunk

---

## üéØ Estrategia: Implementaci√≥n M√≠nima Viable de ETI

### Objetivo del Release

**Implementar fase de Inferencia m√≠nima viable** que permita:
1. Extracci√≥n de entidades y relaciones b√°sicas desde chunks
2. Generaci√≥n de tripletas (subject-predicate-object) con confianza
3. Persistencia de facts en Neo4j como nodos/relaciones
4. Trazabilidad b√°sica con PROV-O (wasDerivedFrom)

### Componentes Disponibles para Matriz Experimental

**Fase Extract (E)**: ‚úÖ Completo
- `LangChainDocumentLoaderService` - Markdown, TXT, Word
- Detecci√≥n de encoding autom√°tica

**Fase Transform (T)**: ‚úÖ Completo
- **Chunking**: 
  - RecursiveCharacter (default)
  - Smart chunking: Fixed, Lexical, Semantic, Hierarchical
  - Estrategias: Character, Recursive, Token, MarkdownHeader, HTMLHeader, PythonCode, Semantic, LanguageSpecific
- **Embeddings**: 
  - HuggingFace (all-MiniLM-L6-v2 por defecto, configurable)
  - Dimensiones: 384 (default), otros modelos configurables
- **Persistencia**: Neo4j con patr√≥n FILE_PAGE_CHUNK

**Fase Inference (I)**: ‚úÖ COMPLETO
- ‚úÖ Interfaz `InferenceService` en `domain/services/`
- ‚úÖ Implementaci√≥n b√°sica `SpacyInferenceService` en `infrastructure/services/`
- ‚úÖ Implementaci√≥n √∫nica: NER-only (spaCy) para v0.1.0
- ‚ö†Ô∏è Opciones futuras: LM-only (LLM), Hybrid (v0.2.0+)

**Retrieval Patterns**: ‚úÖ Disponibles
- Basic Retriever
- Parent-Child Retriever
- Hybrid Search (text + vector)
- Metadata Filtering
- Graph-Enhanced Vector Search (requiere GDS)
- Local Retriever (requiere GDS)
- Community Summary Retriever (requiere GDS)

---

## üìä Matriz de Experimentaci√≥n: Espacio de Componentes

### Componentes Disponibles para Combinar

| Componente | Tipo | Opciones Disponibles | Estado |
|------------|------|---------------------|--------|
| **Chunking** | Estrategia | `recursive`, `character`, `token`, `markdown_header`, `html_header`, `python_code`, `semantic`, `language_specific` | ‚úÖ |
| **Chunking Smart** | Modo | `fixed`, `lexical`, `semantic`, `hierarchical` | ‚úÖ |
| **Embedding Model** | Modelo | `all-MiniLM-L6-v2` (default), otros HuggingFace | ‚úÖ |
| **Retrieval Pattern** | Patr√≥n | `basic`, `parent_child`, `hybrid`, `metadata_filtering`, `graph_enhanced_vector`, `local`, `community_summary` | ‚úÖ |
| **Inference Type** | Tipo | `ner-only` (spaCy) | ‚úÖ Implementado (v0.1.0) |
| **Domain** | Dominio | `finance`, `biomedical`, `scientific`, `general` | ‚ö†Ô∏è Planificado |

### Matriz de Experimentaci√≥n (Espacio de B√∫squeda)

**Dimensiones del espacio experimental:**

```
Experimento = f(Chunking, Embedding, Retrieval, Inference, Domain)
```

**Combinaciones prioritarias para Release v0.1.0:**

| ID | Chunking | Embedding | Retrieval | Inference | Domain | Prioridad |
|----|----------|-----------|-----------|-----------|--------|-----------|
| E1 | `recursive` | `all-MiniLM-L6-v2` | `basic` | `ner-only` | `finance` | üî¥ Alta |
| E2 | `recursive` | `all-MiniLM-L6-v2` | `parent_child` | `ner-only` | `finance` | üî¥ Alta |
| E3 | `semantic` | `all-MiniLM-L6-v2` | `hybrid` | `ner-only` | `biomedical` | üü° Media |
| E4 | `lexical` | `all-MiniLM-L6-v2` | `graph_enhanced_vector` | `ner-only` | `scientific` | üü° Media |
| E5 | `hierarchical` | `all-MiniLM-L6-v2` | `community_summary` | `ner-only` | `general` | üü¢ Baja |

**Nota**: Para release v0.1.0, solo se implementa `ner-only` (spaCy). 
Implementaciones LLM (`lm-only`, `hybrid`) est√°n documentadas como alternativas 
futuras (ver referencia a Neo4j LLM Graph Builder en c√≥digo).

**Ablation Studies (Control vs ETI):**

| Baseline | Variante | Diferencia | Objetivo |
|----------|----------|------------|----------|
| ET (sin I) | ETI (con I) | Fase Inference | Medir impacto de inferencia |
| `basic` retrieval | `parent_child` | Patr√≥n retrieval | Medir impacto de contexto |
| `recursive` chunking | `semantic` chunking | Estrategia chunking | Medir impacto de chunking |

**Nota**: Estudios de ablaci√≥n con diferentes tipos de inferencia (`lm-only`, `hybrid`) 
quedan para futuras versiones. Release v0.1.0 implementa solo `ner-only` (spaCy).

### Dise√±o Experimental: Matriz de Factores

**Factores principales (variables independientes):**
1. **Chunking Strategy**: {recursive, semantic, lexical, hierarchical}
2. **Retrieval Pattern**: {basic, parent_child, hybrid, graph_enhanced}
3. **Inference Type**: {none, ner-only} (v0.1.0 implementa solo ner-only con spaCy)
4. **Domain**: {finance, biomedical, scientific, general}

**Variables dependientes (m√©tricas):**
- **Retrieval**: recall@k, MRR, precision@k
- **QA**: F1-score (micro/macro), exact match
- **Inference**: precision, recall, F1 sobre facts extra√≠dos
- **Hallucination**: tasa de facts no groundeados
- **Performance**: latencia (ms), throughput (docs/sec)

**Hip√≥tesis experimentales:**
- **H1**: ETI (con Inference) > ET (sin Inference) en recall@k y QA-F1
- **H2**: Semantic chunking > Recursive chunking para dominios t√©cnicos
- **H3**: Parent-Child retrieval > Basic retrieval para preguntas que requieren contexto
- **H4**: [Futuro] Hybrid inference > LM-only para precisi√≥n de facts extra√≠dos

---

## üìã Tareas Cr√≠ticas: Implementaci√≥n + Documentaci√≥n

### üî¥ PRIORIDAD 0: Implementar Fase de Inferencia con spaCy (6-8 horas)

**Objetivo**: Crear servicio de inferencia m√≠nima viable usando spaCy, siguiendo Clean Architecture estricta.

**Alcance del Release (Closure)**: ‚úÖ COMPLETO
- ‚úÖ Implementaci√≥n √∫nica con spaCy (NER-only)
- ‚úÖ Extracci√≥n de entidades b√°sicas (PERSON, ORG, LOC, etc.)
- ‚úÖ Generaci√≥n de facts simples (MENTIONS)
- ‚úÖ Persistencia en Neo4j
- ‚úÖ Trazabilidad b√°sica PROV-O
- ‚úÖ LLM como alternativa futura (documentado en c√≥digo, no implementado)

#### Arquitectura: Patr√≥n Clean Architecture

**Estructura siguiendo el patr√≥n existente:**

```
domain/
  ‚îú‚îÄ‚îÄ services/
  ‚îÇ   ‚îî‚îÄ‚îÄ inference_service.py          # Interfaz (ABC)
  ‚îú‚îÄ‚îÄ entities/
  ‚îÇ   ‚îú‚îÄ‚îÄ fact.py                       # Entidad Fact
  ‚îÇ   ‚îú‚îÄ‚îÄ entity.py                      # Entidad Entity
  ‚îÇ   ‚îî‚îÄ‚îÄ relation.py                   # Entidad Relation
  ‚îî‚îÄ‚îÄ value_objects/
      ‚îî‚îÄ‚îÄ provenance.py                 # Value Object

application/
  ‚îî‚îÄ‚îÄ use_cases/
      ‚îî‚îÄ‚îÄ ingest_document.py            # Modificar: a√±adir fase Inference

infrastructure/
  ‚îú‚îÄ‚îÄ services/
  ‚îÇ   ‚îî‚îÄ‚îÄ spacy_inference_service.py    # Implementaci√≥n con spaCy
  ‚îî‚îÄ‚îÄ repositories/
      ‚îî‚îÄ‚îÄ neo4j_chunk_repository.py    # Modificar: a√±adir save_facts()
```

#### Componentes a Implementar

1. **Interfaz de dominio** (`InferenceService`):
   ```python
   # src/domain/services/inference_service.py
   class InferenceService(ABC):
       """
       Interfaz para servicios de inferencia.
       
       Esta interfaz define las operaciones para extraer entidades, relaciones
       y facts desde chunks de texto.
       
       Nota sobre implementaciones alternativas:
       - La extracci√≥n de entidades puede realizarse tambi√©n usando LLMs
         (OpenAI, Claude, Gemini, etc.) para obtener mayor flexibilidad y
         capacidad de extraer relaciones complejas. Para referencia, ver
         el trabajo de Neo4j con LLM Graph Builder:
         https://neo4j.com/labs/genai-ecosystem/llm-graph-builder/
       
       La implementaci√≥n actual usa spaCy (NER-only) como soluci√≥n m√≠nima
       viable para el release v0.1.0. Implementaciones LLM pueden a√±adirse
       en futuras versiones siguiendo el mismo patr√≥n de arquitectura.
       """
       
       @abstractmethod
       def extract_entities(self, chunk: Chunk) -> List[Entity]:
           """Extrae entidades nombradas del chunk"""
           pass
       
       @abstractmethod
       def extract_relations(self, chunk: Chunk) -> List[Relation]:
           """Extrae relaciones entre entidades"""
           pass
       
       @abstractmethod
       def infer_facts(self, chunk: Chunk) -> List[Fact]:
           """
           Genera facts estructurados (subject-predicate-object).
           
           Returns:
               Lista de facts con subject, predicate, object, confidence y provenance
           """
           pass
   ```

2. **Entidades de dominio**:
   - `Fact`: subject, predicate, object, confidence (0.0-1.0), provenance_ref
   - `Entity`: name, type (PERSON, ORGANIZATION, LOCATION, etc.), mentions
   - `Relation`: source_entity, target_entity, relation_type, confidence

3. **Implementaci√≥n con spaCy** (√öNICA para release):
   ```python
   # src/infrastructure/services/spacy_inference_service.py
   class SpacyInferenceService(InferenceService):
       """
       Implementaci√≥n de InferenceService usando spaCy para NER.
       
       Esta es la implementaci√≥n de referencia para el release v0.1.0.
       Usa spaCy para extracci√≥n de entidades nombradas (NER) y genera
       facts simples del tipo (chunk_id, "MENTIONS", entity_name).
       
       Nota: Para extracci√≥n m√°s avanzada con LLMs, ver documentaci√≥n
       de InferenceService y referencia a Neo4j LLM Graph Builder.
       """
   ```

4. **Caso de uso actualizado**:
   ```python
   # src/application/use_cases/ingest_document.py
   class IngestDocumentUseCase:
       def __init__(
           self,
           ...,
           inference_service: Optional[InferenceService] = None  # Nueva dependencia
       ):
           ...
       
       def execute(...):
           # 1. Extract
           document = self.document_loader_service.load(...)
           # 2. Transform
           chunks = self.chunking_service.chunk(...)
           embeddings = self.embedding_service.generate_embeddings_batch(...)
           # 3. Inference (NUEVO)
           if self.inference_service:
               facts = []
               for chunk in chunks:
                   chunk_facts = self.inference_service.infer_facts(chunk)
                   facts.extend(chunk_facts)
               # Persistir facts
               self.chunk_repository.save_facts(facts)
   ```

5. **Persistencia en Neo4j**:
   - Crear nodos `Fact` con propiedades: subject, predicate, object, confidence
   - Crear relaciones `DERIVED_FROM` entre Fact y Chunk (provenance)
   - Crear nodos `Entity` y relaciones `MENTIONS` entre Chunk y Entity

#### Tareas Detalladas (Seguir Clean Architecture)

1. **Crear interfaz en domain** (1.5 horas):
   - `src/domain/services/inference_service.py`
   - M√©todos: `extract_entities()`, `extract_relations()`, `infer_facts()`
   - **Documentar**: LLM como alternativa futura, referencia a Neo4j LLM Graph Builder
   - Retornar entidades `Fact`, `Entity`, `Relation`

2. **Crear entidades de dominio** (1 hora):
   - `src/domain/entities/fact.py` - Fact con subject, predicate, object, confidence, provenance
   - `src/domain/entities/entity.py` - Entity con name, type, mentions
   - `src/domain/entities/relation.py` - Relation entre entidades
   - `src/domain/value_objects/provenance.py` - Provenance info (wasDerivedFrom, timestamp)

3. **Implementar servicio spaCy** (3-4 horas):
   - `src/infrastructure/services/spacy_inference_service.py`
   - Usar spaCy para NER (modelo `en_core_web_sm` o similar)
   - Extraer entidades: PERSON, ORG, LOC, GPE, etc.
   - Generar facts: (chunk_id, "MENTIONS", entity_name)
   - Generar relaciones simples entre entidades co-ocurrentes
   - **Documentar en c√≥digo**: LLM como alternativa futura

4. **Modificar caso de uso** (1 hora):
   - `src/application/use_cases/ingest_document.py`
   - A√±adir `inference_service` como dependencia opcional
   - Llamar a `inference_service.infer_facts()` despu√©s de chunking
   - Orquestar persistencia de facts

5. **Modificar repository** (1 hora):
   - `src/infrastructure/repositories/neo4j_chunk_repository.py`
   - A√±adir m√©todo `save_facts(facts: List[Fact])`
   - Crear nodos Fact y Entity en Neo4j
   - Crear relaciones DERIVED_FROM y MENTIONS

6. **Actualizar dependencies.py** (0.5 horas):
   - `src/application/dependencies.py`
   - Crear factory para `SpacyInferenceService`
   - Inyectar en `IngestDocumentUseCase`

7. **Tests** (1 hora):
   - Tests unitarios de `SpacyInferenceService`
   - Tests de integraci√≥n con pipeline completo
   - Validar que facts se persisten correctamente

**Archivos a crear/modificar**:
- `src/domain/services/inference_service.py` (nuevo) - Interfaz con documentaci√≥n LLM
- `src/domain/entities/fact.py` (nuevo)
- `src/domain/entities/entity.py` (nuevo)
- `src/domain/entities/relation.py` (nuevo)
- `src/infrastructure/services/spacy_inference_service.py` (nuevo) - Implementaci√≥n √∫nica
- `src/application/use_cases/ingest_document.py` (modificar)
- `src/infrastructure/repositories/neo4j_chunk_repository.py` (modificar: a√±adir `save_facts()`)
- `src/application/dependencies.py` (modificar: factory para inference service)

---

### üî¥ PRIORIDAD 1: Corregir Referencias (2 horas)

**Problema**: Referencias duplicadas, faltantes, formato inconsistente.

**Acciones**:
1. Corregir l√≠nea 104 de `article/ungraph.md`:
   - Cambiar `[2]` duplicado ‚Üí `[3]` para Neo4j GraphRAG
2. A√±adir a `article/references.bib`:
   ```bibtex
   @misc{neo4j2024graphrag,
     title={GraphRAG Patterns Catalog},
     author={{Neo4j, Inc.}},
     year={2024},
     howpublished={\url{https://graphrag.com/reference/}},
     note={Accessed: 2025-12-25}
   }
   ```
3. Renumerar referencias posteriores
4. Completar DOIs faltantes (buscar en Google Scholar)
5. Estandarizar formato: num√©rico `[1]`, `[2]` en todo el documento

**Archivos**:
- `article/ungraph.md` (l√≠neas 102-106, 137-142)
- `article/references.bib`

---

### üî¥ PRIORIDAD 2: Reescribir Abstract (1 hora)

**Problema**: Abstract actual es muy breve y no sigue estructura IMRAD.

**Nuevo abstract** (150-200 palabras):
```
Las arquitecturas modernas de Retrieval-Augmented Generation (RAG) enfrentan 
desaf√≠os en la construcci√≥n de grafos de conocimiento confiables y trazables. 
Este trabajo propone el patr√≥n Extract-Transform-Inference (ETI) como evoluci√≥n 
del tradicional ETL, a√±adiendo una fase expl√≠cita de inferencia que genera hechos 
normalizados con trazabilidad PROV-O. 

Presentamos una implementaci√≥n parcial de ETI en la librer√≠a Ungraph, que 
construye Lexical Graphs sobre Neo4j integrando chunking estrat√©gico, embeddings 
vectoriales y patrones GraphRAG b√°sicos. La implementaci√≥n actual cubre las fases 
Extract y Transform; la fase Inference se propone conceptualmente y se valida 
mediante demos con datos mock.

[Para versi√≥n completa:] Evaluamos la efectividad mediante experimentos reproducibles 
en cuatro dominios (financiero, biom√©dico, cient√≠fico y general), comparando pipelines 
control (ET) versus ETI en m√©tricas de recuperaci√≥n (recall@k, MRR), calidad de QA 
(F1), precisi√≥n de inferencia y tasa de hallucination. [Resultados pendientes de 
ejecuci√≥n experimental].

El patr√≥n ETI proporciona un marco coherente para construir sistemas de conocimiento 
confiables, integrando principios de ingenier√≠a del conocimiento, Web sem√°ntica 
(ontolog√≠as, PROV) y neuro-symbolic computing.
```

**Archivo**: `article/ungraph.md` (l√≠neas 3-4)

---

### üü° PRIORIDAD 3: Documentar Matriz de Experimentaci√≥n (2 horas)

**Objetivo**: A√±adir secci√≥n de dise√±o experimental con matriz de componentes al art√≠culo.

**Acciones**:
1. A√±adir secci√≥n "Dise√±o Experimental" despu√©s de "Metodolog√≠a experimental":
   ```markdown
   ## Dise√±o Experimental: Matriz de Componentes
   
   Para evaluar el patr√≥n ETI, dise√±amos un espacio experimental multidimensional 
   que combina diferentes componentes disponibles en Ungraph:
   
   ### Componentes del Espacio Experimental
   
   - **Chunking**: {recursive, semantic, lexical, hierarchical}
   - **Embedding**: {all-MiniLM-L6-v2, otros modelos HuggingFace}
   - **Retrieval**: {basic, parent_child, hybrid, graph_enhanced_vector}
   - **Inference**: {none, lm-only, ner-only, hybrid}
   - **Domain**: {finance, biomedical, scientific, general}
   
   ### Matriz de Experimentos Prioritarios
   
   [Tabla con combinaciones E1-E5 de la matriz anterior]
   
   ### Ablation Studies
   
   [Tabla con estudios de ablaci√≥n: ET vs ETI, chunking strategies, etc.]
   ```

2. Actualizar secci√≥n "Metodolog√≠a experimental" con referencia a matriz

**Archivo**: `article/ungraph.md`

---

### üü° PRIORIDAD 4: A√±adir Research Questions (1 hora)

**Problema**: No hay RQs expl√≠citas (requerido para paper cient√≠fico).

**Acciones**:
1. A√±adir secci√≥n antes de "Metodolog√≠a experimental":
   ```markdown
   ## Research Questions e Hip√≥tesis
   
   ### Research Questions
   
   **RQ1: Efectividad de la Fase de Inferencia**
   ¬øA√±adir una fase expl√≠cita de inferencia (I) mejora la calidad de recuperaci√≥n y 
   respuesta de preguntas comparado con pipelines que solo realizan extracci√≥n y 
   transformaci√≥n (ET)?
   
   **RQ2: Tipos de Inferencia por Dominio**
   ¬øQu√© tipo de inferencia (LM-only, symbolic-only, neuro-symbolic) es m√°s efectiva 
   para diferentes dominios de conocimiento (financiero, biom√©dico, cient√≠fico, general)?
   
   **RQ3: Trade-off Trazabilidad vs Performance**
   ¬øLa trazabilidad completa con PROV-O mejora la confianza y explicabilidad del sistema 
   sin sacrificar significativamente el rendimiento (latencia, throughput)?
   
   **Nota**: Estas research questions guiar√°n los experimentos futuros una vez completada 
   la implementaci√≥n de la fase Inference.
   ```

**Archivo**: `article/ungraph.md` (nueva secci√≥n)

---

### üü° PRIORIDAD 5: Formalizar Patr√≥n ETI (2 horas)

**Problema**: Falta definici√≥n matem√°tica formal.

**Acciones**:
1. A√±adir despu√©s de l√≠nea 111:
   ```markdown
   ### Definici√≥n Formal del Patr√≥n ETI
   
   **Definici√≥n 1 (Pipeline ETI):**
   Un pipeline ETI es una tupla P = (E, T, I, O, M) donde:
   
   - **E (Extractors)**: Conjunto de extractores {e‚ÇÅ, e‚ÇÇ, ..., e‚Çô} donde cada 
     e·µ¢: Sources ‚Üí Documents produce documentos estructurados con metadatos.
   
   - **T (Transformers)**: Conjunto de transformadores {t‚ÇÅ, t‚ÇÇ, ..., t‚Çò} donde cada 
     t‚±º: Documents ‚Üí Chunks produce chunks con embeddings y anotaciones sem√°nticas.
   
   - **I (Inference)**: Conjunto de modelos de inferencia {i‚ÇÅ, i‚ÇÇ, ..., i‚Çñ} donde cada 
     i‚Çñ: Chunks ‚Üí (Facts ‚à™ Relations ‚à™ Explanations) genera artefactos de conocimiento 
     con se√±ales de confianza y trazabilidad.
   
   - **O (Ontology)**: Esquema formal que define tipos de entidades, relaciones permitidas, 
     constraints y mapeos a vocabularios est√°ndar (schema.org, PROV-O).
   
   - **M (Metadata)**: Estructura PROV-O que registra provenance de cada artefacto, 
     incluyendo: entidades derivadas, actividades ejecutadas, agentes responsables y timestamps.
   
   **Propiedades del Pipeline ETI:**
   1. **Trazabilidad**: Todo fact f ‚àà Facts tiene prov:wasDerivedFrom apuntando a su chunk fuente
   2. **Validabilidad**: Todo fact f puede ser verificado contra source s mediante provenance chain
   3. **Composabilidad**: Pipelines ETI pueden encadenarse (salida de I‚Çñ ‚Üí entrada de E·µ¢‚Çä‚ÇÅ)
   4. **Reproducibilidad**: Dado mismo input + config + seed ‚Üí mismo output
   ```

2. A√±adir tabla comparativa ETL vs ETI (simple, en markdown)

**Archivo**: `article/ungraph.md`

---

## üü¢ Tareas Opcionales (Solo si hay tiempo)

### Opcional 1: Consolidar Documentaci√≥n en `docs/` (1-2 horas)
**Objetivo**: Eliminar redundancias y consolidar documentaci√≥n

**Archivos a consolidar/eliminar**:
- `docs/theory/GRAPHRAG_AVANZADO.md` ‚Üí Consolidar contenido relevante en `docs/theory/graphrag.md` o eliminar si es solo gu√≠a futura
- `docs/validation/` ‚Üí Consolidar m√∫ltiples archivos en uno solo (`validation_summary.md` + `README.md` son suficientes)
- `docs/examples/` ‚Üí Revisar y consolidar ejemplos duplicados

**Criterio**: Mantener solo documentaci√≥n que aporta valor √∫nico. Eliminar gu√≠as futuras o contenido duplicado.

### Opcional 2: Crear Tabla de Datasets (30 min)
- Crear `article/experiments/datasets.csv` con placeholders
- Mencionar que son datasets planificados

### Opcional 3: A√±adir Diagrama ASCII (30 min)
- Diagrama simple de arquitectura ETI (ASCII art)
- Mostrar flujo Extract ‚Üí Transform ‚Üí Inference

### Opcional 4: Documentar Ontolog√≠a B√°sica (1 hora)
- Crear `docs/ontology.md` m√≠nimo
- Describir File/Page/Chunk/Fact (ya est√° en c√≥digo)
- NO crear OWL completo (no necesario para v0.1.0)

---

## ‚úÖ Lo que S√ç hacer para Release

1. ‚úÖ **Implementar fase Inference m√≠nima viable** - requerido para release completo
2. ‚úÖ **Integrar PROV-O b√°sico** - trazabilidad m√≠nima (wasDerivedFrom)
3. ‚úÖ **Dise√±ar matriz experimental** - documentar espacio de experimentaci√≥n
4. ‚úÖ **Crear servicios de inferencia** - siguiendo Clean Architecture
5. ‚úÖ **Documentar ontolog√≠a b√°sica** - File/Page/Chunk/Fact

## ‚ùå Lo que NO hacer (fuera de scope v0.1.0)

1. ‚ùå **NO crear PROV-O completo** - solo integraci√≥n b√°sica
2. ‚ùå **NO ejecutar experimentos completos** - solo dise√±o y demos
3. ‚ùå **NO crear OWL completo** - solo documentaci√≥n b√°sica
4. ‚ùå **NO implementar razonamiento simb√≥lico avanzado** - solo extracci√≥n b√°sica

---

## üìÖ Timeline Estimado

**Total: 10-12 horas de trabajo** (reducido al enfocarse solo en spaCy)

### Fase 1: Implementaci√≥n (6-8 horas)
- D√≠a 1 (1.5h): Prioridad 0 - Interfaz domain con documentaci√≥n LLM
- D√≠a 1 (1h): Prioridad 0 - Entidades domain
- D√≠a 1-2 (3-4h): Prioridad 0 - Implementaci√≥n spaCy
- D√≠a 2 (1h): Prioridad 0 - Modificar caso de uso
- D√≠a 2 (1h): Prioridad 0 - Modificar repository
- D√≠a 2 (0.5h): Prioridad 0 - Actualizar dependencies.py
- D√≠a 2 (1h): Prioridad 0 - Tests

### Fase 2: Documentaci√≥n (6-8 horas)
- D√≠a 3 (2h): Prioridad 1 (Referencias)
- D√≠a 3 (1h): Prioridad 2 (Abstract)
- D√≠a 4 (2h): Prioridad 3 (Matriz experimental)
- D√≠a 4 (1h): Prioridad 4 (Research Questions)
- D√≠a 5 (2h): Prioridad 5 (Formalizaci√≥n ETI)

### Fase 3: Validaci√≥n (2-4 horas)
- D√≠a 5-6 (2-4h): Tests end-to-end, demos, validaci√≥n

---

## ‚úÖ Checklist Final - Release v0.1.0

Antes de considerar "publicable":

### Implementaci√≥n (Prioridad 0) - ‚úÖ COMPLETO
- [x] Interfaz `InferenceService` creada en domain (con documentaci√≥n LLM como futuro)
- [x] Entidades `Fact`, `Entity`, `Relation` creadas
- [x] Implementaci√≥n `SpacyInferenceService` (√∫nica para v0.1.0)
- [x] Integraci√≥n con `IngestDocumentUseCase`
- [x] M√©todo `save_facts()` en repository
- [x] Factory en `dependencies.py`
- [x] Persistencia de facts en Neo4j
- [x] Trazabilidad PROV-O b√°sica (wasDerivedFrom)
- [x] Tests unitarios e integraci√≥n
- [x] C√≥digo sigue Clean Architecture estricta

### Documentaci√≥n (Prioridades 1-5) - ‚úÖ COMPLETO
- [x] Referencias corregidas y validadas (Prioridad 1)
  - Corregido [2] duplicado ‚Üí [3] para Neo4j GraphRAG
  - A√±adida entrada en `references.bib`
  - Referencias renumeradas correctamente (1-11)
- [x] Abstract reescrito (150-200 palabras, IMRAD) (Prioridad 2)
- [x] Secci√≥n "Matriz de Experimentaci√≥n" a√±adida (Prioridad 3)
- [x] Research Questions expl√≠citas (Prioridad 4)
  - RQ1: Efectividad de la Fase de Inferencia
  - RQ2: Tipos de Inferencia por Dominio
  - RQ3: Trade-off Trazabilidad vs Performance
- [x] Definici√≥n formal de ETI a√±adida (Prioridad 5)
- [x] Tabla comparativa ETL vs ETI (Prioridad 5)
- [x] Documento `article/ungraph.md` revisado para consistencia

### Validaci√≥n - ‚è≥ PENDIENTE

#### Validaciones Funcionales
- [ ] Pipeline ETI completo funciona end-to-end (verificar con datos reales)
- [ ] Facts se persisten correctamente en Neo4j (verificar con datos reales)
- [ ] Tests pasan sin errores (verificar configuraci√≥n pytest)
- [ ] Documentaci√≥n revisada y sin contradicciones

#### Validaciones para PyPI Build

**1. Tests y Calidad de C√≥digo**
- [x] ‚úÖ Corregido `pytest.ini` (removidas opciones de timeout problem√°ticas)
- [x] ‚úÖ Tests b√°sicos funcionan: `pytest tests/test_inference_service.py::TestFactEntity::test_fact_creation -v` (PASSED)
- [x] ‚úÖ Imports b√°sicos funcionan: `from domain.entities.fact import Fact` (OK)
- [x] ‚ö†Ô∏è Script de integraci√≥n ejecutado: `python scripts/test_eti_integration.py` (2/3 pruebas pasadas, falta spaCy)
- [ ] Ejecutar todos los tests unitarios: `pytest tests/ -m unit -v` (requiere instalar dependencias)
- [ ] Verificar que las dependencias opcionales funcionan (`ungraph[infer]`, `ungraph[gds]`)

**2. Build del Paquete**
- [ ] Verificar `pyproject.toml` tiene versi√≥n correcta (0.1.0)
- [ ] Verificar que todos los paquetes en `src/` est√°n incluidos en `[tool.hatch.build.targets.wheel]`
- [ ] Build local: `uv build` (genera dist/ungraph-0.1.0.tar.gz y .whl)
- [ ] Verificar que el build no tiene errores ni warnings
- [ ] Verificar que el archivo .whl contiene todos los m√≥dulos necesarios (usar `scripts/verify_wheel.py`)

**3. Instalaci√≥n y Verificaci√≥n**
- [ ] Instalaci√≥n limpia desde wheel: `uv pip install dist/ungraph-0.1.0-py3-none-any.whl`
- [ ] Verificar que `ungraph` se puede importar: `python -c "import ungraph"`
- [ ] Verificar que las entidades se pueden importar: `from ungraph.domain.entities import Fact, Entity, Relation`
- [ ] Verificar que los servicios se pueden importar: `from ungraph.domain.services import InferenceService`
- [ ] Verificar que el caso de uso funciona: `from ungraph.application.use_cases import IngestDocumentUseCase`
- [ ] Verificar instalaci√≥n con extras: `uv pip install dist/ungraph-0.1.0-py3-none-any.whl[infer]`
- [ ] Ejecutar script de verificaci√≥n: `python scripts/verify_installation.py`

**4. Tests Post-Instalaci√≥n**
- [ ] Crear entorno virtual limpio: `python -m venv test_env`
- [ ] Activar entorno: `test_env\Scripts\activate` (Windows) o `source test_env/bin/activate` (Linux/Mac)
- [ ] Instalar desde wheel: `uv pip install dist/ungraph-0.1.0-py3-none-any.whl`
- [ ] Ejecutar tests b√°sicos en entorno limpio: `pytest tests/ -m unit -v`
- [ ] Verificar que las dependencias opcionales se instalan correctamente: `uv pip install dist/ungraph-0.1.0-py3-none-any.whl[infer]`

**5. TestPyPI (Recomendado antes de PyPI oficial)**

**Preparaci√≥n:**
- [x] ‚úÖ Crear cuenta en TestPyPI: https://test.pypi.org/account/register/
- [x] ‚úÖ Generar API token en TestPyPI: https://test.pypi.org/manage/account/#api-tokens
- [ ] Configurar credenciales (opci√≥n 1 - archivo `~/.pypirc`):
  ```ini
  [distutils]
  index-servers = testpypi

  [testpypi]
  repository = https://test.pypi.org/legacy/
  username = __token__
  password = pypi-xxxxxxxxxxxxx  # Token de TestPyPI
  ```
- [ ] O configurar variable de entorno (opci√≥n 2):
  ```bash
  export UV_PUBLISH_TOKEN="pypi-xxxxxxxxxxxxx"  # Token de TestPyPI
  export UV_PUBLISH_URL="https://test.pypi.org/legacy/"
  ```

**Publicaci√≥n:**
- [x] ‚úÖ Build del paquete: `uv build` (completado)
- [x] ‚úÖ Verificar archivos generados en `dist/`: `ungraphx-0.1.0-py3-none-any.whl` y `ungraphx-0.1.0.tar.gz`
- [x] ‚úÖ Subir a TestPyPI usando `uv`:
  ```bash
  uv publish --publish-url https://test.pypi.org/legacy/ --token $env:UV_PUBLISH_TOKEN dist/ungraphx-*
  ```
  **Nota:** Se public√≥ como `ungraphx` porque `ungraph` ya existe en TestPyPI (pertenece a otro usuario)
- [x] ‚úÖ Verificar publicaci√≥n en: https://test.pypi.org/project/ungraphx/

**Verificaci√≥n Post-Publicaci√≥n:**
- [ ] Crear entorno virtual limpio para prueba:
  ```bash
  python -m venv test_env
  test_env\Scripts\activate  # Windows
  # source test_env/bin/activate  # Linux/Mac
  ```
- [ ] Instalar desde TestPyPI (usar nombre temporal `ungraphx`):
  ```bash
  pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ ungraphx==0.1.0
  ```
  (Nota: `--extra-index-url` necesario porque TestPyPI no tiene todas las dependencias)
- [ ] Verificar instalaci√≥n: `python -c "import ungraphx; print(ungraphx.__version__)"`
- [ ] Verificar imports cr√≠ticos: `python scripts/verify_installation.py`
- [ ] Verificar que README.md se renderiza correctamente en TestPyPI

**6. PyPI Oficial (Despu√©s de validar TestPyPI)**

**Preparaci√≥n:**
- [x] ‚úÖ Verificar que `ungraph` NO existe en PyPI oficial (verificado: ‚úÖ DISPONIBLE)
- [ ] Crear cuenta en PyPI oficial: https://pypi.org/account/register/ (si no existe)
- [ ] Generar API token en PyPI oficial: https://pypi.org/manage/account/#api-tokens
- [ ] Configurar token: `$env:UV_PUBLISH_TOKEN="pypi-token-pypi-oficial"`

**Publicaci√≥n en PyPI Oficial:**
- [ ] Verificar que `pyproject.toml` tiene `name = "ungraph"` (nombre original restaurado)
- [ ] Build del paquete: `uv build`
- [ ] Verificar archivos generados: `ungraph-0.1.0-py3-none-any.whl` y `ungraph-0.1.0.tar.gz`
- [ ] Publicar en PyPI oficial:
  ```bash
  uv publish --token $env:UV_PUBLISH_TOKEN dist/ungraph-*
  ```
  (Sin `--publish-url` para usar PyPI oficial por defecto)
- [ ] Verificar publicaci√≥n en: https://pypi.org/project/ungraph/
- [ ] Instalar desde PyPI oficial: `pip install ungraph==0.1.0`
- [ ] Verificar instalaci√≥n y funcionalidad completa

**6. Documentaci√≥n del Paquete**
- [ ] Verificar que README.md est√° completo y actualizado
- [ ] Verificar que LICENSE est√° presente
- [ ] Verificar que CHANGELOG.md existe (opcional pero recomendado)
- [ ] Verificar que las dependencias est√°n correctamente especificadas
- [ ] Verificar que los extras opcionales est√°n documentados

**7. Validaci√≥n Final Pre-Release**
- [ ] Verificar que la versi√≥n en `pyproject.toml` coincide con el release
- [ ] Verificar que no hay archivos temporales o de desarrollo en el build
- [ ] Verificar que los notebooks no se incluyen en el paquete (correcto seg√∫n pyproject.toml)
- [ ] Instalar dependencias de desarrollo: `uv pip install -e ".[dev]"`
- [ ] Ejecutar linting: `ruff check src/` (Ruff est√° en dependencias dev, l√≠nea 77 de pyproject.toml)
- [ ] Verificar que no hay secrets o informaci√≥n sensible en el c√≥digo

---

## üéØ Resultado Esperado: Closure del Release v0.1.0

**Release v0.1.0 completo que incluye**:

### Implementaci√≥n
1. ‚úÖ Pipeline ETI completo (Extract + Transform + Inference)
2. ‚úÖ `SpacyInferenceService` implementado (NER b√°sico, √∫nica implementaci√≥n)
3. ‚úÖ Persistencia de facts en Neo4j
4. ‚úÖ Trazabilidad b√°sica PROV-O (wasDerivedFrom)
5. ‚úÖ C√≥digo siguiendo Clean Architecture estricta

### Documentaci√≥n Cient√≠fica
6. ‚úÖ Abstract profesional (150-200 palabras, IMRAD)
7. ‚úÖ Research Questions expl√≠citas
8. ‚úÖ Definici√≥n formal de ETI
9. ‚úÖ Matriz de experimentaci√≥n documentada
10. ‚úÖ Dise√±o experimental con espacio de componentes
11. ‚úÖ Hip√≥tesis experimentales formuladas
12. ‚úÖ Referencias correctas y completas

### Valor Entregado
- ‚úÖ Librer√≠a funcional con ETI completo
- ‚úÖ Implementaci√≥n m√≠nima viable con spaCy
- ‚úÖ Base para experimentaci√≥n futura
- ‚úÖ Documentaci√≥n cient√≠fica rigurosa
- ‚úÖ Dise√±o experimental reproducible
- ‚úÖ Arquitectura extensible (LLM puede a√±adirse en v0.2.0+)

**Alcance del Release v0.1.0 (Closure)**:
- ‚úÖ **Incluye**: spaCy NER-only como √∫nica implementaci√≥n de Inference
- ‚úÖ **Documenta**: LLM como alternativa futura (no implementado en v0.1.0)
- ‚úÖ **Incluye**: Dise√±o experimental completo con matriz de componentes
- ‚úÖ **Incluye**: Trazabilidad b√°sica PROV-O (wasDerivedFrom)
- ‚ùå **NO incluye**: Implementaciones LLM (v0.2.0+)
- ‚ùå **NO incluye**: Resultados experimentales completos (solo dise√±o)
- ‚ùå **NO incluye**: PROV-O completo avanzado (solo b√°sico)

---

---

## üìã Consolidaci√≥n de Documentaci√≥n

**Ver plan detallado**: `article/CONSOLIDACION_DOCS.md`  
**Notas de release**: Ver `RELEASE_NOTES.md` (en ra√≠z del proyecto) - Lista de archivos a eliminar y estado del release

### Resumen de Consolidaci√≥n

**Archivos a Eliminar** (informaci√≥n transferida al PLAN):
- `article/ANALISIS_CODIGO_REFERENCIA.md` ‚úÖ
- `article/RESUMEN_AUDITORIA_GAPS.md` ‚úÖ
- `docs/theory/GRAPHRAG_AVANZADO.md` (gu√≠a futura, no necesario para v0.1.0)

**Archivos a Consolidar**:
- `docs/validation/` ‚Üí Mantener solo `README.md` y `validation_summary.md`
- `docs/examples/` ‚Üí Consolidar ejemplos espec√≠ficos en archivos principales

**Tiempo estimado**: 1.25 horas (despu√©s de completar release)

**Criterio**: Mantener solo documentaci√≥n que aporta valor √∫nico para usuarios finales.

---

---

## üéØ ENFOQUE: SOLO RELEASE v0.1.0

**Este plan se enfoca √öNICAMENTE en completar el release v0.1.0.**

**Scope v0.1.0**:
- ‚úÖ Implementar `SpacyInferenceService` (NER b√°sico)
- ‚úÖ Completar pipeline ETI con fase Inference b√°sica
- ‚úÖ Documentaci√≥n cient√≠fica rigurosa (RQs, definiciones, matriz experimental)
- ‚úÖ Dise√±o experimental completo (no ejecuci√≥n)

**Fuera de scope v0.1.0**:
- ‚ùå Implementaci√≥n LLM (v0.2.0+)
- ‚ùå Experimentos ejecutados (solo dise√±o)
- ‚ùå PROV-O completo avanzado (solo b√°sico)

---

**√öltima actualizaci√≥n**: 2025-01-XX
**Versi√≥n objetivo**: Release v0.1.0 con ETI completo (spaCy NER-only) + dise√±o experimental
**Closure**: Implementaci√≥n √∫nica con spaCy, LLM documentado como alternativa futura

**Estado del Release**: ‚úÖ **IMPLEMENTACI√ìN Y DOCUMENTACI√ìN COMPLETAS**
- ‚úÖ Todas las tareas de implementaci√≥n (Prioridad 0) completadas
- ‚úÖ Todas las tareas de documentaci√≥n (Prioridades 1-5) completadas
- ‚è≥ Solo falta validaci√≥n final (ejecutar pipeline end-to-end, verificar persistencia, ejecutar tests)

---

## üìù Nota sobre Implementaci√≥n LLM (v0.2.0+ - FUERA DE SCOPE v0.1.0)

**Estado**: C√≥digo de referencia evaluado y documentado para futuras versiones.

**Para v0.1.0**: Solo se implementa `SpacyInferenceService` (NER b√°sico). 
La implementaci√≥n LLM queda para v0.2.0+ y est√° documentada en el c√≥digo como alternativa futura.

**Referencia**: Neo4j LLM Graph Builder
- URL: https://neo4j.com/labs/genai-ecosystem/llm-graph-builder/
- El c√≥digo en `reference_code/` proporciona base para futura implementaci√≥n de `LLMInferenceService`

