{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hybrid & Vector Search - Ungraph\n",
        "\n",
        "Este notebook demuestra c√≥mo usar b√∫squeda vectorial y b√∫squeda h√≠brida en Ungraph.\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "1. **B√∫squeda vectorial pura** - B√∫squeda por similitud sem√°ntica usando embeddings\n",
        "2. **B√∫squeda h√≠brida** - Combinaci√≥n de texto y vectorial para mejores resultados\n",
        "3. **Ajuste de pesos** - C√≥mo ajustar la importancia de texto vs vectorial\n",
        "4. **Comparaci√≥n de m√©todos** - Cu√°ndo usar cada tipo de b√∫squeda\n",
        "5. **Ejemplos pr√°cticos** - Casos de uso reales\n",
        "\n",
        "## Tipos de B√∫squeda\n",
        "\n",
        "- **Text Search**: B√∫squeda por palabras clave (full-text)\n",
        "- **Vector Search**: B√∫squeda por similitud sem√°ntica (embeddings)\n",
        "- **Hybrid Search**: Combinaci√≥n de ambas para mejores resultados\n",
        "\n",
        "**Referencias:**\n",
        "- [Gu√≠a de B√∫squeda](../../docs/guides/search.md)\n",
        "- [API P√∫blica](../../docs/api/public-api.md)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_src_to_path(path_folder: str):\n",
        "    ''' \n",
        "    Helper function for adding the \"path_folder\" directory to the path.\n",
        "    '''\n",
        "    import sys\n",
        "    from pathlib import Path\n",
        "\n",
        "    base_path = Path().resolve()\n",
        "    for parent in [base_path] + list(base_path.parents):\n",
        "        candidate = parent / path_folder\n",
        "        if candidate.exists():\n",
        "            parent_dir = candidate.parent\n",
        "            if str(parent_dir) not in sys.path:\n",
        "                sys.path.insert(0, str(parent_dir))\n",
        "            if str(candidate) not in sys.path:\n",
        "                sys.path.append(str(candidate))\n",
        "            return\n",
        "\n",
        "# Agregar carpetas necesarias al path\n",
        "add_src_to_path(path_folder=\"src\")\n",
        "add_src_to_path(path_folder=\"src/utils\")\n",
        "add_src_to_path(path_folder=\"src/data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar librer√≠as necesarias\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "# Importar ungraph\n",
        "try:\n",
        "    import ungraph\n",
        "    print(\"‚úÖ Ungraph importado como paquete instalado\")\n",
        "except ImportError:\n",
        "    import src\n",
        "    ungraph = src\n",
        "    print(\"‚úÖ Ungraph importado desde src/ (modo desarrollo)\")\n",
        "\n",
        "# Importar servicios espec√≠ficos\n",
        "from infrastructure.services.neo4j_search_service import Neo4jSearchService\n",
        "from infrastructure.services.huggingface_embedding_service import HuggingFaceEmbeddingService\n",
        "\n",
        "print(f\"üì¶ Ungraph version: {ungraph.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 1: Configuraci√≥n y Datos de Prueba\n",
        "\n",
        "Primero necesitamos tener datos en el grafo. Si no tienes datos, puedes usar el notebook de ingesta b√°sica primero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar que tenemos datos en el grafo\n",
        "from src.utils.graph_operations import graph_session\n",
        "\n",
        "driver = graph_session()\n",
        "try:\n",
        "    with driver.session() as session:\n",
        "        result = session.run(\"MATCH (c:Chunk) RETURN count(c) as count\")\n",
        "        count = result.single()[\"count\"]\n",
        "        print(f\"üìä Chunks en el grafo: {count}\")\n",
        "        \n",
        "        if count == 0:\n",
        "            print(\"‚ö†Ô∏è  No hay chunks en el grafo. Por favor ingiere documentos primero.\")\n",
        "            print(\"   Puedes usar el notebook '0. Basic Ingestion.ipynb' para ingerir datos.\")\n",
        "        else:\n",
        "            print(\"‚úÖ Datos disponibles para b√∫squeda\")\n",
        "finally:\n",
        "    driver.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 2: B√∫squeda Vectorial Pura\n",
        "\n",
        "La b√∫squeda vectorial usa embeddings para encontrar contenido sem√°nticamente similar, sin depender de palabras clave exactas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Crear servicio de embeddings\n",
        "embedding_service = HuggingFaceEmbeddingService()\n",
        "\n",
        "# 2. Generar embedding de la query\n",
        "query_text = \"inteligencia artificial y machine learning\"\n",
        "print(f\"üîç Query: '{query_text}'\")\n",
        "print(\"üìä Generando embedding...\")\n",
        "\n",
        "query_embedding = embedding_service.generate_embedding(query_text)\n",
        "print(f\"‚úÖ Embedding generado: {len(query_embedding.vector)} dimensiones\")\n",
        "print(f\"   Modelo: {query_embedding.encoder_info}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Realizar b√∫squeda vectorial\n",
        "search_service = Neo4jSearchService()\n",
        "\n",
        "print(\"üîç Realizando b√∫squeda vectorial...\")\n",
        "vector_results = search_service.vector_search(\n",
        "    query_embedding=query_embedding,\n",
        "    limit=5\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Encontrados {len(vector_results)} resultados:\\n\")\n",
        "for i, result in enumerate(vector_results, 1):\n",
        "    print(f\"Resultado {i}:\")\n",
        "    print(f\"  Score: {result.score:.4f}\")\n",
        "    print(f\"  Chunk ID: {result.chunk_id}\")\n",
        "    print(f\"  Contenido: {result.content[:200]}...\")\n",
        "    if result.previous_chunk_content:\n",
        "        print(f\"  Contexto anterior: {result.previous_chunk_content[:100]}...\")\n",
        "    if result.next_chunk_content:\n",
        "        print(f\"  Contexto siguiente: {result.next_chunk_content[:100]}...\")\n",
        "    print()\n",
        "\n",
        "search_service.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 3: B√∫squeda H√≠brida\n",
        "\n",
        "La b√∫squeda h√≠brida combina b√∫squeda por texto (full-text) y b√∫squeda vectorial para obtener mejores resultados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# B√∫squeda h√≠brida usando la funci√≥n de alto nivel\n",
        "query_text = \"deep learning y redes neuronales\"\n",
        "\n",
        "print(f\"üîç Query: '{query_text}'\")\n",
        "print(\"üîç Realizando b√∫squeda h√≠brida (pesos por defecto: 30% texto, 70% vectorial)...\\n\")\n",
        "\n",
        "hybrid_results = ungraph.hybrid_search(\n",
        "    query_text=query_text,\n",
        "    limit=5,\n",
        "    weights=(0.3, 0.7)  # 30% texto, 70% vectorial\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Encontrados {len(hybrid_results)} resultados:\\n\")\n",
        "for i, result in enumerate(hybrid_results, 1):\n",
        "    print(f\"Resultado {i}:\")\n",
        "    print(f\"  Score combinado: {result.score:.4f}\")\n",
        "    print(f\"  Chunk ID: {result.chunk_id}\")\n",
        "    print(f\"  Contenido: {result.content[:200]}...\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 4: Ajuste de Pesos en B√∫squeda H√≠brida\n",
        "\n",
        "Los pesos determinan qu√© tan importante es cada tipo de b√∫squeda. Puedes ajustarlos seg√∫n tus necesidades.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar diferentes combinaciones de pesos\n",
        "query_text = \"computaci√≥n cu√°ntica\"\n",
        "\n",
        "weight_configs = [\n",
        "    (0.7, 0.3, \"M√°s peso a texto (palabras clave exactas)\"),\n",
        "    (0.5, 0.5, \"Balanceado\"),\n",
        "    (0.3, 0.7, \"M√°s peso a vectorial (conceptos sem√°nticos) - DEFAULT\"),\n",
        "    (0.2, 0.8, \"Muy enfocado en sem√°ntica\"),\n",
        "]\n",
        "\n",
        "print(f\"üîç Query: '{query_text}'\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for text_weight, vector_weight, description in weight_configs:\n",
        "    print(f\"\\nüìä Configuraci√≥n: {description}\")\n",
        "    print(f\"   Pesos: {text_weight*100:.0f}% texto, {vector_weight*100:.0f}% vectorial\")\n",
        "    \n",
        "    results = ungraph.hybrid_search(\n",
        "        query_text=query_text,\n",
        "        limit=3,\n",
        "        weights=(text_weight, vector_weight)\n",
        "    )\n",
        "    \n",
        "    print(f\"   Top 3 resultados:\")\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"     {i}. Score: {result.score:.4f} | {result.content[:80]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 5: Comparaci√≥n de M√©todos\n",
        "\n",
        "Comparemos los tres tipos de b√∫squeda con la misma query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar los tres m√©todos\n",
        "query_text = \"machine learning applications\"\n",
        "\n",
        "print(f\"üîç Query: '{query_text}'\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. B√∫squeda por texto\n",
        "print(\"\\n1Ô∏è‚É£ B√öSQUEDA POR TEXTO (Full-text)\")\n",
        "print(\"-\" * 80)\n",
        "text_results = ungraph.search(query_text, limit=3)\n",
        "for i, result in enumerate(text_results, 1):\n",
        "    print(f\"  {i}. Score: {result.score:.4f} | {result.content[:80]}...\")\n",
        "\n",
        "# 2. B√∫squeda vectorial\n",
        "print(\"\\n2Ô∏è‚É£ B√öSQUEDA VECTORIAL (Sem√°ntica)\")\n",
        "print(\"-\" * 80)\n",
        "embedding_service = HuggingFaceEmbeddingService()\n",
        "query_embedding = embedding_service.generate_embedding(query_text)\n",
        "search_service = Neo4jSearchService()\n",
        "vector_results = search_service.vector_search(query_embedding, limit=3)\n",
        "for i, result in enumerate(vector_results, 1):\n",
        "    print(f\"  {i}. Score: {result.score:.4f} | {result.content[:80]}...\")\n",
        "search_service.close()\n",
        "\n",
        "# 3. B√∫squeda h√≠brida\n",
        "print(\"\\n3Ô∏è‚É£ B√öSQUEDA H√çBRIDA (Texto + Vectorial)\")\n",
        "print(\"-\" * 80)\n",
        "hybrid_results = ungraph.hybrid_search(query_text, limit=3, weights=(0.3, 0.7))\n",
        "for i, result in enumerate(hybrid_results, 1):\n",
        "    print(f\"  {i}. Score: {result.score:.4f} | {result.content[:80]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 6: Cu√°ndo Usar Cada Tipo de B√∫squeda\n",
        "\n",
        "### B√∫squeda por Texto\n",
        "- ‚úÖ **Cu√°ndo usar**: B√∫squedas por palabras clave exactas, t√©rminos t√©cnicos espec√≠ficos\n",
        "- ‚úÖ **Ventajas**: Muy r√°pida, buena para t√©rminos exactos\n",
        "- ‚ùå **Limitaciones**: No captura sin√≥nimos o conceptos relacionados\n",
        "\n",
        "### B√∫squeda Vectorial\n",
        "- ‚úÖ **Cu√°ndo usar**: Conceptos abstractos, b√∫squedas sem√°nticas, sin√≥nimos\n",
        "- ‚úÖ **Ventajas**: Entiende significado, encuentra contenido relacionado\n",
        "- ‚ùå **Limitaciones**: Puede ser m√°s lenta, requiere embeddings\n",
        "\n",
        "### B√∫squeda H√≠brida\n",
        "- ‚úÖ **Cu√°ndo usar**: La mayor√≠a de casos de uso, mejor precisi√≥n general\n",
        "- ‚úÖ **Ventajas**: Combina lo mejor de ambos mundos\n",
        "- ‚ùå **Limitaciones**: M√°s compleja, requiere ambos √≠ndices\n",
        "\n",
        "## Mejores Pr√°cticas\n",
        "\n",
        "1. **Empezar con h√≠brida**: Generalmente da mejores resultados\n",
        "2. **Ajustar pesos seg√∫n necesidad**: \n",
        "   - M√°s texto (0.7, 0.3) para palabras clave exactas\n",
        "   - M√°s vectorial (0.2, 0.8) para conceptos abstractos\n",
        "3. **Usar l√≠mites razonables**: `limit=5-10` suele ser suficiente\n",
        "4. **Reconstruir contexto**: Usa chunks adyacentes para mejor comprensi√≥n\n",
        "\n",
        "## Referencias\n",
        "\n",
        "- [Gu√≠a de B√∫squeda](../../docs/guides/search.md)\n",
        "- [API P√∫blica](../../docs/api/public-api.md)\n",
        "- [Patrones de B√∫squeda GraphRAG](../../docs/api/search-patterns.md)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
