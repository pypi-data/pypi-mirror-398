{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3.3 GraphRAG Retrieval Patterns - Ungraph\n",
        "\n",
        "Este notebook cubre los patrones de b√∫squeda GraphRAG b√°sicos: c√≥mo buscar informaci√≥n en el grafo usando diferentes estrategias que aprovechan la estructura del grafo.\n",
        "\n",
        "## Objetivos\n",
        "\n",
        "1. **Entender patrones GraphRAG** - Qu√© son y cu√°ndo usarlos\n",
        "2. **Basic Retriever** - B√∫squeda full-text simple\n",
        "3. **Metadata Filtering** - Filtrar por metadatos de documentos\n",
        "4. **Parent-Child Retriever** - B√∫squeda jer√°rquica con contexto\n",
        "5. **Comparar patrones** - Cu√°ndo usar cada uno\n",
        "\n",
        "## Patrones Cubiertos\n",
        "\n",
        "1. ‚úÖ **Basic Retriever** - B√∫squeda full-text simple y r√°pida\n",
        "2. ‚úÖ **Metadata Filtering** - B√∫squeda con filtros por metadatos\n",
        "3. ‚úÖ **Parent-Child Retriever** - B√∫squeda que incluye contexto jer√°rquico\n",
        "\n",
        "**Nota:** Los patrones avanzados (Community Summary, Graph-Enhanced Vector Search) est√°n cubiertos en el notebook `3.4 Advanced GraphRAG Patterns`.\n",
        "\n",
        "**Referencias:**\n",
        "- [GraphRAG Pattern Catalog](https://graphrag.com/reference/)\n",
        "- [API de B√∫squeda](../../docs/api/search-patterns.md)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_src_to_path(path_folder: str):\n",
        "    ''' \n",
        "    Helper function for adding the \"path_folder\" directory to the path.\n",
        "    in order to work on notebooks and scripts\n",
        "    '''\n",
        "    import sys\n",
        "    from pathlib import Path\n",
        "\n",
        "    base_path = Path().resolve()\n",
        "    for parent in [base_path] + list(base_path.parents):\n",
        "        candidate = parent / path_folder\n",
        "        if candidate.exists():\n",
        "            parent_dir = candidate.parent\n",
        "            if str(parent_dir) not in sys.path:\n",
        "                sys.path.insert(0, str(parent_dir))\n",
        "                print(f\"Path Folder parent added: {parent_dir}\")\n",
        "            if str(candidate) not in sys.path:\n",
        "                sys.path.append(str(candidate))\n",
        "                print(f\"Path Folder {path_folder} added: {candidate}\")\n",
        "            return\n",
        "    print(f\"Not found '{path_folder}' folder on the hierarchy of directories\")\n",
        "\n",
        "# Agregar carpetas necesarias al path\n",
        "add_src_to_path(path_folder=\"src\")\n",
        "add_src_to_path(path_folder=\"src/utils\")\n",
        "add_src_to_path(path_folder=\"src/data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Ungraph importado desde src/ (modo desarrollo)\n",
            "üì¶ Ungraph version: 0.1.0\n",
            "‚úÖ GraphRAGSearchPatterns importado correctamente\n"
          ]
        }
      ],
      "source": [
        "# Importar librer√≠as necesarias\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Importar handlers\n",
        "from src.utils.handlers import find_in_project\n",
        "\n",
        "# Importar ungraph\n",
        "try:\n",
        "    import ungraph\n",
        "    print(\"‚úÖ Ungraph importado como paquete instalado\")\n",
        "except ImportError:\n",
        "    import src\n",
        "    ungraph = src\n",
        "    print(\"‚úÖ Ungraph importado desde src/ (modo desarrollo)\")\n",
        "\n",
        "# Importar GraphRAGSearchPatterns para usar directamente\n",
        "from infrastructure.services.graphrag_search_patterns import GraphRAGSearchPatterns\n",
        "\n",
        "print(f\"üì¶ Ungraph version: {ungraph.__version__}\")\n",
        "print(f\"‚úÖ GraphRAGSearchPatterns importado correctamente\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 1: Introducci√≥n a GraphRAG Retrieval Patterns\n",
        "\n",
        "Los patrones GraphRAG aprovechan la estructura del grafo para mejorar las b√∫squedas. A diferencia de la b√∫squeda vectorial pura, estos patrones consideran las relaciones entre nodos para proporcionar contexto m√°s rico.\n",
        "\n",
        "### ¬øQu√© son los Patrones GraphRAG?\n",
        "\n",
        "Los patrones GraphRAG son estrategias de b√∫squeda que:\n",
        "- **Aprovechan la estructura del grafo** - Usan relaciones entre nodos\n",
        "- **Proporcionan contexto** - Incluyen informaci√≥n relacionada\n",
        "- **Mejoran la precisi√≥n** - Filtran y expanden resultados seg√∫n la estructura\n",
        "\n",
        "### Patrones B√°sicos Disponibles\n",
        "\n",
        "- ‚úÖ **Basic Retriever** - B√∫squeda full-text simple y r√°pida\n",
        "- ‚úÖ **Metadata Filtering** - Filtra por propiedades de documentos\n",
        "- ‚úÖ **Parent-Child Retriever** - Incluye contexto jer√°rquico (Page ‚Üí Chunks)\n",
        "\n",
        "**Nota:** Los patrones avanzados est√°n cubiertos en `3.4 Advanced GraphRAG Patterns`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã PATRONES DE B√öSQUEDA GRAPHRAG\n",
            "============================================================\n",
            "\n",
            "Basic Retriever (basic):\n",
            "  üìù B√∫squeda full-text simple usando √≠ndice de texto completo\n",
            "  üéØ Cu√°ndo usar: B√∫squedas por palabras clave, consultas simples\n",
            "  ‚ö° Velocidad: ‚ö°‚ö°‚ö° | üéØ Precisi√≥n: ‚≠ê‚≠ê\n",
            "\n",
            "Pattern Matching (pattern_matching):\n",
            "  üìù Busca usando patrones Cypher espec√≠ficos\n",
            "  üéØ Cu√°ndo usar: B√∫squedas con estructura espec√≠fica del grafo\n",
            "  ‚ö° Velocidad: ‚ö°‚ö° | üéØ Precisi√≥n: ‚≠ê‚≠ê‚≠ê\n",
            "\n",
            "Metadata Filtering (metadata_filtering):\n",
            "  üìù B√∫squeda full-text con filtros por metadatos\n",
            "  üéØ Cu√°ndo usar: Buscar solo en documentos espec√≠ficos, filtrar por fecha/autor\n",
            "  ‚ö° Velocidad: ‚ö°‚ö°‚ö° | üéØ Precisi√≥n: ‚≠ê‚≠ê‚≠ê\n",
            "\n",
            "Parent-Child Retriever (parent_child):\n",
            "  üìù Busca en nodos padre y expande a todos sus hijos\n",
            "  üéØ Cu√°ndo usar: Cuando necesitas contexto completo de una secci√≥n\n",
            "  ‚ö° Velocidad: ‚ö°‚ö° | üéØ Precisi√≥n: ‚≠ê‚≠ê‚≠ê\n",
            "\n",
            "Community Summary (Global) (community):\n",
            "  üìù Encuentra comunidades de nodos relacionados\n",
            "  üéØ Cu√°ndo usar: Necesitas contexto amplio sobre un tema\n",
            "  ‚ö° Velocidad: ‚ö° | üéØ Precisi√≥n: ‚≠ê‚≠ê\n",
            "\n",
            "Local Retriever (local):\n",
            "  üìù Similar a Community pero para comunidades peque√±as\n",
            "  üéØ Cu√°ndo usar: Exploraci√≥n de conocimiento espec√≠fico y focalizado\n",
            "  ‚ö° Velocidad: ‚ö°‚ö° | üéØ Precisi√≥n: ‚≠ê‚≠ê‚≠ê\n",
            "\n",
            "Graph-Enhanced Vector Search (graph_enhanced_vector):\n",
            "  üìù Combina b√∫squeda vectorial con estructura del grafo\n",
            "  üéØ Cu√°ndo usar: B√∫squedas avanzadas que combinan sem√°ntica y estructura\n",
            "  ‚ö° Velocidad: ‚ö° | üéØ Precisi√≥n: ‚≠ê‚≠ê‚≠ê‚≠ê\n"
          ]
        }
      ],
      "source": [
        "# Lista de patrones de b√∫squeda GraphRAG disponibles\n",
        "print(\"üìã PATRONES DE B√öSQUEDA GRAPHRAG\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "search_patterns = {\n",
        "    \"basic\": {\n",
        "        \"nombre\": \"Basic Retriever\",\n",
        "        \"descripci√≥n\": \"B√∫squeda full-text simple usando √≠ndice de texto completo\",\n",
        "        \"cuando_usar\": \"B√∫squedas por palabras clave, consultas simples\",\n",
        "        \"velocidad\": \"‚ö°‚ö°‚ö°\",\n",
        "        \"precisi√≥n\": \"‚≠ê‚≠ê\"\n",
        "    },\n",
        "    \"pattern_matching\": {\n",
        "        \"nombre\": \"Pattern Matching\",\n",
        "        \"descripci√≥n\": \"Busca usando patrones Cypher espec√≠ficos\",\n",
        "        \"cuando_usar\": \"B√∫squedas con estructura espec√≠fica del grafo\",\n",
        "        \"velocidad\": \"‚ö°‚ö°\",\n",
        "        \"precisi√≥n\": \"‚≠ê‚≠ê‚≠ê\"\n",
        "    },\n",
        "    \"metadata_filtering\": {\n",
        "        \"nombre\": \"Metadata Filtering\",\n",
        "        \"descripci√≥n\": \"B√∫squeda full-text con filtros por metadatos\",\n",
        "        \"cuando_usar\": \"Buscar solo en documentos espec√≠ficos, filtrar por fecha/autor\",\n",
        "        \"velocidad\": \"‚ö°‚ö°‚ö°\",\n",
        "        \"precisi√≥n\": \"‚≠ê‚≠ê‚≠ê\"\n",
        "    },\n",
        "    \"parent_child\": {\n",
        "        \"nombre\": \"Parent-Child Retriever\",\n",
        "        \"descripci√≥n\": \"Busca en nodos padre y expande a todos sus hijos\",\n",
        "        \"cuando_usar\": \"Cuando necesitas contexto completo de una secci√≥n\",\n",
        "        \"velocidad\": \"‚ö°‚ö°\",\n",
        "        \"precisi√≥n\": \"‚≠ê‚≠ê‚≠ê\"\n",
        "    },\n",
        "    \"community\": {\n",
        "        \"nombre\": \"Community Summary (Global)\",\n",
        "        \"descripci√≥n\": \"Encuentra comunidades de nodos relacionados\",\n",
        "        \"cuando_usar\": \"Necesitas contexto amplio sobre un tema\",\n",
        "        \"velocidad\": \"‚ö°\",\n",
        "        \"precisi√≥n\": \"‚≠ê‚≠ê\"\n",
        "    },\n",
        "    \"local\": {\n",
        "        \"nombre\": \"Local Retriever\",\n",
        "        \"descripci√≥n\": \"Similar a Community pero para comunidades peque√±as\",\n",
        "        \"cuando_usar\": \"Exploraci√≥n de conocimiento espec√≠fico y focalizado\",\n",
        "        \"velocidad\": \"‚ö°‚ö°\",\n",
        "        \"precisi√≥n\": \"‚≠ê‚≠ê‚≠ê\"\n",
        "    },\n",
        "    \"graph_enhanced_vector\": {\n",
        "        \"nombre\": \"Graph-Enhanced Vector Search\",\n",
        "        \"descripci√≥n\": \"Combina b√∫squeda vectorial con estructura del grafo\",\n",
        "        \"cuando_usar\": \"B√∫squedas avanzadas que combinan sem√°ntica y estructura\",\n",
        "        \"velocidad\": \"‚ö°\",\n",
        "        \"precisi√≥n\": \"‚≠ê‚≠ê‚≠ê‚≠ê\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for pattern_id, info in search_patterns.items():\n",
        "    print(f\"\\n{info['nombre']} ({pattern_id}):\")\n",
        "    print(f\"  üìù {info['descripci√≥n']}\")\n",
        "    print(f\"  üéØ Cu√°ndo usar: {info['cuando_usar']}\")\n",
        "    print(f\"  ‚ö° Velocidad: {info['velocidad']} | üéØ Precisi√≥n: {info['precisi√≥n']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù QUERIES CYPHER DE EJEMPLO\n",
            "================================================================================\n",
            "\n",
            "1. BASIC RETRIEVER:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
            "YIELD node, score\n",
            "RETURN node.page_content as content, \n",
            "       score,\n",
            "       node.chunk_id as chunk_id,\n",
            "       node.chunk_id_consecutive as chunk_id_consecutive\n",
            "ORDER BY score DESC\n",
            "LIMIT $limit\n",
            "\n",
            "\n",
            "‚úÖ Usa par√°metros: $query_text, $limit\n",
            "‚úÖ Sintaxis v√°lida para Neo4j\n"
          ]
        }
      ],
      "source": [
        "# Queries Cypher de ejemplo para cada patr√≥n\n",
        "print(\"üìù QUERIES CYPHER DE EJEMPLO\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Basic Retriever\n",
        "basic_query = \"\"\"\n",
        "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
        "YIELD node, score\n",
        "RETURN node.page_content as content, \n",
        "       score,\n",
        "       node.chunk_id as chunk_id,\n",
        "       node.chunk_id_consecutive as chunk_id_consecutive\n",
        "ORDER BY score DESC\n",
        "LIMIT $limit\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n1. BASIC RETRIEVER:\")\n",
        "print(\"-\" * 80)\n",
        "print(basic_query)\n",
        "print(\"\\n‚úÖ Usa par√°metros: $query_text, $limit\")\n",
        "print(\"‚úÖ Sintaxis v√°lida para Neo4j\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù GENERAR QUERIES CYPHER CON PATRONES IMPLEMENTADOS\n",
            "================================================================================\n",
            "\n",
            "1. BASIC RETRIEVER:\n",
            "--------------------------------------------------------------------------------\n",
            "Query generado:\n",
            "\n",
            "        CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
            "        YIELD node, score\n",
            "        RETURN node.page_content as content,\n",
            "               score,\n",
            "               node.chunk_id as chunk_id,\n",
            "               node.chunk_id_consecutive as chunk_id_consecutive\n",
            "        ORDER BY score DESC\n",
            "        LIMIT $limit\n",
            "        \n",
            "\n",
            "Par√°metros: ['query_text', 'limit']\n",
            "‚úÖ Query generado correctamente con par√°metros seguros\n",
            "\n",
            "2. METADATA FILTERING:\n",
            "--------------------------------------------------------------------------------\n",
            "Query generado:\n",
            "\n",
            "        CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
            "        YIELD node, score\n",
            "        WHERE node.filename = $filename AND node.page_number = $page_number\n",
            "        RETURN node.page_content as content,\n",
            "               score,\n",
            "               node.chunk_id as chunk_id,\n",
            "               node.chunk_id_consecutive as chunk_id_consecutive\n",
            "        ORDER BY score DESC\n",
            "        LIMIT $limit\n",
            "        \n",
            "\n",
            "Par√°metros: ['query_text', 'limit', 'filename', 'page_number']\n",
            "‚úÖ Query generado correctamente con par√°metros seguros\n",
            "\n",
            "3. PARENT-CHILD RETRIEVER:\n",
            "--------------------------------------------------------------------------------\n",
            "Query generado:\n",
            "\n",
            "        CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
            "        YIELD node as parent_node, score as parent_score\n",
            "        \n",
            "        OPTIONAL MATCH (parent_node:Page)-[:HAS_CHUNK]->(child_node:Chunk)\n",
            "        \n",
            "        RETURN {\n",
            "            parent_content: parent_node.page_content,\n",
            "            parent_score: parent_score,\n",
            "            parent_chunk_id: parent_node.chunk_id,\n",
            "            children: collect(DISTINCT {\n",
            "                content: child_node.page_content,\n",
            "                chunk_id: child_node.chunk_id\n",
            "            })\n",
            "        } as result\n",
            "        ORDER BY parent_score DESC\n",
            "        LIMIT $limit\n",
            "        \n",
            "\n",
            "Par√°metros: ['query_text', 'limit']\n",
            "‚úÖ Query generado correctamente con par√°metros seguros\n"
          ]
        }
      ],
      "source": [
        "# Generar queries usando los patrones implementados (EJECUTABLE)\n",
        "print(\"üìù GENERAR QUERIES CYPHER CON PATRONES IMPLEMENTADOS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Basic Retriever\n",
        "print(\"\\n1. BASIC RETRIEVER:\")\n",
        "print(\"-\" * 80)\n",
        "query_basic, params_basic = GraphRAGSearchPatterns.basic_retriever(\n",
        "    \"test query\",\n",
        "    limit=5\n",
        ")\n",
        "print(\"Query generado:\")\n",
        "print(query_basic)\n",
        "print(f\"\\nPar√°metros: {list(params_basic.keys())}\")\n",
        "print(\"‚úÖ Query generado correctamente con par√°metros seguros\")\n",
        "\n",
        "# 2. Metadata Filtering\n",
        "print(\"\\n2. METADATA FILTERING:\")\n",
        "print(\"-\" * 80)\n",
        "query_meta, params_meta = GraphRAGSearchPatterns.metadata_filtering(\n",
        "    \"test query\",\n",
        "    metadata_filters={\"filename\": \"test.md\", \"page_number\": 1},\n",
        "    limit=5\n",
        ")\n",
        "print(\"Query generado:\")\n",
        "print(query_meta)\n",
        "print(f\"\\nPar√°metros: {list(params_meta.keys())}\")\n",
        "print(\"‚úÖ Query generado correctamente con par√°metros seguros\")\n",
        "\n",
        "# 3. Parent-Child Retriever\n",
        "print(\"\\n3. PARENT-CHILD RETRIEVER:\")\n",
        "print(\"-\" * 80)\n",
        "query_parent, params_parent = GraphRAGSearchPatterns.parent_child_retriever(\n",
        "    \"test query\",\n",
        "    parent_label=\"Page\",\n",
        "    child_label=\"Chunk\",\n",
        "    relationship_type=\"HAS_CHUNK\",\n",
        "    limit=5\n",
        ")\n",
        "print(\"Query generado:\")\n",
        "print(query_parent)\n",
        "print(f\"\\nPar√°metros: {list(params_parent.keys())}\")\n",
        "print(\"‚úÖ Query generado correctamente con par√°metros seguros\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 3: Usar Patrones con Datos Reales\n",
        "\n",
        "Ahora usemos los patrones con datos reales. Primero necesitamos tener documentos ingeridos en Neo4j.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç PROBANDO search_with_pattern CON DATOS REALES\n",
            "================================================================================\n",
            "\n",
            "1. Probando Basic Retriever...\n",
            "--------------------------------------------------------------------------------\n",
            "   ‚úÖ Basic Retriever: 0 resultados\n",
            "\n",
            "‚ö†Ô∏è  No se encontraron resultados. Aseg√∫rate de:\n",
            "   1. Haber ingerido documentos con ungraph.ingest_document()\n",
            "   2. Que los documentos contengan la palabra 'test'\n",
            "   3. Que Neo4j est√© configurado correctamente\n"
          ]
        }
      ],
      "source": [
        "# Probar search_with_pattern con datos reales (EJECUTABLE)\n",
        "print(\"üîç PROBANDO search_with_pattern CON DATOS REALES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ‚ö†Ô∏è Requiere Neo4j configurado y datos ingeridos\n",
        "# Este c√≥digo probar√° los 3 patrones implementados si hay datos disponibles\n",
        "\n",
        "try:\n",
        "    # 1. Probar Basic Retriever (usando search_with_pattern)\n",
        "    print(\"\\n1. Probando Basic Retriever...\")\n",
        "    print(\"-\" * 80)\n",
        "    basic_results = ungraph.search_with_pattern(\n",
        "        \"test\",\n",
        "        pattern_type=\"basic\",\n",
        "        limit=5\n",
        "    )\n",
        "    print(f\"   ‚úÖ Basic Retriever: {len(basic_results)} resultados\")\n",
        "    \n",
        "    if len(basic_results) > 0:\n",
        "        print(f\"\\n   Primer resultado:\")\n",
        "        print(f\"   - Score: {basic_results[0].score:.3f}\")\n",
        "        print(f\"   - Chunk ID: {basic_results[0].chunk_id}\")\n",
        "        print(f\"   - Content preview: {basic_results[0].content[:80]}...\")\n",
        "        \n",
        "        # Obtener filename del primer resultado para usar en filtros\n",
        "        # Necesitamos obtener el filename desde Neo4j\n",
        "        from src.utils.graph_operations import graph_session\n",
        "        driver = graph_session()\n",
        "        with driver.session() as session:\n",
        "            result = session.run(\n",
        "                \"MATCH (c:Chunk {chunk_id: $chunk_id})-[:HAS_CHUNK]-(p:Page)-[:CONTAINS]-(f:File) \"\n",
        "                \"RETURN f.filename as filename LIMIT 1\",\n",
        "                chunk_id=basic_results[0].chunk_id\n",
        "            )\n",
        "            record = result.single()\n",
        "            if record:\n",
        "                test_filename = record[\"filename\"]\n",
        "            else:\n",
        "                test_filename = None\n",
        "        driver.close()\n",
        "        \n",
        "        if test_filename:\n",
        "            # 2. Probar Metadata Filtering\n",
        "            print(\"\\n2. Probando Metadata Filtering...\")\n",
        "            print(\"-\" * 80)\n",
        "            metadata_results = ungraph.search_with_pattern(\n",
        "                \"test\",\n",
        "                pattern_type=\"metadata_filtering\",\n",
        "                metadata_filters={\"filename\": test_filename},\n",
        "                limit=5\n",
        "            )\n",
        "            print(f\"   ‚úÖ Metadata Filtering: {len(metadata_results)} resultados\")\n",
        "            print(f\"   üìÑ Filtrando por: filename='{test_filename}'\")\n",
        "            \n",
        "            if len(metadata_results) > 0:\n",
        "                print(f\"\\n   Primer resultado:\")\n",
        "                print(f\"   - Score: {metadata_results[0].score:.3f}\")\n",
        "                print(f\"   - Chunk ID: {metadata_results[0].chunk_id}\")\n",
        "                print(f\"   - Content preview: {metadata_results[0].content[:80]}...\")\n",
        "        \n",
        "        # 3. Probar Parent-Child Retriever\n",
        "        print(\"\\n3. Probando Parent-Child Retriever...\")\n",
        "        print(\"-\" * 80)\n",
        "        parent_results = ungraph.search_with_pattern(\n",
        "            \"test\",\n",
        "            pattern_type=\"parent_child\",\n",
        "            parent_label=\"Page\",\n",
        "            child_label=\"Chunk\",\n",
        "            relationship_type=\"HAS_CHUNK\",\n",
        "            limit=5\n",
        "        )\n",
        "        print(f\"   ‚úÖ Parent-Child Retriever: {len(parent_results)} resultados\")\n",
        "        \n",
        "        if len(parent_results) > 0:\n",
        "            print(f\"\\n   Primer resultado:\")\n",
        "            print(f\"   - Score: {parent_results[0].score:.3f}\")\n",
        "            print(f\"   - Chunk ID: {parent_results[0].chunk_id}\")\n",
        "            print(f\"   - Content preview: {parent_results[0].content[:80]}...\")\n",
        "            # Parent-child retorna estructura especial con children\n",
        "            if hasattr(parent_results[0], 'next_chunk_content') and parent_results[0].next_chunk_content:\n",
        "                print(f\"   - Contexto de hijos incluido: {len(parent_results[0].next_chunk_content)} caracteres\")\n",
        "        \n",
        "        # Resumen comparativo\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"üìä RESUMEN COMPARATIVO\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"Basic Retriever:        {len(basic_results)} resultados\")\n",
        "        if test_filename:\n",
        "            print(f\"Metadata Filtering:     {len(metadata_results)} resultados (filtrado por '{test_filename}')\")\n",
        "        print(f\"Parent-Child Retriever: {len(parent_results)} resultados\")\n",
        "        \n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  No se encontraron resultados. Aseg√∫rate de:\")\n",
        "        print(\"   1. Haber ingerido documentos con ungraph.ingest_document()\")\n",
        "        print(\"   2. Que los documentos contengan la palabra 'test'\")\n",
        "        print(\"   3. Que Neo4j est√© configurado correctamente\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    print(\"\\nüí° Aseg√∫rate de:\")\n",
        "    print(\"   1. Tener Neo4j configurado y corriendo\")\n",
        "    print(\"   2. Haber ingerido documentos primero con ungraph.ingest_document()\")\n",
        "    print(\"   3. Verificar configuraci√≥n en .env o con ungraph.configure()\")\n",
        "    print(\"   4. Que el √≠ndice 'chunk_content' exista (se crea autom√°ticamente con ingest_document)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 4: Comparar Patrones Implementados\n",
        "\n",
        "Comparar resultados entre diferentes patrones de b√∫squeda.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä COMPARACI√ìN DE PATRONES IMPLEMENTADOS\n",
            "================================================================================\n",
            "\n",
            "üîç Query de prueba: 'test'\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "1. Basic Retriever:\n",
            "   Resultados: 0\n",
            "\n",
            "2. Metadata Filtering:\n",
            "   ‚ö†Ô∏è  No se pudo obtener filename para filtrar\n",
            "\n",
            "3. Parent-Child Retriever:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error in search_with_pattern (parent_child): {code: Neo.ClientError.Statement.SyntaxError} {message: In a WITH/RETURN with DISTINCT or an aggregation, it is not possible to access variables declared before the WITH/RETURN: parent_score (line 16, column 18 (offset: 574))\n",
            "\"        ORDER BY parent_score DESC\"\n",
            "                  ^}\n",
            "neo4j.exceptions.GqlError: {gql_status: 42N44} {gql_status_description: error: syntax error or access rule violation - inaccessible variable. It is not possible to access the variable `parent_score` declared before the RETURN clause when using `DISTINCT` or an aggregation.} {message: 42N44: It is not possible to access the variable `parent_score` declared before the RETURN clause when using `DISTINCT` or an aggregation.} {diagnostic_record: {'_classification': 'CLIENT_ERROR', '_position': {'offset': 574, 'column': 18, 'line': 16}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}} {raw_classification: CLIENT_ERROR}\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"D:\\projects\\Ungraph\\src\\infrastructure\\services\\neo4j_search_service.py\", line 297, in search_with_pattern\n",
            "    records = session.run(query, **params)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 330, in run\n",
            "    self._auto_result._run(\n",
            "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py\", line 236, in _run\n",
            "    self._attach()\n",
            "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py\", line 430, in _attach\n",
            "    self._connection.fetch_message()\n",
            "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py\", line 193, in inner\n",
            "    func(*args, **kwargs)\n",
            "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 863, in fetch_message\n",
            "    res = self._process_message(tag, fields)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py\", line 1208, in _process_message\n",
            "    response.on_failure(summary_metadata or {})\n",
            "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py\", line 263, in on_failure\n",
            "    raise self._hydrate_error(metadata)\n",
            "neo4j.exceptions.CypherSyntaxError: {code: Neo.ClientError.Statement.SyntaxError} {message: In a WITH/RETURN with DISTINCT or an aggregation, it is not possible to access variables declared before the WITH/RETURN: parent_score (line 16, column 18 (offset: 574))\n",
            "\"        ORDER BY parent_score DESC\"\n",
            "                  ^}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚ùå Error: {code: Neo.ClientError.Statement.SyntaxError} {message: In a WITH/RETURN with DISTINCT or an aggregation, it is not possible to access variables declared before the WITH/RETURN: parent_score (line 16, column 18 (offset: 574))\n",
            "\"        ORDER BY parent_score DESC\"\n",
            "                  ^}\n",
            "\n",
            "üí° Aseg√∫rate de:\n",
            "   1. Tener Neo4j configurado y corriendo\n",
            "   2. Haber ingerido documentos primero\n",
            "   3. Que la query tenga resultados en tu base de datos\n"
          ]
        }
      ],
      "source": [
        "# Comparar resultados entre patrones implementados\n",
        "print(\"üìä COMPARACI√ìN DE PATRONES IMPLEMENTADOS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Este c√≥digo compara los 3 patrones implementados con la misma query\n",
        "query = \"test\"  # Cambiar por tu query de prueba\n",
        "\n",
        "try:\n",
        "    print(f\"\\nüîç Query de prueba: '{query}'\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # 1. Basic Retriever\n",
        "    print(\"\\n1. Basic Retriever:\")\n",
        "    basic_results = ungraph.search_with_pattern(\n",
        "        query,\n",
        "        pattern_type=\"basic\",\n",
        "        limit=5\n",
        "    )\n",
        "    print(f\"   Resultados: {len(basic_results)}\")\n",
        "    if basic_results:\n",
        "        avg_basic = sum(r.score for r in basic_results) / len(basic_results)\n",
        "        print(f\"   Score promedio: {avg_basic:.3f}\")\n",
        "        print(f\"   Score m√°ximo: {max(r.score for r in basic_results):.3f}\")\n",
        "        print(f\"   Score m√≠nimo: {min(r.score for r in basic_results):.3f}\")\n",
        "    \n",
        "    # 2. Metadata Filtering (necesitamos un filename)\n",
        "    # Intentar obtener un filename de los resultados b√°sicos\n",
        "    test_filename = None\n",
        "    if basic_results:\n",
        "        from src.utils.graph_operations import graph_session\n",
        "        driver = graph_session()\n",
        "        with driver.session() as session:\n",
        "            result = session.run(\n",
        "                \"MATCH (c:Chunk {chunk_id: $chunk_id})-[:HAS_CHUNK]-(p:Page)-[:CONTAINS]-(f:File) \"\n",
        "                \"RETURN f.filename as filename LIMIT 1\",\n",
        "                chunk_id=basic_results[0].chunk_id\n",
        "            )\n",
        "            record = result.single()\n",
        "            if record:\n",
        "                test_filename = record[\"filename\"]\n",
        "        driver.close()\n",
        "    \n",
        "    if test_filename:\n",
        "        print(f\"\\n2. Metadata Filtering (filtrado por '{test_filename}'):\")\n",
        "        metadata_results = ungraph.search_with_pattern(\n",
        "            query,\n",
        "            pattern_type=\"metadata_filtering\",\n",
        "            metadata_filters={\"filename\": test_filename},\n",
        "            limit=5\n",
        "        )\n",
        "        print(f\"   Resultados: {len(metadata_results)}\")\n",
        "        if metadata_results:\n",
        "            avg_metadata = sum(r.score for r in metadata_results) / len(metadata_results)\n",
        "            print(f\"   Score promedio: {avg_metadata:.3f}\")\n",
        "            print(f\"   Score m√°ximo: {max(r.score for r in metadata_results):.3f}\")\n",
        "            print(f\"   Score m√≠nimo: {min(r.score for r in metadata_results):.3f}\")\n",
        "    else:\n",
        "        print(\"\\n2. Metadata Filtering:\")\n",
        "        print(\"   ‚ö†Ô∏è  No se pudo obtener filename para filtrar\")\n",
        "    \n",
        "    # 3. Parent-Child Retriever\n",
        "    print(\"\\n3. Parent-Child Retriever:\")\n",
        "    parent_results = ungraph.search_with_pattern(\n",
        "        query,\n",
        "        pattern_type=\"parent_child\",\n",
        "        parent_label=\"Page\",\n",
        "        child_label=\"Chunk\",\n",
        "        relationship_type=\"HAS_CHUNK\",\n",
        "        limit=5\n",
        "    )\n",
        "    print(f\"   Resultados: {len(parent_results)}\")\n",
        "    if parent_results:\n",
        "        avg_parent = sum(r.score for r in parent_results) / len(parent_results)\n",
        "        print(f\"   Score promedio: {avg_parent:.3f}\")\n",
        "        print(f\"   Score m√°ximo: {max(r.score for r in parent_results):.3f}\")\n",
        "        print(f\"   Score m√≠nimo: {min(r.score for r in parent_results):.3f}\")\n",
        "    \n",
        "    # Resumen comparativo\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìä RESUMEN COMPARATIVO\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"{'Patr√≥n':<25} {'Resultados':<12} {'Score Promedio':<15}\")\n",
        "    print(\"-\" * 80)\n",
        "    if basic_results:\n",
        "        print(f\"{'Basic Retriever':<25} {len(basic_results):<12} {avg_basic:.3f}\")\n",
        "    if test_filename and metadata_results:\n",
        "        print(f\"{'Metadata Filtering':<25} {len(metadata_results):<12} {avg_metadata:.3f}\")\n",
        "    if parent_results:\n",
        "        print(f\"{'Parent-Child Retriever':<25} {len(parent_results):<12} {avg_parent:.3f}\")\n",
        "    \n",
        "    print(\"\\nüí° Interpretaci√≥n:\")\n",
        "    print(\"   - Basic Retriever: M√°s r√°pido, resultados generales\")\n",
        "    print(\"   - Metadata Filtering: M√°s preciso cuando filtras por documento espec√≠fico\")\n",
        "    print(\"   - Parent-Child: Incluye contexto jer√°rquico (Page + Chunks)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")\n",
        "    print(\"\\nüí° Aseg√∫rate de:\")\n",
        "    print(\"   1. Tener Neo4j configurado y corriendo\")\n",
        "    print(\"   2. Haber ingerido documentos primero\")\n",
        "    print(\"   3. Que la query tenga resultados en tu base de datos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "3. PARENT-CHILD RETRIEVER:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
            "YIELD node as parent_node, score as parent_score\n",
            "\n",
            "OPTIONAL MATCH (parent_node:Page)-[:HAS_CHUNK]->(child_node:Chunk)\n",
            "\n",
            "RETURN {\n",
            "    parent_content: parent_node.page_content,\n",
            "    parent_score: parent_score,\n",
            "    parent_chunk_id: parent_node.chunk_id,\n",
            "    children: collect(DISTINCT {\n",
            "        content: child_node.page_content,\n",
            "        chunk_id: child_node.chunk_id\n",
            "    })\n",
            "} as result\n",
            "ORDER BY parent_score DESC\n",
            "LIMIT $limit\n",
            "\n",
            "\n",
            "‚úÖ Expande a nodos hijos relacionados\n",
            "‚úÖ Retorna estructura jer√°rquica\n"
          ]
        }
      ],
      "source": [
        "# 3. Parent-Child Retriever\n",
        "parent_child_query = \"\"\"\n",
        "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
        "YIELD node as parent_node, score as parent_score\n",
        "\n",
        "OPTIONAL MATCH (parent_node:Page)-[:HAS_CHUNK]->(child_node:Chunk)\n",
        "\n",
        "RETURN {\n",
        "    parent_content: parent_node.page_content,\n",
        "    parent_score: parent_score,\n",
        "    parent_chunk_id: parent_node.chunk_id,\n",
        "    children: collect(DISTINCT {\n",
        "        content: child_node.page_content,\n",
        "        chunk_id: child_node.chunk_id\n",
        "    })\n",
        "} as result\n",
        "ORDER BY parent_score DESC\n",
        "LIMIT $limit\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n3. PARENT-CHILD RETRIEVER:\")\n",
        "print(\"-\" * 80)\n",
        "print(parent_child_query)\n",
        "print(\"\\n‚úÖ Expande a nodos hijos relacionados\")\n",
        "print(\"‚úÖ Retorna estructura jer√°rquica\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "4. COMMUNITY SUMMARY RETRIEVER:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
            "YIELD node as central_node, score\n",
            "\n",
            "MATCH path = (central_node)-[*1..2]-(community_node:Chunk)\n",
            "WHERE community_node <> central_node\n",
            "\n",
            "WITH central_node, score,\n",
            "     collect(DISTINCT community_node) as community,\n",
            "     count(DISTINCT community_node) as community_size\n",
            "\n",
            "WHERE community_size >= $community_threshold\n",
            "\n",
            "RETURN {\n",
            "    central_content: central_node.page_content,\n",
            "    central_score: score,\n",
            "    central_chunk_id: central_node.chunk_id,\n",
            "    central_chunk_id_consecutive: central_node.chunk_id_consecutive,\n",
            "    community_size: community_size,\n",
            "    community_summary: reduce(\n",
            "        summary = \"\",\n",
            "        node IN community |\n",
            "        summary + \" \" + coalesce(node.page_content, \"\")\n",
            "    )\n",
            "} as result\n",
            "ORDER BY score DESC, community_size DESC\n",
            "LIMIT $limit\n",
            "\n",
            "\n",
            "‚úÖ Encuentra comunidades de nodos relacionados\n",
            "‚úÖ Genera resumen de la comunidad\n",
            "‚úÖ Usa par√°metros: $query_text, $community_threshold, $limit\n"
          ]
        }
      ],
      "source": [
        "# 4. Community Summary Retriever\n",
        "community_query = \"\"\"\n",
        "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
        "YIELD node as central_node, score\n",
        "\n",
        "MATCH path = (central_node)-[*1..2]-(community_node:Chunk)\n",
        "WHERE community_node <> central_node\n",
        "\n",
        "WITH central_node, score,\n",
        "     collect(DISTINCT community_node) as community,\n",
        "     count(DISTINCT community_node) as community_size\n",
        "\n",
        "WHERE community_size >= $community_threshold\n",
        "\n",
        "RETURN {\n",
        "    central_content: central_node.page_content,\n",
        "    central_score: score,\n",
        "    central_chunk_id: central_node.chunk_id,\n",
        "    central_chunk_id_consecutive: central_node.chunk_id_consecutive,\n",
        "    community_size: community_size,\n",
        "    community_summary: reduce(\n",
        "        summary = \"\",\n",
        "        node IN community |\n",
        "        summary + \" \" + coalesce(node.page_content, \"\")\n",
        "    )\n",
        "} as result\n",
        "ORDER BY score DESC, community_size DESC\n",
        "LIMIT $limit\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n4. COMMUNITY SUMMARY RETRIEVER:\")\n",
        "print(\"-\" * 80)\n",
        "print(community_query)\n",
        "print(\"\\n‚úÖ Encuentra comunidades de nodos relacionados\")\n",
        "print(\"‚úÖ Genera resumen de la comunidad\")\n",
        "print(\"‚úÖ Usa par√°metros: $query_text, $community_threshold, $limit\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "5. GRAPH-ENHANCED VECTOR SEARCH:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "CALL db.index.vector.queryNodes('chunk_embeddings', toInteger($limit), $query_vector)\n",
            "YIELD node as vec_node, score as vec_score\n",
            "\n",
            "OPTIONAL MATCH path = (vec_node)-[:NEXT_CHUNK|HAS_CHUNK]*1..2-(related_node:Chunk)\n",
            "WHERE related_node IS NOT NULL\n",
            "\n",
            "WITH vec_node, vec_score,\n",
            "     collect(DISTINCT related_node) as related_nodes,\n",
            "     count(DISTINCT related_node) as related_count\n",
            "\n",
            "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
            "YIELD node as text_node, score as text_score\n",
            "WHERE text_node = vec_node\n",
            "\n",
            "RETURN {\n",
            "    content: vec_node.page_content,\n",
            "    vector_score: vec_score,\n",
            "    text_score: text_score,\n",
            "    combined_score: (vec_score * 0.6 + text_score * 0.4),\n",
            "    chunk_id: vec_node.chunk_id,\n",
            "    chunk_id_consecutive: vec_node.chunk_id_consecutive,\n",
            "    related_count: related_count\n",
            "} as result\n",
            "ORDER BY result.combined_score DESC\n",
            "LIMIT $limit\n",
            "\n",
            "\n",
            "‚úÖ Combina b√∫squeda vectorial con estructura del grafo\n",
            "‚úÖ Considera nodos relacionados para enriquecer contexto\n",
            "‚úÖ Usa par√°metros: $query_text, $query_vector, $limit\n"
          ]
        }
      ],
      "source": [
        "# 5. Graph-Enhanced Vector Search\n",
        "graph_enhanced_query = \"\"\"\n",
        "CALL db.index.vector.queryNodes('chunk_embeddings', toInteger($limit), $query_vector)\n",
        "YIELD node as vec_node, score as vec_score\n",
        "\n",
        "OPTIONAL MATCH path = (vec_node)-[:NEXT_CHUNK|HAS_CHUNK]*1..2-(related_node:Chunk)\n",
        "WHERE related_node IS NOT NULL\n",
        "\n",
        "WITH vec_node, vec_score,\n",
        "     collect(DISTINCT related_node) as related_nodes,\n",
        "     count(DISTINCT related_node) as related_count\n",
        "\n",
        "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
        "YIELD node as text_node, score as text_score\n",
        "WHERE text_node = vec_node\n",
        "\n",
        "RETURN {\n",
        "    content: vec_node.page_content,\n",
        "    vector_score: vec_score,\n",
        "    text_score: text_score,\n",
        "    combined_score: (vec_score * 0.6 + text_score * 0.4),\n",
        "    chunk_id: vec_node.chunk_id,\n",
        "    chunk_id_consecutive: vec_node.chunk_id_consecutive,\n",
        "    related_count: related_count\n",
        "} as result\n",
        "ORDER BY result.combined_score DESC\n",
        "LIMIT $limit\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n5. GRAPH-ENHANCED VECTOR SEARCH:\")\n",
        "print(\"-\" * 80)\n",
        "print(graph_enhanced_query)\n",
        "print(\"\\n‚úÖ Combina b√∫squeda vectorial con estructura del grafo\")\n",
        "print(\"‚úÖ Considera nodos relacionados para enriquecer contexto\")\n",
        "print(\"‚úÖ Usa par√°metros: $query_text, $query_vector, $limit\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 3: Validaci√≥n de Sintaxis Cypher\n",
        "\n",
        "Verificamos que los queries sean sint√°cticamente v√°lidos (validaci√≥n b√°sica).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç VALIDACI√ìN DE SINTAXIS CYPHER\n",
            "================================================================================\n",
            "\n",
            "‚úÖ PATRONES IMPLEMENTADOS:\n",
            "\n",
            "Basic Retriever:\n",
            "  ‚úÖ Sintaxis b√°sica v√°lida\n",
            "  üìù Keywords encontradas: RETURN, CALL\n",
            "\n",
            "Metadata Filtering:\n",
            "  ‚úÖ Sintaxis b√°sica v√°lida\n",
            "  üìù Keywords encontradas: RETURN, CALL\n",
            "\n",
            "Parent-Child Retriever:\n",
            "  ‚úÖ Sintaxis b√°sica v√°lida\n",
            "  üìù Keywords encontradas: RETURN, MATCH, CALL\n",
            "\n",
            "üìù PATRONES DOCUMENTADOS (ejemplos):\n",
            "\n",
            "Community Summary (ejemplo):\n",
            "  ‚úÖ Sintaxis b√°sica v√°lida\n",
            "  üìù Keywords encontradas: RETURN, MATCH, CALL\n",
            "\n",
            "Graph-Enhanced Vector (ejemplo):\n",
            "  ‚úÖ Sintaxis b√°sica v√°lida\n",
            "  üìù Keywords encontradas: RETURN, MATCH, CALL\n"
          ]
        }
      ],
      "source": [
        "# Validaci√≥n b√°sica de sintaxis Cypher\n",
        "print(\"üîç VALIDACI√ìN DE SINTAXIS CYPHER\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def validate_cypher_basic(query: str) -> Dict[str, Any]:\n",
        "    \"\"\"Validaci√≥n b√°sica de sintaxis Cypher.\"\"\"\n",
        "    issues = []\n",
        "    warnings = []\n",
        "    \n",
        "    # Verificar que usa par√°metros\n",
        "    if \"$\" not in query:\n",
        "        warnings.append(\"No se detectaron par√°metros ($param)\")\n",
        "    \n",
        "    # Verificar palabras clave comunes\n",
        "    required_keywords = [\"RETURN\", \"MATCH\", \"CALL\"]\n",
        "    found_keywords = [kw for kw in required_keywords if kw in query]\n",
        "    \n",
        "    if not found_keywords:\n",
        "        issues.append(\"No se encontraron palabras clave Cypher comunes\")\n",
        "    \n",
        "    # Verificar que no hay interpolaci√≥n directa peligrosa\n",
        "    dangerous_patterns = ['f\"', \"f'\", '${', '%s', '%d']\n",
        "    for pattern in dangerous_patterns:\n",
        "        if pattern in query:\n",
        "            warnings.append(f\"Posible interpolaci√≥n directa detectada: {pattern}\")\n",
        "    \n",
        "    return {\n",
        "        \"valid\": len(issues) == 0,\n",
        "        \"issues\": issues,\n",
        "        \"warnings\": warnings,\n",
        "        \"found_keywords\": found_keywords\n",
        "    }\n",
        "\n",
        "# Generar queries usando los m√©todos implementados (EJECUTABLE)\n",
        "query_basic_val, _ = GraphRAGSearchPatterns.basic_retriever(\"test\", limit=5)\n",
        "query_meta_val, _ = GraphRAGSearchPatterns.metadata_filtering(\"test\", {\"filename\": \"test.md\"}, limit=5)\n",
        "query_parent_val, _ = GraphRAGSearchPatterns.parent_child_retriever(\"test\", limit=5)\n",
        "\n",
        "# Validar cada query implementado (EJECUTABLE)\n",
        "queries_to_validate = {\n",
        "    \"Basic Retriever\": query_basic_val,\n",
        "    \"Metadata Filtering\": query_meta_val,\n",
        "    \"Parent-Child Retriever\": query_parent_val,\n",
        "}\n",
        "\n",
        "# Tambi√©n validar queries de ejemplo (documentados pero no implementados)\n",
        "# Definir queries de ejemplo para validaci√≥n\n",
        "community_query = \"\"\"\n",
        "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
        "YIELD node as central_node, score\n",
        "MATCH path = (central_node)-[*1..2]-(community_node:Chunk)\n",
        "WHERE community_node <> central_node\n",
        "WITH central_node, score,\n",
        "     collect(DISTINCT community_node) as community,\n",
        "     count(DISTINCT community_node) as community_size\n",
        "WHERE community_size >= $community_threshold\n",
        "RETURN {\n",
        "    central_content: central_node.page_content,\n",
        "    central_score: score,\n",
        "    community_size: community_size\n",
        "} as result\n",
        "ORDER BY score DESC, community_size DESC\n",
        "LIMIT $limit\n",
        "\"\"\"\n",
        "\n",
        "graph_enhanced_query = \"\"\"\n",
        "CALL db.index.vector.queryNodes('chunk_embeddings', toInteger($limit), $query_vector)\n",
        "YIELD node as vec_node, score as vec_score\n",
        "OPTIONAL MATCH path = (vec_node)-[:NEXT_CHUNK|HAS_CHUNK]*1..2-(related_node:Chunk)\n",
        "WHERE related_node IS NOT NULL\n",
        "WITH vec_node, vec_score,\n",
        "     collect(DISTINCT related_node) as related_nodes,\n",
        "     count(DISTINCT related_node) as related_count\n",
        "CALL db.index.fulltext.queryNodes(\"chunk_content\", $query_text)\n",
        "YIELD node as text_node, score as text_score\n",
        "WHERE text_node = vec_node\n",
        "RETURN {\n",
        "    content: vec_node.page_content,\n",
        "    vector_score: vec_score,\n",
        "    text_score: text_score,\n",
        "    combined_score: (vec_score * 0.6 + text_score * 0.4)\n",
        "} as result\n",
        "ORDER BY result.combined_score DESC\n",
        "LIMIT $limit\n",
        "\"\"\"\n",
        "\n",
        "queries_examples = {\n",
        "    \"Community Summary (ejemplo)\": community_query,\n",
        "    \"Graph-Enhanced Vector (ejemplo)\": graph_enhanced_query\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ PATRONES IMPLEMENTADOS:\")\n",
        "for name, query in queries_to_validate.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    result = validate_cypher_basic(query)\n",
        "    if result[\"valid\"]:\n",
        "        print(f\"  ‚úÖ Sintaxis b√°sica v√°lida\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå Problemas encontrados: {result['issues']}\")\n",
        "    \n",
        "    if result[\"warnings\"]:\n",
        "        print(f\"  ‚ö†Ô∏è  Advertencias: {result['warnings']}\")\n",
        "    \n",
        "    print(f\"  üìù Keywords encontradas: {', '.join(result['found_keywords'])}\")\n",
        "\n",
        "print(\"\\nüìù PATRONES DOCUMENTADOS (ejemplos):\")\n",
        "for name, query in queries_examples.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    result = validate_cypher_basic(query)\n",
        "    if result[\"valid\"]:\n",
        "        print(f\"  ‚úÖ Sintaxis b√°sica v√°lida\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå Problemas encontrados: {result['issues']}\")\n",
        "    \n",
        "    if result[\"warnings\"]:\n",
        "        print(f\"  ‚ö†Ô∏è  Advertencias: {result['warnings']}\")\n",
        "    \n",
        "    print(f\"  üìù Keywords encontradas: {', '.join(result['found_keywords'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä TABLA COMPARATIVA DE PATRONES\n",
            "================================================================================\n",
            "                      Patr√≥n                    ID Velocidad Precisi√≥n                                       Uso Recomendado\n",
            "             Basic Retriever                 basic       ‚ö°‚ö°‚ö°        ‚≠ê‚≠ê    B√∫squedas por palabras clave, consultas simples...\n",
            "            Pattern Matching      pattern_matching        ‚ö°‚ö°       ‚≠ê‚≠ê‚≠ê      B√∫squedas con estructura espec√≠fica del grafo...\n",
            "          Metadata Filtering    metadata_filtering       ‚ö°‚ö°‚ö°       ‚≠ê‚≠ê‚≠ê Buscar solo en documentos espec√≠ficos, filtrar por...\n",
            "      Parent-Child Retriever          parent_child        ‚ö°‚ö°       ‚≠ê‚≠ê‚≠ê  Cuando necesitas contexto completo de una secci√≥n...\n",
            "  Community Summary (Global)             community         ‚ö°        ‚≠ê‚≠ê            Necesitas contexto amplio sobre un tema...\n",
            "             Local Retriever                 local        ‚ö°‚ö°       ‚≠ê‚≠ê‚≠ê Exploraci√≥n de conocimiento espec√≠fico y focalizad...\n",
            "Graph-Enhanced Vector Search graph_enhanced_vector         ‚ö°      ‚≠ê‚≠ê‚≠ê‚≠ê B√∫squedas avanzadas que combinan sem√°ntica y estru...\n",
            "\n",
            "üí° Nota: Velocidad y precisi√≥n son estimaciones relativas\n",
            "   ‚ö°‚ö°‚ö° = Muy r√°pido | ‚ö° = Lento\n",
            "   ‚≠ê‚≠ê‚≠ê‚≠ê = Muy preciso | ‚≠ê‚≠ê = Menos preciso\n"
          ]
        }
      ],
      "source": [
        "# Tabla comparativa de patrones\n",
        "print(\"üìä TABLA COMPARATIVA DE PATRONES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Crear DataFrame comparativo\n",
        "comparison_data = []\n",
        "for pattern_id, info in search_patterns.items():\n",
        "    comparison_data.append({\n",
        "        \"Patr√≥n\": info[\"nombre\"],\n",
        "        \"ID\": pattern_id,\n",
        "        \"Velocidad\": info[\"velocidad\"],\n",
        "        \"Precisi√≥n\": info[\"precisi√≥n\"],\n",
        "        \"Uso Recomendado\": info[\"cuando_usar\"][:50] + \"...\"\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(comparison_data)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\nüí° Nota: Velocidad y precisi√≥n son estimaciones relativas\")\n",
        "print(\"   ‚ö°‚ö°‚ö° = Muy r√°pido | ‚ö° = Lento\")\n",
        "print(\"   ‚≠ê‚≠ê‚≠ê‚≠ê = Muy preciso | ‚≠ê‚≠ê = Menos preciso\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 5: Ejemplos de Uso Futuro\n",
        "\n",
        "Ejemplos de c√≥mo se usar√°n estos patrones cuando est√©n implementados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üí° EJEMPLOS DE USO FUTURO\n",
            "============================================================\n",
            "\n",
            "Basic Retriever (basic):\n",
            "------------------------------------------------------------\n",
            "\n",
            "# B√∫squeda b√°sica\n",
            "results = ungraph.search_with_pattern(\n",
            "    \"computaci√≥n cu√°ntica\",\n",
            "    pattern_type=\"basic\",\n",
            "    limit=5\n",
            ")\n",
            "\n",
            "‚è≥ Disponible en Fase 3 del plan\n",
            "\n",
            "Metadata Filtering (metadata_filtering):\n",
            "------------------------------------------------------------\n",
            "\n",
            "# B√∫squeda con filtros de metadatos\n",
            "results = ungraph.search_with_pattern(\n",
            "    \"machine learning\",\n",
            "    pattern_type=\"metadata_filtering\",\n",
            "    metadata_filters={\n",
            "        \"filename\": \"ai_paper.md\",\n",
            "        \"page_number\": 1\n",
            "    },\n",
            "    limit=10\n",
            ")\n",
            "\n",
            "‚è≥ Disponible en Fase 3 del plan\n",
            "\n",
            "Parent-Child Retriever (parent_child):\n",
            "------------------------------------------------------------\n",
            "\n",
            "# B√∫squeda Parent-Child\n",
            "results = ungraph.search_with_pattern(\n",
            "    \"inteligencia artificial\",\n",
            "    pattern_type=\"parent_child\",\n",
            "    parent_label=\"Page\",\n",
            "    child_label=\"Chunk\",\n",
            "    relationship_type=\"HAS_CHUNK\",\n",
            "    limit=5\n",
            ")\n",
            "\n",
            "‚è≥ Disponible en Fase 3 del plan\n",
            "\n",
            "Community Summary (Global) (community):\n",
            "------------------------------------------------------------\n",
            "\n",
            "# B√∫squeda Community Summary\n",
            "results = ungraph.search_with_pattern(\n",
            "    \"deep learning\",\n",
            "    pattern_type=\"community\",\n",
            "    community_threshold=5,\n",
            "    max_depth=2,\n",
            "    limit=3\n",
            ")\n",
            "\n",
            "‚è≥ Disponible en Fase 3 del plan\n",
            "\n",
            "Graph-Enhanced Vector Search (graph_enhanced_vector):\n",
            "------------------------------------------------------------\n",
            "\n",
            "# B√∫squeda Graph-Enhanced Vector\n",
            "from ungraph import HuggingFaceEmbeddingService\n",
            "\n",
            "embedding_service = HuggingFaceEmbeddingService()\n",
            "query_embedding = embedding_service.generate_embedding(\"deep learning\")\n",
            "\n",
            "results = ungraph.search_with_pattern(\n",
            "    \"deep learning\",\n",
            "    pattern_type=\"graph_enhanced_vector\",\n",
            "    query_vector=query_embedding.vector,\n",
            "    relationship_types=[\"NEXT_CHUNK\", \"HAS_CHUNK\"],\n",
            "    limit=5\n",
            ")\n",
            "\n",
            "‚è≥ Disponible en Fase 3 del plan\n"
          ]
        }
      ],
      "source": [
        "# Ejemplos de uso futuro (cuando est√©n implementados)\n",
        "print(\"üí° EJEMPLOS DE USO FUTURO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "examples = {\n",
        "    \"basic\": \"\"\"\n",
        "# B√∫squeda b√°sica\n",
        "results = ungraph.search_with_pattern(\n",
        "    \"computaci√≥n cu√°ntica\",\n",
        "    pattern_type=\"basic\",\n",
        "    limit=5\n",
        ")\n",
        "\"\"\",\n",
        "    \n",
        "    \"metadata_filtering\": \"\"\"\n",
        "# B√∫squeda con filtros de metadatos\n",
        "results = ungraph.search_with_pattern(\n",
        "    \"machine learning\",\n",
        "    pattern_type=\"metadata_filtering\",\n",
        "    metadata_filters={\n",
        "        \"filename\": \"ai_paper.md\",\n",
        "        \"page_number\": 1\n",
        "    },\n",
        "    limit=10\n",
        ")\n",
        "\"\"\",\n",
        "    \n",
        "    \"parent_child\": \"\"\"\n",
        "# B√∫squeda Parent-Child\n",
        "results = ungraph.search_with_pattern(\n",
        "    \"inteligencia artificial\",\n",
        "    pattern_type=\"parent_child\",\n",
        "    parent_label=\"Page\",\n",
        "    child_label=\"Chunk\",\n",
        "    relationship_type=\"HAS_CHUNK\",\n",
        "    limit=5\n",
        ")\n",
        "\"\"\",\n",
        "    \n",
        "    \"community\": \"\"\"\n",
        "# B√∫squeda Community Summary\n",
        "results = ungraph.search_with_pattern(\n",
        "    \"deep learning\",\n",
        "    pattern_type=\"community\",\n",
        "    community_threshold=5,\n",
        "    max_depth=2,\n",
        "    limit=3\n",
        ")\n",
        "\"\"\",\n",
        "    \n",
        "    \"graph_enhanced_vector\": \"\"\"\n",
        "# B√∫squeda Graph-Enhanced Vector\n",
        "from ungraph import HuggingFaceEmbeddingService\n",
        "\n",
        "embedding_service = HuggingFaceEmbeddingService()\n",
        "query_embedding = embedding_service.generate_embedding(\"deep learning\")\n",
        "\n",
        "results = ungraph.search_with_pattern(\n",
        "    \"deep learning\",\n",
        "    pattern_type=\"graph_enhanced_vector\",\n",
        "    query_vector=query_embedding.vector,\n",
        "    relationship_types=[\"NEXT_CHUNK\", \"HAS_CHUNK\"],\n",
        "    limit=5\n",
        ")\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "for pattern_id, example_code in examples.items():\n",
        "    pattern_name = search_patterns[pattern_id][\"nombre\"]\n",
        "    print(f\"\\n{pattern_name} ({pattern_id}):\")\n",
        "    print(\"-\" * 60)\n",
        "    print(example_code)\n",
        "    print(\"‚è≥ Disponible en Fase 3 del plan\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 6: Resumen y Estado\n",
        "\n",
        "Resumen de lo probado y estado de implementaci√≥n.\n",
        "\n",
        "**‚úÖ Los patrones b√°sicos est√°n implementados y funcionando:**\n",
        "- `basic` / `basic_retriever` - B√∫squeda full-text simple\n",
        "- `metadata_filtering` - B√∫squeda con filtros por metadatos  \n",
        "- `parent_child` / `parent_child_retriever` - B√∫squeda jer√°rquica\n",
        "\n",
        "**üìö Ver ejemplos de uso:**\n",
        "- `docs/examples/phase3_search_patterns.md` - Ejemplos completos\n",
        "- `docs/api/search-patterns.md` - Documentaci√≥n de API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç PROBANDO B√öSQUEDA B√ÅSICA EXISTENTE\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to create a graph session: {code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}\n",
            "URI: bolt://localhost:7687\n",
            "User: neo4j\n",
            "Please check:\n",
            "1. Neo4j is running\n",
            "2. Credentials are correct\n",
            "3. URI is accessible\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Error: Failed to create a graph session: {code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}\n",
            "URI: bolt://localhost:7687\n",
            "User: neo4j\n",
            "Please check:\n",
            "1. Neo4j is running\n",
            "2. Credentials are correct\n",
            "3. URI is accessible\n",
            "üí° Aseg√∫rate de haber ingerido documentos primero\n",
            "üí° Descomenta el c√≥digo anterior para probar con Neo4j real\n",
            "‚ö†Ô∏è  Requiere Neo4j configurado y datos ingeridos\n"
          ]
        }
      ],
      "source": [
        "# Probar b√∫squeda b√°sica existente (si hay datos en Neo4j)\n",
        "print(\"üîç PROBANDO B√öSQUEDA B√ÅSICA EXISTENTE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Descomentar si quieres probar con Neo4j real\n",
        "# ‚ö†Ô∏è Requiere Neo4j configurado y datos ingeridos\n",
        "\n",
        "\n",
        "# Configurar Neo4j (si no est√° configurado)\n",
        "ungraph.configure(\n",
        "    neo4j_uri=\"bolt://localhost:7687\",\n",
        "    neo4j_password=\"tu_contrase√±a\"\n",
        ")\n",
        "\n",
        "# Probar b√∫squeda b√°sica\n",
        "try:\n",
        "    results = ungraph.search(\"test query\", limit=3)\n",
        "    print(f\"‚úÖ B√∫squeda exitosa: {len(results)} resultados\")\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"\\nResultado {i}:\")\n",
        "        print(f\"  Score: {result.score:.3f}\")\n",
        "        print(f\"  Content: {result.content[:100]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"üí° Aseg√∫rate de haber ingerido documentos primero\")\n",
        "\n",
        "\n",
        "print(\"üí° Descomenta el c√≥digo anterior para probar con Neo4j real\")\n",
        "print(\"‚ö†Ô∏è  Requiere Neo4j configurado y datos ingeridos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parte 6: Resumen y Mejores Pr√°cticas\n",
        "\n",
        "Resumen de los patrones y cu√°ndo usar cada uno.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä RESUMEN DE TESTS DE RETRIEVALS\n",
            "================================================================================\n",
            "Patrones Documentados: 7\n",
            "Queries Cypher Validados: 3\n",
            "Estado de Implementaci√≥n: ‚è≥ Pendiente (Fase 3)\n",
            "\n",
            "üìã Patrones de B√∫squeda GraphRAG:\n",
            "  üìù Planificado - Basic Retriever (basic)\n",
            "  üìù Planificado - Pattern Matching (pattern_matching)\n",
            "  üìù Planificado - Metadata Filtering (metadata_filtering)\n",
            "  üìù Planificado - Parent-Child Retriever (parent_child)\n",
            "  üìù Planificado - Community Summary (Global) (community)\n",
            "  üìù Planificado - Local Retriever (local)\n",
            "  üìù Planificado - Graph-Enhanced Vector Search (graph_enhanced_vector)\n",
            "\n",
            "üéØ Pr√≥ximos Pasos:\n",
            "  1. Fase 3: Implementar GraphRAGSearchPatterns\n",
            "  2. Fase 3: Crear SearchWithPatternUseCase\n",
            "  3. Fase 3: Exponer en API p√∫blica (ungraph.search_with_pattern)\n",
            "  4. Probar con datos reales y comparar resultados\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä RESUMEN DE PATRONES GRAPHRAG B√ÅSICOS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n‚úÖ Patrones B√°sicos Disponibles:\")\n",
        "print(\"  1. Basic Retriever - B√∫squeda full-text simple\")\n",
        "print(\"  2. Metadata Filtering - Filtrado por metadatos\")\n",
        "print(\"  3. Parent-Child Retriever - Contexto jer√°rquico\")\n",
        "\n",
        "print(\"\\nüìã Cu√°ndo Usar Cada Patr√≥n:\")\n",
        "print(\"\\n  Basic Retriever:\")\n",
        "print(\"    ‚úÖ B√∫squedas simples por palabras clave\")\n",
        "print(\"    ‚úÖ Necesitas resultados r√°pidos\")\n",
        "print(\"    ‚úÖ No necesitas filtrar por documento espec√≠fico\")\n",
        "print(\"\\n  Metadata Filtering:\")\n",
        "print(\"    ‚úÖ Buscar solo en documentos espec√≠ficos\")\n",
        "print(\"    ‚úÖ Filtrar por fecha, autor, tipo de documento\")\n",
        "print(\"    ‚úÖ Necesitas precisi√≥n en documentos conocidos\")\n",
        "print(\"\\n  Parent-Child Retriever:\")\n",
        "print(\"    ‚úÖ Necesitas contexto completo de una secci√≥n\")\n",
        "print(\"    ‚úÖ Buscar en Pages y obtener todos sus Chunks\")\n",
        "print(\"    ‚úÖ Quieres mantener estructura jer√°rquica\")\n",
        "\n",
        "print(\"\\nüí° Mejores Pr√°cticas:\")\n",
        "print(\"  1. Empieza con Basic Retriever para b√∫squedas simples\")\n",
        "print(\"  2. Usa Metadata Filtering cuando conozcas el documento\")\n",
        "print(\"  3. Usa Parent-Child cuando necesites contexto completo\")\n",
        "print(\"  4. Combina con b√∫squeda vectorial para mejor precisi√≥n (ver 3.2)\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen Final\n",
        "\n",
        "### Patrones B√°sicos GraphRAG\n",
        "\n",
        "| Patr√≥n | Velocidad | Precisi√≥n | Mejor Para |\n",
        "|--------|-----------|-----------|------------|\n",
        "| **Basic Retriever** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | B√∫squedas simples y r√°pidas |\n",
        "| **Metadata Filtering** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Filtrar por documento espec√≠fico |\n",
        "| **Parent-Child Retriever** | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Contexto jer√°rquico completo |\n",
        "\n",
        "### Siguiente Paso\n",
        "\n",
        "Una vez que dominas los patrones b√°sicos, contin√∫a con:\n",
        "- **3.4 Advanced GraphRAG Patterns** - Patrones avanzados con GDS y vector search mejorado\n",
        "- **3.2 Basic Retrieval Patterns** - B√∫squeda vectorial e h√≠brida\n",
        "\n",
        "## Referencias\n",
        "\n",
        "- [GraphRAG Pattern Catalog](https://graphrag.com/reference/)\n",
        "- [API de B√∫squeda](../../docs/api/search-patterns.md)\n",
        "- [Neo4j Cypher Manual](https://neo4j.com/docs/cypher-manual/)\n",
        "- [GraphRAGSearchPatterns Service](../../src/infrastructure/services/graphrag_search_patterns.py)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
