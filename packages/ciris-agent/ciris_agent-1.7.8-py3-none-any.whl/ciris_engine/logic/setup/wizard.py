"""Interactive setup wizard for first-run CIRIS configuration.

Mirrors the functionality of scripts/install.sh env creation (lines 673-849).
"""

import logging
import secrets
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

from ciris_engine.config.ciris_services import get_billing_url
from ciris_engine.constants import CIRIS_VERSION

logger = logging.getLogger(__name__)


def generate_encryption_key() -> str:
    """Generate a secure 32-byte base64-encoded encryption key.

    Equivalent to: openssl rand -base64 32

    Returns:
        Base64-encoded random key
    """
    random_bytes = secrets.token_bytes(32)
    import base64

    return base64.b64encode(random_bytes).decode("utf-8")


def prompt_llm_configuration() -> tuple[str, str, str, str]:
    """Interactively prompt for LLM configuration.

    Returns:
        Tuple of (provider, api_key, base_url, model)
    """
    print("\n" + "=" * 70)
    print("LLM CONFIGURATION")
    print("=" * 70)
    print()
    print("CIRIS can work with OpenAI or any OpenAI-compatible LLM provider.")
    print()
    print("Options:")
    print("  1) OpenAI (requires API key)")
    print("  2) Local LLM (Ollama, LM Studio, vLLM, etc.)")
    print("  3) Other provider (Together AI, Groq, Fireworks, etc.)")
    print()

    choice = input("Select option [1-3] (default: 1): ").strip() or "1"

    if choice == "1":
        # OpenAI
        print()
        api_key = input("Enter your OpenAI API key (or press Enter to skip): ").strip()
        if not api_key:
            print("‚ö†Ô∏è  No API key provided. You'll need to add it to .env later.")
            api_key = "your_openai_api_key_here"
        return ("openai", api_key, "", "")

    elif choice == "2":
        # Local LLM
        print()
        print("Local LLM Setup")
        print("Popular options:")
        print("  - Ollama:    http://localhost:11434")
        print("  - LM Studio: http://localhost:1234/v1")
        print("  - vLLM:      http://localhost:8000/v1")
        print("  - LocalAI:   http://localhost:8080/v1")
        print()

        base_url = input("Enter LLM base URL (default: http://localhost:11434): ").strip()
        base_url = base_url or "http://localhost:11434"

        model = input("Enter model name (default: llama3): ").strip()
        model = model or "llama3"

        api_key = input("Enter API key (or 'local' if no auth) (default: local): ").strip()
        api_key = api_key or "local"

        return ("local", api_key, base_url, model)

    else:
        # Other provider
        print()
        print("Other OpenAI-Compatible Provider")
        print()
        print("Popular providers:")
        print("  - Together AI: https://api.together.xyz/v1")
        print("  - Groq:        https://api.groq.com/openai/v1")
        print("  - Fireworks:   https://api.fireworks.ai/inference/v1")
        print("  - Anyscale:    https://api.endpoints.anyscale.com/v1")
        print()

        base_url = input("Enter API base URL: ").strip()
        if not base_url:
            print("‚ùå Base URL required for custom providers")
            sys.exit(1)

        model = input("Enter model name: ").strip()
        if not model:
            print("‚ùå Model name required")
            sys.exit(1)

        api_key = input("Enter API key: ").strip()
        if not api_key:
            print("‚ùå API key required for commercial providers")
            sys.exit(1)

        return ("other", api_key, base_url, model)


def create_env_file(
    save_path: Path,
    llm_provider: str,
    llm_api_key: str,
    llm_base_url: str,
    llm_model: str,
    agent_port: int = 8080,
) -> None:
    """Create .env configuration file.

    Args:
        save_path: Where to save the .env file
        llm_provider: LLM provider type (openai, local, other)
        llm_api_key: API key for LLM
        llm_base_url: Base URL for OpenAI-compatible endpoint
        llm_model: Model name
        agent_port: Port for agent API (default: 8080)
    """
    # Log what we received for debugging
    logger.info(f"[create_env_file] Received llm_provider='{llm_provider}', llm_base_url='{llm_base_url}'")

    # Generate encryption keys
    secrets_key = generate_encryption_key()
    telemetry_key = generate_encryption_key()

    # Build .env content with version marker
    content = f"""# ENV GENERATED BY CIRIS AGENT VERSION {CIRIS_VERSION}
# Generated on {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
# LLM Provider: {llm_provider}

# ============================================================================
# LLM Configuration
# ============================================================================

"""

    if llm_provider == "openai":
        content += f"""# OpenAI Configuration
OPENAI_API_KEY="{llm_api_key}"

# Optional: Use a different OpenAI model
# OPENAI_MODEL="gpt-4"

# Optional: Use OpenAI-compatible endpoint
# OPENAI_API_BASE="https://api.openai.com/v1"

"""
    else:
        content += f"""# OpenAI-Compatible LLM Configuration
OPENAI_API_KEY="{llm_api_key}"
OPENAI_API_BASE="{llm_base_url}"
OPENAI_MODEL="{llm_model}"

"""
        # If using CIRIS LLM proxy, also set billing token and instructor mode
        if "ciris.ai" in llm_base_url.lower() or "ciris-services" in llm_base_url.lower():
            # Determine billing URL based on LLM proxy URL (match region)
            use_eu_fallback = "ciris-services-2" in llm_base_url.lower()
            billing_url = get_billing_url(use_fallback=use_eu_fallback)

            content += f"""# CIRIS Billing Configuration (Android - uses Google ID token for JWT auth)
CIRIS_BILLING_GOOGLE_ID_TOKEN="{llm_api_key}"
CIRIS_BILLING_API_URL="{billing_url}"

# CIRIS Proxy uses JSON mode for Maverick (native structured output support)
INSTRUCTOR_MODE="JSON"

"""

        content += """# Popular OpenAI-compatible providers:
#
# Local Models:
#   Ollama:    http://localhost:11434
#   LM Studio: http://localhost:1234/v1
#   vLLM:      http://localhost:8000/v1
#   LocalAI:   http://localhost:8080/v1
#
# Commercial Providers:
#   Together AI: https://api.together.xyz/v1
#   Groq:        https://api.groq.com/openai/v1
#   Fireworks:   https://api.fireworks.ai/inference/v1
#   Anyscale:    https://api.endpoints.anyscale.com/v1

"""

    content += f"""# ============================================================================
# Security Keys (auto-generated)
# ============================================================================

SECRETS_MASTER_KEY="{secrets_key}"
TELEMETRY_ENCRYPTION_KEY="{telemetry_key}"

# ============================================================================
# Application Configuration
# ============================================================================

# Log Level
LOG_LEVEL="INFO"

# Ports
CIRIS_AGENT_PORT={agent_port}
CIRIS_API_PORT={agent_port}
NEXT_PUBLIC_API_BASE_URL="http://localhost:{agent_port}"

# Database Paths (using ~/ciris as base directory)
CIRIS_DB_PATH="~/ciris/data/ciris_engine.db"
CIRIS_DATA_DIR="~/ciris/data"
SECRETS_DB_PATH="~/ciris/data/secrets.db"
AUDIT_LOG_PATH="~/ciris/data/audit_logs.jsonl"

# Mark as configured
CIRIS_CONFIGURED="true"

# ============================================================================
# Optional: Discord Integration
# ============================================================================

# Uncomment and configure if using Discord adapter
# DISCORD_BOT_TOKEN="your_discord_bot_token_here"
# DISCORD_CHANNEL_ID="your_channel_id_here"

# ============================================================================
# Optional: Reddit Integration
# ============================================================================

# Uncomment and configure if using Reddit adapter
# CIRIS_REDDIT_CLIENT_ID="your_client_id"
# CIRIS_REDDIT_CLIENT_SECRET="your_client_secret"
# CIRIS_REDDIT_USERNAME="your_username"
# CIRIS_REDDIT_PASSWORD="your_password"

# ============================================================================
# Optional: Production Settings
# ============================================================================

# CIRISNode Configuration
# CIRISNODE_BASE_URL="https://your-cirisnode.com:8001"
# CIRISNODE_AGENT_SECRET_JWT="your_jwt_token"
"""

    # Write file
    save_path.parent.mkdir(parents=True, exist_ok=True)
    save_path.write_text(content, encoding="utf-8")


def run_setup_wizard(save_path: Optional[Path] = None) -> Path:
    """Run the interactive setup wizard.

    Args:
        save_path: Where to save .env file (None = auto-detect)

    Returns:
        Path where .env was saved
    """
    from ciris_engine.logic.setup.first_run import get_default_config_path

    if save_path is None:
        save_path = get_default_config_path()

    print()
    print("=" * 70)
    print(" " * 20 + "CIRIS AGENT SETUP")
    print("=" * 70)
    print()
    print("Welcome to CIRIS! This wizard will help you configure your agent.")
    print()

    # Check if config already exists
    if save_path.exists():
        print(f"‚ö†Ô∏è  Configuration already exists at: {save_path}")
        overwrite = input("Overwrite? [y/N] ").strip().lower()
        if overwrite not in ("y", "yes"):
            print("Setup cancelled. Using existing configuration.")
            return save_path

    # Get LLM configuration
    llm_provider, llm_api_key, llm_base_url, llm_model = prompt_llm_configuration()

    # Create .env file
    print()
    print(f"Creating configuration at: {save_path}")
    create_env_file(
        save_path=save_path,
        llm_provider=llm_provider,
        llm_api_key=llm_api_key,
        llm_base_url=llm_base_url,
        llm_model=llm_model,
    )

    print()
    print("=" * 70)
    print("‚úÖ SETUP COMPLETE")
    print("=" * 70)
    print()
    print(f"Configuration saved to: {save_path}")
    print()

    if llm_api_key in ("your_openai_api_key_here", ""):
        print("‚ö†Ô∏è  Remember to add your LLM API key to the .env file!")
        print()

    print("Starting CIRIS Agent...")
    print()
    print("Once started, you can access:")
    print("  üåê Web Interface: http://localhost:8080")
    print("  üì° API Endpoint:  http://localhost:8080/v1/")
    print("  üìö API Docs:      http://localhost:8080/docs")
    print()
    print("Default credentials:")
    print("  Username: admin")
    print("  Password: ciris_admin_password")
    print()

    return save_path
