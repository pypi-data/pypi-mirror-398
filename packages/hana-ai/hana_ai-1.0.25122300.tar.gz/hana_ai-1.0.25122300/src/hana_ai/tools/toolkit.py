"""
Toolkit for interacting with hana-ml.

The following class is available:

    * :class `HANAMLToolkit`
"""
import sys
import socket
from contextlib import closing
import logging
import threading
import time
from typing import Optional, List, Annotated, Any
import inspect
try:
    from pydantic import Field as PydField
except Exception:
    PydField = None
try:
    from typing_extensions import Doc as TxtDoc  # PEP 727 style doc metadata
except Exception:
    TxtDoc = None
try:
    from mcp.server.fastmcp import FastMCP
except ImportError:
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "mcp"])
    from mcp.server.fastmcp import FastMCP

# For HTTP transport support via fastmcp (separate package)
try:
    from fastmcp import FastMCP as FastMCPHTTP
    from fastmcp.tools import Tool as HTTPTool
except ImportError:
    try:
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", "fastmcp"])
        from fastmcp import FastMCP as FastMCPHTTP
        from fastmcp.tools import Tool as HTTPTool
    except Exception:
        FastMCPHTTP = None

from hana_ml import ConnectionContext
from langchain.agents.agent_toolkits.base import BaseToolkit
from langchain.tools import BaseTool

from hana_ai.tools.code_template_tools import GetCodeTemplateFromVectorDB
from hana_ai.tools.hana_ml_tools.fetch_tools import FetchDataTool
from hana_ai.tools.hana_ml_tools.model_storage_tools import DeleteModels, ListModels
from hana_ai.vectorstore.hana_vector_engine import HANAMLinVectorEngine
from hana_ai.tools.hana_ml_tools.additive_model_forecast_tools import AdditiveModelForecastFitAndSave, AdditiveModelForecastLoadModelAndPredict
from hana_ai.tools.hana_ml_tools.cap_artifacts_tools import CAPArtifactsForBASTool, CAPArtifactsTool
from hana_ai.tools.hana_ml_tools.intermittent_forecast_tools import IntermittentForecast
from hana_ai.tools.hana_ml_tools.ts_visualizer_tools import ForecastLinePlot, TimeSeriesDatasetReport
from hana_ai.tools.hana_ml_tools.automatic_timeseries_tools import AutomaticTimeSeriesFitAndSave, AutomaticTimeSeriesLoadModelAndPredict, AutomaticTimeSeriesLoadModelAndScore
from hana_ai.tools.hana_ml_tools.ts_check_tools import TimeSeriesCheck, MassiveTimeSeriesCheck
from hana_ai.tools.hana_ml_tools.ts_outlier_detection_tools import TSOutlierDetection
from hana_ai.tools.hana_ml_tools.ts_accuracy_measure_tools import AccuracyMeasure
from hana_ai.tools.hana_ml_tools.hdi_artifacts_tools import HDIArtifactsTool
from hana_ai.tools.hana_ml_tools.unsupported_tools import ClassificationTool, RegressionTool
from hana_ai.tools.hana_ml_tools.ts_make_predict_table import TSMakeFutureTableTool, TSMakeFutureTableForMassiveForecastTool
from hana_ai.tools.hana_ml_tools.select_statement_to_table_tools import SelectStatementToTableTool
from hana_ai.tools.hana_ml_tools.massive_automatic_timeseries_tools import MassiveAutomaticTimeSeriesFitAndSave, MassiveAutomaticTimeSeriesLoadModelAndPredict, MassiveAutomaticTimeSeriesLoadModelAndScore
from hana_ai.tools.hana_ml_tools.massive_ts_outlier_detection_tools import MassiveTSOutlierDetection

class HANAMLToolkit(BaseToolkit):
    """
    Toolkit for interacting with HANA SQL.

    Parameters
    ----------
    connection_context : ConnectionContext
        Connection context to the HANA database.
    used_tools : list, optional
        List of tools to use. If None or 'all', all tools are used. Default to None.

    Examples
    --------
    Assume cc is a connection to a SAP HANA instance:

    >>> from hana_ai.tools.toolkit import HANAMLToolkit
    >>> from hana_ai.agents.hanaml_agent_with_memory import HANAMLAgentWithMemory

    >>> tools = HANAMLToolkit(connection_context=cc, used_tools='all').get_tools()
    >>> chatbot = HANAMLAgentWithMemory(llm=llm, toos=tools, session_id='hana_ai_test', n_messages=10)
    """
    vectordb: Optional[HANAMLinVectorEngine] = None
    connection_context: ConnectionContext = None
    used_tools: Optional[list] = None
    default_tools: List[BaseTool] = None

    def __init__(self, connection_context, used_tools=None, return_direct=None):
        super().__init__(connection_context=connection_context)
        self.default_tools = [
            AccuracyMeasure(connection_context=self.connection_context),
            AdditiveModelForecastFitAndSave(connection_context=self.connection_context),
            AdditiveModelForecastLoadModelAndPredict(connection_context=self.connection_context),
            AutomaticTimeSeriesFitAndSave(connection_context=self.connection_context),
            AutomaticTimeSeriesLoadModelAndPredict(connection_context=self.connection_context),
            AutomaticTimeSeriesLoadModelAndScore(connection_context=self.connection_context),
            CAPArtifactsTool(connection_context=self.connection_context),
            DeleteModels(connection_context=self.connection_context),
            FetchDataTool(connection_context=self.connection_context),
            ForecastLinePlot(connection_context=self.connection_context),
            IntermittentForecast(connection_context=self.connection_context),
            ListModels(connection_context=self.connection_context),
            HDIArtifactsTool(connection_context=self.connection_context),
            TimeSeriesDatasetReport(connection_context=self.connection_context),
            TimeSeriesCheck(connection_context=self.connection_context),
            TSOutlierDetection(connection_context=self.connection_context),
            ClassificationTool(connection_context=self.connection_context),
            RegressionTool(connection_context=self.connection_context),
            TSMakeFutureTableTool(connection_context=self.connection_context),
            SelectStatementToTableTool(connection_context=self.connection_context),
            MassiveAutomaticTimeSeriesFitAndSave(connection_context=self.connection_context),
            MassiveAutomaticTimeSeriesLoadModelAndPredict(connection_context=self.connection_context),
            MassiveAutomaticTimeSeriesLoadModelAndScore(connection_context=self.connection_context),
            MassiveTimeSeriesCheck(connection_context=self.connection_context),
            TSMakeFutureTableForMassiveForecastTool(connection_context=self.connection_context),
            MassiveTSOutlierDetection(connection_context=self.connection_context)
        ]
        if isinstance(return_direct, dict):
            for tool in self.default_tools:
                if tool.name in return_direct:
                    tool.return_direct = return_direct[tool.name]
        if isinstance(return_direct, bool):
            for tool in self.default_tools:
                tool.return_direct = return_direct
        if used_tools is None or used_tools == "all":
            self.used_tools = self.default_tools
        else:
            if isinstance(used_tools, str):
                used_tools = [used_tools]
            self.used_tools = []
            for tool in self.default_tools:
                if tool.name in used_tools:
                    self.used_tools.append(tool)

    def add_custom_tool(self, tool: BaseTool):
        """
        Add a custom tool to the toolkit.

        Parameters
        ----------
        tool : BaseTool
            Custom tool to add.

            .. note::

                The tool must be a subclass of BaseTool. Please follow the guide to create the custom tools https://python.langchain.com/docs/how_to/custom_tools/.
        """
        self.used_tools.append(tool)

    def delete_tool(self, tool_name: str):
        """
        Delete a tool from the toolkit.

        Parameters
        ----------
        tool_name : str
            Name of the tool to delete.
        """
        for tool in self.used_tools:
            if tool.name == tool_name:
                self.used_tools.remove(tool)
                break

    def set_bas(self, bas=True):
        """
        Set the BAS mode for all tools in the toolkit.
        """
        for tool in self.used_tools:
            if hasattr(tool, "bas"):
                tool.bas = bas
        # remove the GetCodeTemplateFromVectorDB tool if it is in the used_tools
        for tool in self.used_tools:
            if isinstance(tool, CAPArtifactsTool):
                self.used_tools.remove(tool)
                break
        self.used_tools.append(CAPArtifactsForBASTool(connection_context=self.connection_context))
        return self

    def set_vectordb(self, vectordb):
        """
        Set the vector database.

        Parameters
        ----------
        vectordb : HANAMLinVectorEngine
            Vector database.
        """
        self.vectordb = vectordb

    def is_port_available(self, port: int) -> bool:
        """Ê£ÄÊü•Á´ØÂè£ÊòØÂê¶ÂèØÁî®"""
        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
            try:
                s.bind(('127.0.0.1', port))
                return True
            except OSError:
                return False

    def launch_mcp_server(
        self,
        server_name: str = "HANATools",
        host: str = "127.0.0.1",
        transport: str = "stdio",
        port: int = 8001,
        auth_token: Optional[str] = None,
        max_retries: int = 5
    ):
        """
        Launch the MCP server with the specified configuration.
        This method initializes the MCP server, registers all tools, and starts the server in a background thread.
        If the specified port is occupied, it will try the next port up to `max_retries` times.

        Parameters
        ----------
        server_name : str
            Name of the server. Default is "HANATools".
        host : str
            Host address for the server.
        transport : {"stdio", "sse", "http"}
            Transport protocol to use. Default is "stdio". Can be "sse" for Server-Sent Events.
        port : int
            Network port to use for server transports that require a port (SSE/HTTP). Default is 8001. Ignored for stdio.
        auth_token : str, optional
            Authentication token for the server. If provided, the server will require this token for access.
        max_retries : int
            Maximum number of retries to find an available port. Default is 5.
        """
        attempts = 0
        original_port = port

        while attempts < max_retries:
            # ÂàùÂßãÂåñMCPÈÖçÁΩÆ
            server_settings = {
                "name": server_name,
                "host": host
            }

            # Êõ¥Êñ∞Á´ØÂè£ËÆæÁΩÆ
            if transport == "sse":
                # Ê£ÄÊü•Á´ØÂè£ÂèØÁî®ÊÄß
                if not self.is_port_available(port):
                    logging.warning("‚ö†Ô∏è  Port %s occupied, trying next port", port)
                    port += 1
                    attempts += 1
                    time.sleep(0.2)
                    continue

                server_settings.update({
                    "port": port,
                    "sse_path": '/sse'
                })

            # ÂàõÂª∫MCPÂÆû‰æãÔºàstdio/sse ‰ΩøÁî® mcp.server.fastmcpÔºõhttp ‰ΩøÁî® fastmcpÔºâ
            if transport == "http":
                if FastMCPHTTP is None or HTTPTool is None:
                    logging.error("HTTP transport requested but 'fastmcp' package is unavailable.")
                    raise RuntimeError("HTTP transport not supported (fastmcp missing)")
                # ‰∏∫ HTTP È¢ÑÊûÑÂª∫ Tool ÂàóË°®ÔºàÊñπÊ°àCÔºöÊòæÂºè inputSchemaÔºâ
                pre_tools = []
                for tool in self.get_tools():
                    if hasattr(tool, 'args_schema') and tool.args_schema:
                        try:
                            schema = None
                            if hasattr(tool.args_schema, 'model_json_schema'):
                                schema = tool.args_schema.model_json_schema(by_alias=True)
                            elif hasattr(tool.args_schema, 'schema'):
                                schema = tool.args_schema.schema(by_alias=True)
                            if schema is None:
                                continue
                            http_tool = HTTPTool(
                                name=tool.name,
                                title=getattr(tool, 'name', None),
                                description=getattr(tool, 'description', '') or tool.name,
                                parameters=schema,
                            )
                            pre_tools.append(http_tool)
                        except Exception as e:
                            logging.warning("Failed to build explicit schema for %s: %s", tool.name, e)
                # fastmcp ÁöÑÊûÑÈÄ†ÂáΩÊï∞‰ª• name ‰Ωú‰∏∫‰ΩçÁΩÆÂèÇÊï∞ÔºåÂπ∂ÊîØÊåÅ tools ÂàóË°®
                mcp = FastMCPHTTP(server_settings.get("name", "HANATools"), tools=pre_tools, host=server_settings.get("host", "127.0.0.1"), port=port, streamable_http_path="/mcp", json_response=True)
                # Ê£ÄÊü•Á´ØÂè£ÂèØÁî®ÊÄß
                if not self.is_port_available(port):
                    logging.warning("‚ö†Ô∏è  Port %s occupied, trying next port", port)
                    port += 1
                    attempts += 1
                    time.sleep(0.2)
                    continue
            else:
                mcp = FastMCP(**server_settings)

            # Ëé∑ÂèñÂπ∂Ê≥®ÂÜåÊâÄÊúâÂ∑•ÂÖ∑
            tools = self.get_tools()
            registered_tools = []
            for tool in tools:
                # ‰∏∫ FastMCP ÊûÑÂª∫Â∏¶ÁúüÂÆûÂèÇÊï∞Á≠æÂêç‰∏éÊèèËø∞ÁöÑÂåÖË£ÖÂô®ÔºàÊñπÊ°àAÔºâ
                # 1) Âü∫Á°ÄÂåÖË£ÖÊâßË°å‰ΩìÔºàÊé•Êî∂ÂëΩÂêçÂèÇÊï∞Ôºâ
                def _exec_wrapper(wrapped_tool):
                    def _inner(**kwargs):
                        try:
                            return wrapped_tool._run(**kwargs)
                        except Exception as e:
                            logging.error("Tool %s failed: %s", wrapped_tool.name, str(e))
                            return {"error": str(e), "tool": wrapped_tool.name}
                    return _inner

                tool_wrapper = _exec_wrapper(tool)
                tool_wrapper.__name__ = tool.name
                tool_wrapper.__doc__ = tool.description

                # 2) ‰ªé Pydantic args_schema Ê¥æÁîüÂèÇÊï∞Á≠æÂêç‰∏éÊ≥®Ëß£ÔºàÂåÖÂê´ÊèèËø∞Ôºâ
                parameters = []
                annotations: dict[str, Any] = {}
                required_fields = []

                if hasattr(tool, 'args_schema') and tool.args_schema:
                    schema_model = tool.args_schema
                    # Ëé∑Âèñ required ÂàóË°®ÔºåÂÖºÂÆπ v1/v2
                    required_fields = []
                    try:
                        if hasattr(schema_model, 'model_json_schema'):
                            # pydantic v2
                            json_schema = schema_model.model_json_schema()
                            required_fields = json_schema.get('required', []) or []
                        elif hasattr(schema_model, 'schema'):
                            # pydantic v1
                            json_schema = schema_model.schema()
                            required_fields = json_schema.get('required', []) or []
                    except Exception:  # ÂÆπÈîô
                        required_fields = []

                    # Â≠óÊÆµÂàóË°®‰∏éÁ±ªÂûã/ÊèèËø∞/ÈªòËÆ§
                    if hasattr(schema_model, 'model_fields'):
                        # pydantic v2
                        fields_iter = schema_model.model_fields.items()
                        for fname, finfo in fields_iter:
                            ftype = getattr(finfo, 'annotation', Any)
                            fdesc = getattr(finfo, 'description', None)
                            # ‰ΩøÁî® Annotated Ê≥®ÂÖ•ÊèèËø∞ÔºåËã•Êó†ÊèèËø∞Âàô‰∏çÂåÖË£π
                            if fdesc and PydField is not None:
                                annotated_type = Annotated[ftype, PydField(description=fdesc)]
                            elif fdesc and TxtDoc is not None:
                                annotated_type = Annotated[ftype, TxtDoc(fdesc)]
                            else:
                                annotated_type = ftype

                            annotations[fname] = annotated_type

                            # ÈªòËÆ§ÂÄºÂ§ÑÁêÜÔºöËã•ÂøÖÂ°´ÔºåÂàôÊó†ÈªòËÆ§ÔºõÂê¶Âàô‰ΩøÁî®Â≠óÊÆµÈªòËÆ§ÔºàÂèØ‰∏∫ NoneÔºâ
                            default_exists = hasattr(finfo, 'default')
                            if fname in required_fields:
                                param = inspect.Parameter(
                                    fname,
                                    kind=inspect.Parameter.KEYWORD_ONLY,
                                    default=inspect._empty
                                )
                            else:
                                default_value = getattr(finfo, 'default', None) if default_exists else None
                                param = inspect.Parameter(
                                    fname,
                                    kind=inspect.Parameter.KEYWORD_ONLY,
                                    default=default_value
                                )
                            parameters.append(param)
                    elif hasattr(schema_model, '__fields__'):
                        # pydantic v1
                        fields_iter = schema_model.__fields__.items()
                        for fname, mfield in fields_iter:
                            ftype = mfield.outer_type_ if hasattr(mfield, 'outer_type_') else mfield.type_ if hasattr(mfield, 'type_') else Any
                            fdesc = None
                            try:
                                # v1: ÊèèËø∞Âú® field_info.description
                                fdesc = getattr(mfield.field_info, 'description', None)
                            except Exception:
                                fdesc = None

                            if fdesc and PydField is not None:
                                annotated_type = Annotated[ftype, PydField(description=fdesc)]
                            elif fdesc and TxtDoc is not None:
                                annotated_type = Annotated[ftype, TxtDoc(fdesc)]
                            else:
                                annotated_type = ftype

                            annotations[fname] = annotated_type

                            # ÂøÖÂ°´Âà§Êñ≠Ôºö‰ºòÂÖà‰ΩøÁî® required ÂàóË°®ÔºõÂê¶Âàô‰ΩøÁî® mfield.required
                            is_required = fname in required_fields
                            if not is_required:
                                try:
                                    is_required = bool(getattr(mfield, 'required', False))
                                except Exception:
                                    is_required = False

                            if is_required:
                                param = inspect.Parameter(
                                    fname,
                                    kind=inspect.Parameter.KEYWORD_ONLY,
                                    default=inspect._empty
                                )
                            else:
                                default_value = None
                                try:
                                    default_value = mfield.default if hasattr(mfield, 'default') else None
                                except Exception:
                                    default_value = None
                                param = inspect.Parameter(
                                    fname,
                                    kind=inspect.Parameter.KEYWORD_ONLY,
                                    default=default_value
                                )
                            parameters.append(param)

                # Â∫îÁî®Á≠æÂêç‰∏éÊ≥®Ëß£Âà∞ÂåÖË£ÖÂô®
                if parameters:
                    sig = inspect.Signature(parameters=parameters)
                    try:
                        tool_wrapper.__signature__ = sig
                    except Exception:
                        pass
                if annotations:
                    tool_wrapper.__annotations__ = annotations

                # 3) Ê≥®ÂÜåÂà∞ MCP
                if transport != "http":
                    # stdio/sseÔºöÂÖàÊ≥®ÂÜåÂáΩÊï∞Â∑•ÂÖ∑ÔºåÂÜçË¶ÜÁõñÂÖ∂ÂèÇÊï∞ schema ‰∏∫ÊòæÂºè Pydantic JSON SchemaÔºàÊñπÊ°àCÔºâ
                    mcp.tool()(tool_wrapper)
                    try:
                        explicit_schema = None
                        if hasattr(tool, 'args_schema') and tool.args_schema:
                            if hasattr(tool.args_schema, 'model_json_schema'):
                                explicit_schema = tool.args_schema.model_json_schema(by_alias=True)
                            elif hasattr(tool.args_schema, 'schema'):
                                explicit_schema = tool.args_schema.schema(by_alias=True)
                        if explicit_schema:
                            # Ëé∑ÂèñÂÜÖÈÉ® Tool Âπ∂Ë¶ÜÁõñ parametersÔºàlist_tools Â∞ÜËøîÂõûÊ≠§ schemaÔºâ
                            info = getattr(mcp, '_tool_manager', None)
                            if info is not None:
                                internal_tool = info.get_tool(tool.name)
                                if internal_tool is not None:
                                    internal_tool.parameters = explicit_schema
                                    logging.debug("üß© Overrode schema for %s", tool.name)
                    except Exception as e:
                        logging.warning("Failed to override schema for %s: %s", tool.name, e)
                registered_tools.append(tool.name)
                try:
                    param_list = list(getattr(tool_wrapper, "__signature__", inspect.Signature()).parameters.keys())
                except Exception:
                    param_list = []
                logging.info("‚úÖ Registered tool: %s", tool.name)
                logging.debug("üîé Params for %s: %s", tool.name, ", ".join(param_list))

            # ÂÆâÂÖ®ÈÖçÁΩÆ
            server_args = {"transport": transport}
            if transport == "stdio" and not hasattr(sys.stdout, 'buffer'):
                logging.warning("‚ö†Ô∏è  Unsupported stdio, switching to SSE")
                transport = "sse"
                port = original_port  # ÈáçÁΩÆÁ´ØÂè£ÈáçËØï
                attempts = 0         # ÈáçÁΩÆÂ∞ùËØïÊ¨°Êï∞
                continue

            if auth_token:
                server_args["auth_token"] = auth_token
                logging.info("üîê Authentication enabled")

            # ÂêØÂä®ÊúçÂä°Âô®Á∫øÁ®ã
            def run_server(mcp_instance, server_args):
                try:
                    logging.info("üöÄ Starting MCP server on port %s...", port)
                    if server_args.get("transport") == "http":
                        # fastmcp HTTP ËøêË°åÂèÇÊï∞
                        # ‰ΩøÁî®Ê†áÂáÜË∑ØÂæÑ /mcpÔºåÂπ∂ÂêØÁî® JSON ÂìçÂ∫î
                        mcp_instance.run(
                            transport="http",
                            host=server_settings.get("host", "127.0.0.1"),
                            port=port,
                            path="/mcp",
                            json_response=True,
                        )
                    else:
                        mcp_instance.run(**server_args)
                except Exception as e:
                    logging.error("Server crashed: %s", str(e))
                    # ËøôÈáå‰∏çÂÜçËá™Âä®ÈáçÂêØÔºåÁî±Â§ñÈÉ®ÁõëÊéß

            logging.info("Starting MCP server in background thread...")
            server_thread = threading.Thread(
                target=run_server,
                args=(mcp, server_args),
                name=f"MCP-Server-Port-{port}",
                daemon=True
            )
            server_thread.start()
            logging.info("üöÄ MCP server started on port %s with tools: %s", port, registered_tools)
            return  # ÊàêÂäüÂêØÂä®ÔºåÈÄÄÂá∫ÂáΩÊï∞

        # ÊâÄÊúâÂ∞ùËØïÂ§±Ë¥•
        logging.error("‚ùå Failed to start server after %s attempts", max_retries)
        raise RuntimeError(f"Could not find available port in range {original_port}-{original_port + max_retries}")

    class Config:
        """Configuration for this pydantic object."""

        arbitrary_types_allowed = True

    def get_tools(self) -> List[BaseTool]:
        """Get the tools in the toolkit."""
        if self.vectordb is not None:
            get_code = GetCodeTemplateFromVectorDB()
            get_code.set_vectordb(self.vectordb)
            return self.used_tools + [get_code]
        return self.used_tools
