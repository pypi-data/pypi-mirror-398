# 模型 (Models) 模块

模型模块提供嵌入模型的查询功能。

## 方法列表

| 方法                      | 描述                   |
| ------------------------- | ---------------------- |
| `list_embedding_models()` | 获取可用的嵌入模型列表 |

---

## list_embedding_models() - 获取嵌入模型列表

获取当前工作区可用的文本嵌入模型列表。

### 参数

无

### 返回值

`EmbeddingModelResponse` - 嵌入模型列表响应

### 示例

```python
response = client.models.list_embedding_models()

for model in response.data:
    print(f"提供商: {model.provider}")
    print(f"模型: {model.model}")
    print(f"类型: {model.model_type}")
    print("---")
```

### 完整示例

```python
from dify_dataset_sdk import DifyDatasetClient

with DifyDatasetClient(api_key="your-api-key") as client:
    # 获取可用的嵌入模型
    response = client.models.list_embedding_models()

    print("可用的嵌入模型:")
    for model in response.data:
        print(f"  - {model.provider}/{model.model}")

    # 创建数据集时使用特定的嵌入模型
    if response.data:
        first_model = response.data[0]
        dataset = client.datasets.create(
            name="使用指定模型的知识库",
            embedding_model=first_model.model,
            embedding_model_provider=first_model.provider
        )
        print(f"创建数据集: {dataset.id}")
```

---

## 数据模型

### EmbeddingModelResponse

```python
class EmbeddingModelResponse:
    data: List[EmbeddingModel]   # 嵌入模型列表
```

### EmbeddingModel

```python
class EmbeddingModel:
    provider: str                # 模型提供商（如 openai, azure_openai）
    label: Label                 # 显示标签
    icon_small: Optional[Icon]   # 小图标
    icon_large: Optional[Icon]   # 大图标
    status: str                  # 状态
    models: List[ModelInfo]      # 模型详情列表
```

### ModelInfo

```python
class ModelInfo:
    model: str                   # 模型标识符
    label: Label                 # 显示标签
    model_type: str              # 模型类型（text-embedding）
    features: Optional[List[str]]  # 特性列表
    fetch_from: str              # 获取来源
    model_properties: ModelProperties  # 模型属性
    deprecated: bool             # 是否已弃用
    status: str                  # 状态
```

### ModelProperties

```python
class ModelProperties:
    context_size: int            # 上下文大小
    max_chunks: int              # 最大分块数
```

---

## 使用场景

### 1. 查看所有可用模型

```python
response = client.models.list_embedding_models()

for provider_group in response.data:
    print(f"\n提供商: {provider_group.provider}")
    for model in provider_group.models:
        status = "可用" if model.status == "active" else "不可用"
        deprecated = " (已弃用)" if model.deprecated else ""
        print(f"  - {model.model} [{status}]{deprecated}")
```

### 2. 选择最佳模型创建数据集

```python
response = client.models.list_embedding_models()

# 筛选可用的非弃用模型
available_models = []
for provider_group in response.data:
    if provider_group.status == "active":
        for model in provider_group.models:
            if model.status == "active" and not model.deprecated:
                available_models.append({
                    "provider": provider_group.provider,
                    "model": model.model,
                    "context_size": model.model_properties.context_size
                })

# 选择上下文最大的模型
if available_models:
    best_model = max(available_models, key=lambda x: x["context_size"])

    dataset = client.datasets.create(
        name="高质量知识库",
        embedding_model=best_model["model"],
        embedding_model_provider=best_model["provider"],
        indexing_technique="high_quality"
    )
    print(f"使用模型 {best_model['model']} 创建数据集")
```

### 3. 检查特定模型是否可用

```python
def is_model_available(client, provider_name: str, model_name: str) -> bool:
    """检查指定模型是否可用"""
    response = client.models.list_embedding_models()

    for provider_group in response.data:
        if provider_group.provider == provider_name:
            for model in provider_group.models:
                if model.model == model_name:
                    return model.status == "active" and not model.deprecated
    return False

# 使用示例
if is_model_available(client, "openai", "text-embedding-ada-002"):
    print("OpenAI Ada 模型可用")
else:
    print("OpenAI Ada 模型不可用，请选择其他模型")
```
