"""
Training script for AUPredictionNet

Trains a neural network to predict 17 Action Unit intensities from
aligned face images.

Uses HDF5 training data generated by TrainingDataGenerator.

Usage:
    python train_au_prediction.py --data training_data.h5 --output models/au_prediction

    # Resume training
    python train_au_prediction.py --data training_data.h5 --resume models/au_prediction/checkpoint_best.pt
"""

import argparse
import json
import time
from pathlib import Path
from typing import Dict, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split

from .au_prediction_net import (
    AUPredictionNet,
    EnhancedAUPredictionNet,
    AUPredictionLoss,
    AU_NAMES,
    NUM_AUS,
    export_au_to_onnx,
    export_au_to_coreml,
)

# Add parent path for data module
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from pyfaceau.data.hdf5_dataset import PyTorchTrainingDataset, create_video_stratified_split


class WarmupCosineScheduler:
    """Learning rate scheduler with linear warmup and cosine annealing."""

    def __init__(self, optimizer, warmup_epochs: int, total_epochs: int, min_lr: float = 1e-6):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.min_lr = min_lr
        self.base_lrs = [group['lr'] for group in optimizer.param_groups]
        self.current_epoch = 0

    def step(self):
        self.current_epoch += 1
        if self.current_epoch <= self.warmup_epochs:
            # Linear warmup
            progress = self.current_epoch / self.warmup_epochs
            for param_group, base_lr in zip(self.optimizer.param_groups, self.base_lrs):
                param_group['lr'] = base_lr * progress
        else:
            # Cosine annealing
            progress = (self.current_epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            for param_group, base_lr in zip(self.optimizer.param_groups, self.base_lrs):
                param_group['lr'] = self.min_lr + (base_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))

    def get_lr(self):
        return [group['lr'] for group in self.optimizer.param_groups]

    def state_dict(self):
        return {'current_epoch': self.current_epoch}

    def load_state_dict(self, state_dict):
        self.current_epoch = state_dict['current_epoch']


class AUTrainer:
    """
    Trainer for AUPredictionNet.

    Handles training loop, validation, checkpointing, and metrics tracking.
    """

    def __init__(
        self,
        model: AUPredictionNet,
        train_loader: DataLoader,
        val_loader: DataLoader,
        device: torch.device,
        output_dir: Path,
        learning_rate: float = 1e-3,
        weight_decay: float = 1e-4,
        smooth_l1_weight: float = 1.0,
        ccc_weight: float = 0.5,
        num_epochs: int = 100,
        warmup_epochs: int = 5,
    ):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Loss function
        self.criterion = AUPredictionLoss(
            smooth_l1_weight=smooth_l1_weight,
            ccc_weight=ccc_weight,
        )

        # Optimizer
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay,
        )

        # Learning rate scheduler with warmup + cosine annealing
        self.scheduler = WarmupCosineScheduler(
            self.optimizer,
            warmup_epochs=warmup_epochs,
            total_epochs=num_epochs,
            min_lr=1e-6,
        )

        # Tracking
        self.epoch = 0
        self.best_val_loss = float('inf')
        self.train_history = []
        self.val_history = []

    def train_epoch(self) -> Dict[str, float]:
        """Train for one epoch."""
        self.model.train()

        total_loss = 0.0
        total_l1_loss = 0.0
        total_ccc_loss = 0.0
        num_batches = 0

        for batch in self.train_loader:
            images = batch['image'].to(self.device)
            au_targets = batch['au_intensities'].to(self.device)

            # Forward pass
            au_pred = self.model(images)

            # Compute loss
            losses = self.criterion(au_pred, au_targets)

            # Backward pass
            self.optimizer.zero_grad()
            losses['total'].backward()

            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

            self.optimizer.step()

            # Accumulate
            total_loss += losses['total'].item()
            total_l1_loss += losses['smooth_l1'].item()
            total_ccc_loss += losses['ccc'].item()
            num_batches += 1

        metrics = {
            'loss': total_loss / num_batches,
            'smooth_l1': total_l1_loss / num_batches,
            'ccc_loss': total_ccc_loss / num_batches,
        }

        return metrics

    @torch.no_grad()
    def validate(self) -> Dict[str, float]:
        """Validate on validation set."""
        self.model.eval()

        total_loss = 0.0
        total_l1_loss = 0.0
        total_ccc_loss = 0.0
        num_batches = 0

        # For correlation computation
        all_pred = []
        all_target = []

        for batch in self.val_loader:
            images = batch['image'].to(self.device)
            au_targets = batch['au_intensities'].to(self.device)

            # Forward pass
            au_pred = self.model(images)

            # Compute loss
            losses = self.criterion(au_pred, au_targets)

            # Accumulate
            total_loss += losses['total'].item()
            total_l1_loss += losses['smooth_l1'].item()
            total_ccc_loss += losses['ccc'].item()
            num_batches += 1

            # Collect for correlation
            all_pred.append(au_pred.cpu().numpy())
            all_target.append(au_targets.cpu().numpy())

        # Compute metrics
        metrics = {
            'loss': total_loss / num_batches,
            'smooth_l1': total_l1_loss / num_batches,
            'ccc_loss': total_ccc_loss / num_batches,
        }

        # Per-AU correlations
        pred = np.concatenate(all_pred, axis=0)
        target = np.concatenate(all_target, axis=0)

        correlations = []
        maes = []
        for i in range(NUM_AUS):
            if target[:, i].std() > 1e-6:
                corr = np.corrcoef(pred[:, i], target[:, i])[0, 1]
            else:
                corr = 0.0
            correlations.append(corr)
            maes.append(np.abs(pred[:, i] - target[:, i]).mean())

        metrics['mean_correlation'] = np.mean(correlations)
        metrics['mean_mae'] = np.mean(maes)

        # Store per-AU metrics
        for i, name in enumerate(AU_NAMES):
            metrics[f'corr_{name}'] = correlations[i]
            metrics[f'mae_{name}'] = maes[i]

        return metrics

    def train(
        self,
        num_epochs: int,
        save_every: int = 5,
        early_stopping_patience: int = 20,
    ):
        """
        Full training loop.

        Args:
            num_epochs: Number of epochs to train
            save_every: Save checkpoint every N epochs
            early_stopping_patience: Stop if no improvement for N epochs
        """
        no_improvement_count = 0
        start_epoch = self.epoch

        print(f"\nStarting AU training from epoch {start_epoch + 1}")
        print(f"Training samples: {len(self.train_loader.dataset)}")
        print(f"Validation samples: {len(self.val_loader.dataset)}")
        print(f"Device: {self.device}")
        print("-" * 70)

        for epoch in range(start_epoch, start_epoch + num_epochs):
            self.epoch = epoch
            epoch_start = time.time()

            # Train
            train_metrics = self.train_epoch()
            self.train_history.append(train_metrics)

            # Validate
            val_metrics = self.validate()
            self.val_history.append(val_metrics)

            # Update scheduler
            self.scheduler.step()

            epoch_time = time.time() - epoch_start

            # Print progress
            print(
                f"Epoch {epoch + 1:3d} | "
                f"Train Loss: {train_metrics['loss']:.4f} | "
                f"Val Loss: {val_metrics['loss']:.4f} | "
                f"Mean Corr: {val_metrics['mean_correlation']:.4f} | "
                f"Mean MAE: {val_metrics['mean_mae']:.3f} | "
                f"Time: {epoch_time:.1f}s"
            )

            # Check for improvement
            if val_metrics['loss'] < self.best_val_loss:
                self.best_val_loss = val_metrics['loss']
                self.save_checkpoint('checkpoint_best.pt')
                no_improvement_count = 0
                print(f"  -> New best model saved (val_loss: {self.best_val_loss:.4f})")
            else:
                no_improvement_count += 1

            # Save periodic checkpoint
            if (epoch + 1) % save_every == 0:
                self.save_checkpoint(f'checkpoint_epoch_{epoch + 1:03d}.pt')

            # Early stopping
            if no_improvement_count >= early_stopping_patience:
                print(f"\nEarly stopping triggered after {epoch + 1} epochs")
                break

        # Save final checkpoint
        self.save_checkpoint('checkpoint_final.pt')

        # Save training history
        self.save_history()

        # Print per-AU results
        print("\n" + "=" * 70)
        print("Final Per-AU Validation Metrics:")
        print("-" * 70)
        final_val = self.val_history[-1]
        for name in AU_NAMES:
            corr = final_val.get(f'corr_{name}', 0)
            mae = final_val.get(f'mae_{name}', 0)
            print(f"  {name}: Corr={corr:.4f}, MAE={mae:.3f}")
        print("=" * 70)

        print("\nTraining completed!")
        print(f"Best validation loss: {self.best_val_loss:.4f}")

    def save_checkpoint(self, filename: str):
        """Save model checkpoint."""
        checkpoint = {
            'epoch': self.epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_loss': self.best_val_loss,
            'train_history': self.train_history,
            'val_history': self.val_history,
        }
        torch.save(checkpoint, self.output_dir / filename)

    def load_checkpoint(self, checkpoint_path: str):
        """Load model checkpoint."""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        self.epoch = checkpoint['epoch'] + 1
        self.best_val_loss = checkpoint['best_val_loss']
        self.train_history = checkpoint.get('train_history', [])
        self.val_history = checkpoint.get('val_history', [])

        print(f"Loaded checkpoint from epoch {checkpoint['epoch'] + 1}")
        print(f"Best validation loss so far: {self.best_val_loss:.4f}")

    def save_history(self):
        """Save training history to JSON."""
        history = {
            'train': self.train_history,
            'val': self.val_history,
            'best_val_loss': self.best_val_loss,
            'au_names': AU_NAMES,
        }

        # Convert numpy values to Python types for JSON serialization
        def convert(obj):
            if isinstance(obj, dict):
                return {k: convert(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert(v) for v in obj]
            elif isinstance(obj, (np.floating, np.integer)):
                return float(obj)
            return obj

        with open(self.output_dir / 'training_history.json', 'w') as f:
            json.dump(convert(history), f, indent=2)


def create_data_loaders(
    h5_path: str,
    batch_size: int = 32,
    val_split: float = 0.1,
    num_workers: int = 4,
    seed: int = 42,
    augment: bool = True,
    video_stratified: bool = True,
) -> Tuple[DataLoader, DataLoader]:
    """
    Create training and validation data loaders.

    Args:
        h5_path: Path to HDF5 training data
        batch_size: Batch size
        val_split: Fraction of data for validation
        num_workers: Number of data loading workers
        seed: Random seed for split
        augment: Whether to apply data augmentation to training data
        video_stratified: Whether to split by video (prevents data leakage)

    Returns:
        Tuple of (train_loader, val_loader)
    """
    # Load dataset with augmentation enabled for training
    full_dataset = PyTorchTrainingDataset(
        h5_path,
        load_images=True,
        load_hog=False,
        augment=augment,
        augment_prob=0.5,
    )

    # Split into train/val - preferring video-stratified split
    if video_stratified and create_video_stratified_split is not None:
        print("Using video-stratified train/val split (prevents data leakage)")
        train_dataset, val_dataset = create_video_stratified_split(
            full_dataset,
            val_split=val_split,
            seed=seed,
        )
    else:
        # Fallback to random split
        print("Using random train/val split (WARNING: may have data leakage)")
        total_size = len(full_dataset)
        val_size = int(total_size * val_split)
        train_size = total_size - val_size

        generator = torch.Generator().manual_seed(seed)
        train_dataset, val_dataset = random_split(
            full_dataset,
            [train_size, val_size],
            generator=generator,
        )
        print(f"Train/val split: {train_size}/{val_size} samples")

    # Use 'spawn' multiprocessing context for HDF5 compatibility
    mp_context = 'spawn' if num_workers > 0 else None
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True,
        multiprocessing_context=mp_context,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
        multiprocessing_context=mp_context,
    )

    return train_loader, val_loader


def main():
    parser = argparse.ArgumentParser(description='Train AU Prediction Network')

    # Data
    parser.add_argument('--data', type=str, required=True,
                        help='Path to HDF5 training data')
    parser.add_argument('--output', type=str, default='models/au_prediction',
                        help='Output directory for checkpoints')

    # Model selection
    parser.add_argument('--model', type=str, default='basic', choices=['basic', 'enhanced'],
                        help='Model type: basic or enhanced (with attention)')

    # Training
    parser.add_argument('--epochs', type=int, default=100,
                        help='Number of training epochs')
    parser.add_argument('--batch-size', type=int, default=32,
                        help='Batch size')
    parser.add_argument('--lr', type=float, default=1e-3,
                        help='Learning rate')
    parser.add_argument('--weight-decay', type=float, default=1e-4,
                        help='Weight decay')

    # Loss weights
    parser.add_argument('--l1-weight', type=float, default=1.0,
                        help='Smooth L1 loss weight')
    parser.add_argument('--ccc-weight', type=float, default=0.5,
                        help='CCC loss weight')

    # Model architecture
    parser.add_argument('--width-mult', type=float, default=1.0,
                        help='Backbone width multiplier')
    parser.add_argument('--dropout', type=float, default=0.2,
                        help='Dropout rate')
    parser.add_argument('--transformer-layers', type=int, default=2,
                        help='Number of transformer layers (enhanced model only)')

    # Resume
    parser.add_argument('--resume', type=str, default=None,
                        help='Path to checkpoint to resume from')

    # Other
    parser.add_argument('--val-split', type=float, default=0.1,
                        help='Validation split fraction')
    parser.add_argument('--num-workers', type=int, default=4,
                        help='Data loading workers')
    parser.add_argument('--seed', type=int, default=42,
                        help='Random seed')
    parser.add_argument('--save-every', type=int, default=10,
                        help='Save checkpoint every N epochs')
    parser.add_argument('--patience', type=int, default=30,
                        help='Early stopping patience')

    # Best practices options
    parser.add_argument('--augment', action='store_true', default=True,
                        help='Enable data augmentation (default: enabled)')
    parser.add_argument('--no-augment', action='store_true',
                        help='Disable data augmentation')
    parser.add_argument('--video-stratified', action='store_true', default=True,
                        help='Use video-stratified split (default: enabled)')
    parser.add_argument('--no-video-stratified', action='store_true',
                        help='Disable video-stratified split (use random)')
    parser.add_argument('--warmup-epochs', type=int, default=5,
                        help='Number of warmup epochs for LR scheduler')
    parser.add_argument('--multi-gpu', action='store_true',
                        help='Enable multi-GPU training with DataParallel')

    args = parser.parse_args()

    # Set random seeds
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)

    # Device
    if torch.backends.mps.is_available():
        device = torch.device('mps')
    elif torch.cuda.is_available():
        device = torch.device('cuda')
    else:
        device = torch.device('cpu')

    print(f"Using device: {device}")

    # Handle negation flags
    use_augment = args.augment and not args.no_augment
    use_video_stratified = args.video_stratified and not args.no_video_stratified

    # Create data loaders
    print(f"Loading data from: {args.data}")
    print(f"Augmentation: {'enabled' if use_augment else 'disabled'}")
    print(f"Video-stratified split: {'enabled' if use_video_stratified else 'disabled'}")
    print(f"LR warmup: {args.warmup_epochs} epochs")

    train_loader, val_loader = create_data_loaders(
        args.data,
        batch_size=args.batch_size,
        val_split=args.val_split,
        num_workers=args.num_workers,
        seed=args.seed,
        augment=use_augment,
        video_stratified=use_video_stratified,
    )

    # Create model
    if args.model == 'enhanced':
        print("Using EnhancedAUPredictionNet (CBAM + region heads + AU transformer)")
        model = EnhancedAUPredictionNet(
            width_mult=args.width_mult,
            dropout=args.dropout,
            use_correlation_transformer=True,
            transformer_layers=args.transformer_layers,
        )
    else:
        print("Using AUPredictionNet (basic)")
        model = AUPredictionNet(
            width_mult=args.width_mult,
            dropout=args.dropout,
        )
    num_params = sum(p.numel() for p in model.parameters())
    print(f"Model parameters: {num_params:,}")

    # Multi-GPU with DataParallel
    if args.multi_gpu and torch.cuda.device_count() > 1:
        print(f"Multi-GPU: Using {torch.cuda.device_count()} GPUs with DataParallel")
        model = torch.nn.DataParallel(model)
    elif args.multi_gpu:
        print("Multi-GPU: Requested but only 1 GPU available, using single GPU")

    # Create trainer
    trainer = AUTrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        device=device,
        output_dir=args.output,
        learning_rate=args.lr,
        weight_decay=args.weight_decay,
        smooth_l1_weight=args.l1_weight,
        ccc_weight=args.ccc_weight,
        num_epochs=args.epochs,
        warmup_epochs=args.warmup_epochs,
    )

    # Resume if specified
    if args.resume:
        trainer.load_checkpoint(args.resume)

    # Train
    trainer.train(
        num_epochs=args.epochs,
        save_every=args.save_every,
        early_stopping_patience=args.patience,
    )

    # Export trained model
    print("\nExporting trained model...")
    output_dir = Path(args.output)

    # Load best checkpoint
    best_checkpoint = torch.load(output_dir / 'checkpoint_best.pt', map_location='cpu')
    model.load_state_dict(best_checkpoint['model_state_dict'])
    model.eval()

    # Export ONNX
    onnx_path = output_dir / 'au_prediction.onnx'
    export_au_to_onnx(model, str(onnx_path))

    # Export CoreML (if available)
    try:
        coreml_path = output_dir / 'au_prediction.mlpackage'
        export_au_to_coreml(model, str(coreml_path))
    except ImportError:
        print("CoreML export skipped (coremltools not installed)")


if __name__ == '__main__':
    main()
