"""
Cursorignore Generator Tool

Generates .cursorignore and .cursorindexingignore files
based on project structure and best practices.
Based on Cursor IDE Best Practice #9.
"""

import json
import logging
import time
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

# Import error handler
try:
    from ..error_handler import (
        ErrorCode,
        format_error_response,
        format_success_response,
        log_automation_execution,
    )
except ImportError:

    def format_success_response(data, message=None):
        return {"success": True, "data": data, "timestamp": time.time()}

    def format_error_response(error, error_code, include_traceback=False):
        return {"success": False, "error": {"code": str(error_code), "message": str(error)}}

    def log_automation_execution(name, duration, success, error=None):
        logger.info(f"{name}: {duration:.2f}s, success={success}")

    class ErrorCode:
        AUTOMATION_ERROR = "AUTOMATION_ERROR"


# Default patterns to ignore for AI context
DEFAULT_CURSORIGNORE = """# Cursorignore - Files to exclude from AI context
# Generated by Exarp generate_cursorignore tool

# Dependencies
node_modules/
vendor/
.venv/
venv/
__pycache__/
*.pyc
.eggs/
*.egg-info/

# Build outputs
dist/
build/
*.min.js
*.min.css
*.bundle.js
*.map

# IDE/Editor
.idea/
.vscode/
*.swp
*.swo
*~

# OS files
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Test artifacts
coverage/
.coverage
htmlcov/
.pytest_cache/
.tox/

# Secrets (NEVER include in AI context)
.env
.env.*
*.pem
*.key
secrets/
credentials/

# Large data files
*.csv
*.json.gz
*.parquet
data/

# Generated docs (redundant with source)
docs/_build/
site/
"""

# Patterns for indexing ignore (heavier exclusions)
DEFAULT_CURSORINDEXINGIGNORE = """# Cursorindexingignore - Files to exclude from indexing
# Generated by Exarp generate_cursorignore tool

# Include everything from .cursorignore
# Plus additional heavy exclusions:

# Large binary files
*.whl
*.tar.gz
*.zip
*.exe
*.dll
*.so
*.dylib

# Media files
*.png
*.jpg
*.jpeg
*.gif
*.svg
*.ico
*.mp3
*.mp4
*.wav
*.pdf

# Database files
*.db
*.sqlite
*.sqlite3

# Lock files (can be large)
package-lock.json
yarn.lock
poetry.lock
Pipfile.lock
Cargo.lock

# Git internals
.git/

# Large test fixtures
fixtures/
mocks/
__snapshots__/
"""


def generate_cursorignore(
    include_indexing: bool = True,
    custom_patterns: Optional[list[str]] = None,
    analyze_project: bool = True,
    dry_run: bool = False,
) -> str:
    """
    [HINT: Cursorignore. Generates .cursorignore/.cursorindexingignore for AI context.]

    ðŸ“Š Output: Generated ignore patterns, files created/updated
    ðŸ”§ Side Effects: Creates/updates .cursorignore and .cursorindexingignore
    ðŸ“ Analyzes: Project structure for smart pattern detection
    â±ï¸ Typical Runtime: 1-3 seconds

    Example Prompt:
    "Generate cursorignore files to optimize AI context"

    Benefits:
    - Faster AI responses (less context to process)
    - More relevant suggestions (no noise from deps/build)
    - Security (secrets excluded from AI)

    Args:
        include_indexing: Also generate .cursorindexingignore
        custom_patterns: Additional patterns to include
        analyze_project: Auto-detect project-specific patterns
        dry_run: Preview without writing files

    Returns:
        JSON with generated patterns and file paths
    """
    start_time = time.time()

    try:
        from project_management_automation.utils import find_project_root

        project_root = find_project_root()

        # Start with defaults
        cursorignore_content = DEFAULT_CURSORIGNORE
        indexingignore_content = DEFAULT_CURSORINDEXINGIGNORE

        # Analyze project for additional patterns
        detected_patterns = []
        if analyze_project:
            detected_patterns = _detect_project_patterns(project_root)
            if detected_patterns:
                cursorignore_content += "\n# Project-specific patterns\n"
                cursorignore_content += "\n".join(detected_patterns)
                cursorignore_content += "\n"

        # Add custom patterns
        if custom_patterns:
            cursorignore_content += "\n# Custom patterns\n"
            cursorignore_content += "\n".join(custom_patterns)
            cursorignore_content += "\n"

        result = {
            "detected_patterns": detected_patterns,
            "custom_patterns": custom_patterns or [],
            "files": [],
        }

        if not dry_run:
            # Write .cursorignore
            cursorignore_path = project_root / ".cursorignore"
            cursorignore_path.write_text(cursorignore_content)
            result["files"].append(str(cursorignore_path))

            # Write .cursorindexingignore
            if include_indexing:
                indexingignore_path = project_root / ".cursorindexingignore"
                indexingignore_path.write_text(indexingignore_content)
                result["files"].append(str(indexingignore_path))

            result["status"] = "created"
        else:
            result["status"] = "dry_run"
            result["preview"] = {
                "cursorignore_lines": len(cursorignore_content.splitlines()),
                "indexingignore_lines": len(indexingignore_content.splitlines()),
            }

        result["tip"] = "Restart Cursor to apply new ignore patterns"

        duration = time.time() - start_time
        log_automation_execution("generate_cursorignore", duration, True)

        return json.dumps(format_success_response(result), indent=2)

    except Exception as e:
        duration = time.time() - start_time
        log_automation_execution("generate_cursorignore", duration, False, e)
        error_response = format_error_response(e, ErrorCode.AUTOMATION_ERROR)
        return json.dumps(error_response, indent=2)


def _detect_project_patterns(project_root: Path) -> list[str]:
    """Detect project-specific patterns to ignore."""
    patterns = []

    # Python project
    if (project_root / "setup.py").exists() or (project_root / "pyproject.toml").exists():
        patterns.append("*.egg-info/")
        patterns.append(".mypy_cache/")
        patterns.append(".ruff_cache/")

    # Node.js project
    if (project_root / "package.json").exists():
        patterns.append("node_modules/")
        patterns.append(".npm/")
        patterns.append(".yarn/")

    # Rust project
    if (project_root / "Cargo.toml").exists():
        patterns.append("target/")

    # Go project
    if (project_root / "go.mod").exists():
        patterns.append("vendor/")

    # Docker
    if any(project_root.glob("Dockerfile*")):
        patterns.append(".docker/")

    # Terraform
    if any(project_root.glob("*.tf")):
        patterns.append(".terraform/")
        patterns.append("*.tfstate*")

    # Large directories (>100 files or >10MB)
    for subdir in project_root.iterdir():
        if subdir.is_dir() and not subdir.name.startswith("."):
            try:
                file_count = sum(1 for _ in subdir.rglob("*") if _.is_file())
                if file_count > 500:
                    patterns.append(f"{subdir.name}/")
                    logger.info(f"Detected large directory: {subdir.name}/ ({file_count} files)")
            except (PermissionError, OSError):
                pass

    return list(set(patterns))  # Deduplicate

