"""
Adapter Transport Wrapper

This module provides a wrapper around mcp_proxy_adapter JsonRpcClient
that exposes methods needed by EmbeddingServiceAsyncClient.

Author: Vasiliy Zdanovskiy
email: vasilyvz@gmail.com
"""

from typing import Any, Dict, Optional, Callable, Awaitable
import logging

from mcp_proxy_adapter.client.jsonrpc_client import JsonRpcClient  # type: ignore[import-untyped]


logger = logging.getLogger(__name__)


class AdapterTransport:
    """
    Wrapper around JsonRpcClient that provides transport layer for EmbeddingServiceAsyncClient.

    This class encapsulates all adapter-specific logic and provides a clean interface
    that matches the expected behavior of the legacy aiohttp-based transport.
    """

    def __init__(self, adapter_params: Dict[str, Any]):
        """
        Initialize adapter transport with configuration parameters.

        Args:
            adapter_params: Dictionary with protocol, host, port, token_header, token,
                          cert, key, ca, check_hostname, timeout
        """
        self.adapter_params = adapter_params
        self._client: Optional[JsonRpcClient] = None
        self._original_config = adapter_params.get("_original_config")

    async def __aenter__(self):
        """Async context manager entry."""
        await self._ensure_client()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        """Async context manager exit."""
        await self.close()

    async def _ensure_client(self) -> JsonRpcClient:
        """Ensure JsonRpcClient is initialized."""
        if self._client is None:
            # Extract token dynamically if needed (for JWT/Basic)
            token = self.adapter_params.get("token")
            token_header = self.adapter_params.get("token_header")

            # If token is None but we have auth config, generate it
            if token is None and token_header and self._original_config:
                token = await self._generate_token_from_config()

            self._client = JsonRpcClient(
                protocol=self.adapter_params["protocol"],
                host=self.adapter_params["host"],
                port=self.adapter_params["port"],
                token_header=token_header,
                token=token,
                cert=self.adapter_params.get("cert"),
                key=self.adapter_params.get("key"),
                ca=self.adapter_params.get("ca"),
                check_hostname=self.adapter_params.get("check_hostname", False),
            )

        return self._client

    async def _generate_token_from_config(self) -> Optional[str]:
        """
        Generate authentication token from original config if needed.

        This handles JWT and Basic auth token generation.
        """
        if not self._original_config:
            return None

        auth_config = self._original_config.get("auth", {})
        auth_method = auth_config.get("method", "none")

        if auth_method == "jwt":
            # JWT tokens are typically generated by auth manager
            # For now, return None - adapter will handle it via headers
            return None
        elif auth_method == "basic":
            # Basic auth is handled via adapter's token mechanism
            return None

        return None

    async def close(self) -> None:
        """Close the underlying adapter client."""
        if self._client:
            await self._client.close()
            self._client = None

    async def health(self) -> Dict[str, Any]:
        """
        Check service health.

        Returns:
            Health status dictionary
        """
        client = await self._ensure_client()
        return await client.health()

    async def get_openapi_schema(self) -> Dict[str, Any]:
        """
        Get OpenAPI schema.

        Returns:
            OpenAPI schema dictionary
        """
        client = await self._ensure_client()
        return await client.get_openapi_schema()

    async def execute_command(
        self,
        command: str,
        params: Optional[Dict[str, Any]] = None,
        use_cmd_endpoint: bool = False,
    ) -> Dict[str, Any]:
        """
        Execute a command via adapter.

        Args:
            command: Command name
            params: Command parameters
            use_cmd_endpoint: Whether to use /cmd endpoint

        Returns:
            Command execution result
        """
        client = await self._ensure_client()

        logger.info(f"Executing command via adapter: {command}, params={params}")

        if use_cmd_endpoint:
            result = await client.cmd_call(command, params or {})
        else:
            result = await client.execute_command(
                command, params, use_cmd_endpoint=False
            )

        logger.debug(f"Command result: {str(result)[:300]}")
        return result

    async def execute_command_unified(
        self,
        command: str,
        params: Optional[Dict[str, Any]] = None,
        *,
        use_cmd_endpoint: bool = False,
        expect_queue: Optional[bool] = None,
        auto_poll: bool = True,
        poll_interval: float = 1.0,
        timeout: Optional[float] = None,
        status_hook: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
    ) -> Dict[str, Any]:
        """
        Execute command with unified queue/immediate handling.

        Uses standard queue_get_job_status for all commands to avoid MethodNotFoundError
        in server logs. The adapter's internal embed_job_status usage is bypassed.

        Args:
            command: Command name
            params: Command parameters
            use_cmd_endpoint: Whether to use /cmd endpoint
            expect_queue: Force queue assumption
            auto_poll: Auto-poll queue status
            poll_interval: Polling interval
            timeout: Overall timeout
            status_hook: Progress callback

        Returns:
            Unified result with mode indicator
        """
        client = await self._ensure_client()

        # Use auto_poll=False to prevent adapter from using embed_job_status internally
        # Then do polling ourselves using standard queue_get_job_status
        if auto_poll:
            # Execute command without auto-polling
            result = await client.execute_command_unified(
                command=command,
                params=params,
                use_cmd_endpoint=use_cmd_endpoint,
                expect_queue=expect_queue,
                auto_poll=False,  # Disable adapter's auto-poll
                poll_interval=poll_interval,
                timeout=timeout,
                status_hook=status_hook,
            )

            # If queued, poll using standard queue_get_job_status
            if isinstance(result, dict) and result.get("mode") == "queued":
                job_id = result.get("job_id")
                if job_id:
                    import asyncio
                    import time

                    start_time = time.time()
                    timeout_sec = timeout if timeout else 300.0

                    while time.time() - start_time < timeout_sec:
                        status = await self.queue_get_job_status(job_id)

                        if status_hook:
                            await status_hook(status)

                        # Check if job is completed
                        job_status = status.get("status")
                        if job_status in ("completed", "success", "done"):
                            result["status"] = job_status
                            result["result"] = status.get("result")
                            return result

                        if job_status in ("failed", "error"):
                            result["status"] = job_status
                            result["result"] = status.get("result")
                            return result

                        await asyncio.sleep(poll_interval)

                    # Timeout
                    result["status"] = "timeout"
                    return result

            return result
        else:
            # No auto-poll, just execute
            return await client.execute_command_unified(
                command=command,
                params=params,
                use_cmd_endpoint=use_cmd_endpoint,
                expect_queue=expect_queue,
                auto_poll=False,
                poll_interval=poll_interval,
                timeout=timeout,
                status_hook=status_hook,
            )

    async def queue_get_job_status(self, job_id: str) -> Dict[str, Any]:
        """
        Get queue job status.

        Uses standard queue_get_job_status endpoint. The embed_job_status command
        is handled internally by execute_command_unified for embed_queue commands.

        This method is called when job status is checked directly (e.g., via job_status()).
        Since we don't know which command created the job, we use the standard endpoint
        to avoid MethodNotFoundError in server logs for non-embed_queue jobs.

        Args:
            job_id: Job identifier

        Returns:
            Job status dictionary in format expected by execute_command_unified
        """
        client = await self._ensure_client()
        return await client.queue_get_job_status(job_id)

    async def queue_list_jobs(
        self,
        status: Optional[str] = None,
        job_type: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        List queue jobs.

        Args:
            status: Filter by status
            job_type: Filter by job type

        Returns:
            List of jobs
        """
        client = await self._ensure_client()
        return await client.queue_list_jobs(status=status, job_type=job_type)

    async def queue_stop_job(self, job_id: str) -> Dict[str, Any]:
        """
        Stop a queue job.

        Args:
            job_id: Job identifier

        Returns:
            Stop operation result
        """
        client = await self._ensure_client()
        return await client.queue_stop_job(job_id)

    async def queue_delete_job(self, job_id: str) -> Dict[str, Any]:
        """
        Delete a queue job.

        Args:
            job_id: Job identifier

        Returns:
            Delete operation result
        """
        client = await self._ensure_client()
        return await client.queue_delete_job(job_id)

    async def queue_get_job_logs(self, job_id: str) -> Dict[str, Any]:
        """
        Get job logs.

        Args:
            job_id: Job identifier

        Returns:
            Job logs dictionary
        """
        client = await self._ensure_client()
        return await client.queue_get_job_logs(job_id)

    async def get_commands_list(self) -> Dict[str, Any]:
        """
        Get list of available commands.

        Returns:
            Dictionary containing list of commands
        """
        client = await self._ensure_client()
        return await client.get_commands_list()
