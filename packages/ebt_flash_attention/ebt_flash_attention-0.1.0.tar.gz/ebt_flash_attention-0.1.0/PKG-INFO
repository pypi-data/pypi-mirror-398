Metadata-Version: 2.4
Name: ebt_flash_attention
Version: 0.1.0
Summary: Triton implemention of the Energy Based Transformer attention mechanism
Project-URL: Homepage, https://github.com/emiledgl/ebt_flash_attention
Project-URL: Repository, https://github.com/emiledgl/ebt_flash_attention
Author-email: Emile Dugelay <dugelayemile@gmail.com>
License-Expression: MIT
License-File: LICENSE
Keywords: artificial intelligence,deep learning,transformer,triton
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Requires-Dist: torch>=2.9.1
Requires-Dist: triton>=3.5.1
Description-Content-Type: text/markdown

<div align="center">

# EBT Flash Attention

<img src="assets/energy_landscape.png" width="480">

</div>
Triton implemention of the Energy Based Transformer attention mechanism

## Description

Leverage Flash Attention Triton kernel i