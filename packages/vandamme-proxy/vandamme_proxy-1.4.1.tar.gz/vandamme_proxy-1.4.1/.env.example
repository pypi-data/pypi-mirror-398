# Required: Your OpenAI API key
# Single key (traditional)
OPENAI_API_KEY="sk-your-openai-api-key-here"

# Or multiple keys for load balancing and automatic failover
# Keys are tried in round-robin order, with automatic rotation on authentication failures (401/403/429)
# OPENAI_API_KEY="sk-key1 sk-key2 sk-key3"

# Optional: Expected proxy API key for client validation
# If set, clients must provide this exact API key to access the proxy
PROXY_API_KEY="your-expected-proxy-api-key"

# Optional: Default provider for models without prefixes
# Overrides the default_provider setting from src/config/defaults.toml
# If not set, uses value from defaults.toml (defaults to "openai")
# Examples: "openai", "poe", "openrouter", "azure"
VDM_DEFAULT_PROVIDER="poe"

# Optional: OpenAI API base URL (default: https://api.openai.com/v1)
# Used when VDM_DEFAULT_PROVIDER is "openai"
OPENAI_BASE_URL="https://api.openai.com/v1"
AZURE_API_VERSION="2024-03-01-preview"  # For Azure OpenAI

# Multi-Provider Configuration
#
# Provider Discovery:
# - Only providers with {PROVIDER}_API_KEY set are discovered and loaded
# - Providers without API keys are silently ignored
# - For OpenAI and Poe, BASE_URL defaults to standard endpoints if not provided
# - Other providers require both API_KEY and BASE_URL to be configured
#
# Configure providers using: {PROVIDER}_API_KEY and optionally {PROVIDER}_BASE_URL

# Example: Configure Poe.com (BASE_URL is optional - defaults to https://api.poe.com/v1)
# Single key
# POE_API_KEY="your-poe-api-key"
# Or multiple keys for high availability
# POE_API_KEY="poe-key1 poe-key2 poe-backup"
# POE_BASE_URL="https://api.poe.com/v1"  # Optional

# Example: Configure OpenRouter (BASE_URL is required)
# Single key
# OPENROUTER_API_KEY="your-openrouter-api-key"
# Or multiple keys for load balancing
# OPENROUTER_API_KEY="or-key1 or-key2"
# OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"

# Example: Configure Azure OpenAI as a named provider
# Single key
# AZURE_OPENAI_API_KEY="your-azure-api-key"
# Or multiple keys for high availability
# AZURE_OPENAI_API_KEY="azure-key1 azure-key2"
# AZURE_OPENAI_BASE_URL="https://your-resource.openai.azure.com/"
# AZURE_OPENAI_API_VERSION="2024-03-01-preview"

# Example: Configure local models (Ollama)
# OLLAMA_API_KEY="dummy-key"  # Required but can be any value for local models
# OLLAMA_BASE_URL="http://localhost:11434/v1"

# Model Aliases Configuration
#
# There are two ways to configure model aliases:
#
# 1. Environment Variables (explicit configuration - takes precedence)
#    Format: <PROVIDER>_ALIAS_<ALIAS_NAME>=<target_model>
#    Examples:
#    POE_ALIAS_HAIKU="my-custom-haiku-model"
#    OPENAI_ALIAS_FAST="gpt-4o-mini"
#    ANTHROPIC_ALIAS_CHAT="claude-3-5-sonnet-20241022"
#
# 2. TOML Configuration File (fallback defaults)
#    The proxy automatically loads fallback aliases from vandamme-config.toml files.
#
#    Configuration Hierarchy (highest to lowest priority):
#    - ./vandamme-config.toml (project-local overrides)
#    - ~/.config/vandamme-proxy/vandamme-config.toml (user-specific configuration)
#    - src/config/defaults.toml (package defaults)
#
#    Create a vandamme-config.toml file with:
#    [poe]
#    base-url = "https://api.poe.com/v1"  # Optional provider config
#    timeout = 90                           # Optional timeout override
#    [poe.aliases]
#    haiku = "grok-4.1-fast-non-reasoning"  # Used if POE_ALIAS_HAIKU not set
#    sonnet = "glm-4.6"                      # Used if POE_ALIAS_SONNET not set
#    opus = "gpt-5.2"                        # Used if POE_ALIAS_OPUS not set
#
#    [openai]
#    base-url = "https://api.openai.com/v1"
#    [openai.aliases]
#    haiku = "gpt-4o-mini"
#    fast = "gpt-4o"
#
# Special Model Names:
# The proxy provides sensible defaults for special Claude model names:
# - haiku: Fast, lightweight model (defaults to grok-4.1-fast-non-reasoning on Poe)
# - sonnet: Balanced model (defaults to glm-4.6 on Poe)
# - opus: Powerful model (defaults to gpt-5.2 on Poe)
#
# These defaults are automatically applied when you use Claude Code with these model names
# and haven't configured explicit aliases.

# Provider-Specific Custom Headers
# You can add custom headers for specific providers:
# {PROVIDER}_CUSTOM_HEADER_{HEADER_NAME}=value

# Examples:
# POE_CUSTOM_HEADER_X_USER_ID="your-poe-user-id"
# OPENROUTER_CUSTOM_HEADER_HTTP_REFERER="https://yourapp.com"
# AZURE_OPENAI_CUSTOM_HEADER_API_KEY="your-azure-api-key"

# Usage Examples:
# 1. Set default provider to Poe:
#    VDM_DEFAULT_PROVIDER="poe"
#    -> Request with "claude-3-5-sonnet" will use POE_API_KEY and POE_BASE_URL
#
# 2. Use specific provider for a request:
#    -> Request with "openrouter:gpt-4o" will use OPENROUTER_API_KEY and OPENROUTER_BASE_URL
#
# 3. Fallback to OpenAI:
#    -> Request with "gpt-4" (no prefix) will use OPENAI_API_KEY and OPENAI_BASE_URL
#
# 4. Multiple API keys for production:
#    OPENAI_API_KEY="sk-key1 sk-key2 sk-key3"
#    -> Requests will automatically rotate between keys in round-robin order
#    -> Failed keys (401/403/429) will be skipped with automatic failover

# Optional: Server settings
HOST="0.0.0.0"
PORT="8082"
LOG_LEVEL="INFO"
# DEBUG, INFO, WARNING, ERROR, CRITICAL

# Optional: Performance settings
MAX_TOKENS_LIMIT="4096"
# Minimum tokens limit for requests (to avoid errors with thinking model)
MIN_TOKENS_LIMIT="100"
REQUEST_TIMEOUT="90"
MAX_RETRIES="2"

# Global Custom Headers (applied to all providers unless overridden)
# Format: CUSTOM_HEADER_KEY=header_value
# These headers will be automatically included in API requests
# Uncomment the lines below to use custom headers:
# CUSTOM_HEADER_ACCEPT="application/jsonstream"
# CUSTOM_HEADER_CONTENT_TYPE="application/json"
# CUSTOM_HEADER_USER_AGENT="node-fetch"
# CUSTOM_HEADER_HOST="example.com"
# CUSTOM_HEADER_AUTHORIZATION="Bearer your-token"
# CUSTOM_HEADER_X_API_KEY="your-api-key"
# CUSTOM_HEADER_X_CLIENT_ID="your-client-id"
