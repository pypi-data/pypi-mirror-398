{
  "version": "1.0.0",
  "tool_version": "0.1.2",
  "repo_commit": "a4a8171b81423b7b86703d4dfb0d810e79fb531e",
  "scanned_at": "2025-12-22T04:18:11.324563Z",
  "repo": {
    "root": "/Users/jtc/Github/flightline_frontend/cli",
    "files_scanned": 26,
    "languages": [
      "python"
    ]
  },
  "project_signals": {
    "frameworks": [],
    "ai_sdks": [
      "openai"
    ],
    "validation_libraries": [
      "pydantic"
    ]
  },
  "nodes": [
    {
      "id": "test_discover_python_openai_file_a12fa2",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/tests/test_discover.py",
        "line": 36,
        "column": null,
        "function": "python_openai_file",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "content",
            "source_type": "inline",
            "source_hint": "'\\nconst messages = [\\n    { role: \"human\", content: \"What is the capital of France?\" },\\n    { role: \"ai\", content: \"Paris\" }\\n];\\nconst result = await chain.invoke({ \\n    messages,\\n    temperature: 0,\\n    model: \"claude-3\"\\n});\\n'",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": "content",
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [
          "write_text"
        ],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "low",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "Output passed to: write_text",
          "No schema validation on output",
          "Context 'content' from inline",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "test_discover_classify_email_0ed08a",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/tests/test_discover.py",
        "line": 62,
        "column": null,
        "function": "classify_email",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "content",
            "source_type": "inline",
            "source_hint": "'\\nconst messages = [\\n    { role: \"human\", content: \"What is the capital of France?\" },\\n    { role: \"ai\", content: \"Paris\" }\\n];\\nconst result = await chain.invoke({ \\n    messages,\\n    temperature: 0,\\n    model: \"claude-3\"\\n});\\n'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "file_path",
            "source_type": "variable",
            "source_hint": "temp_dir / 'chain.js'",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'content' from inline",
          "Context 'file_path' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "test_discover_summarize_document_d61fde",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/tests/test_discover.py",
        "line": 84,
        "column": null,
        "function": "summarize_document",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "content",
            "source_type": "inline",
            "source_hint": "'\\nconst messages = [\\n    { role: \"human\", content: \"What is the capital of France?\" },\\n    { role: \"ai\", content: \"Paris\" }\\n];\\nconst result = await chain.invoke({ \\n    messages,\\n    temperature: 0,\\n    model: \"claude-3\"\\n});\\n'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "file_path",
            "source_type": "variable",
            "source_hint": "temp_dir / 'chain.js'",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'content' from inline",
          "Context 'file_path' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "test_discover_processApproval_687b86",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/tests/test_discover.py",
        "line": 122,
        "column": null,
        "function": "processApproval",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "content",
            "source_type": "inline",
            "source_hint": "'\\nconst messages = [\\n    { role: \"human\", content: \"What is the capital of France?\" },\\n    { role: \"ai\", content: \"Paris\" }\\n];\\nconst result = await chain.invoke({ \\n    messages,\\n    temperature: 0,\\n    model: \"claude-3\"\\n});\\n'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "file_path",
            "source_type": "variable",
            "source_hint": "temp_dir / 'chain.js'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "data",
            "source_type": "variable",
            "source_hint": "json.load(f)",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'content' from inline",
          "Context 'file_path' from variable",
          "Context 'data' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "test_discover_generateResponse_ce36b7",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/tests/test_discover.py",
        "line": 145,
        "column": null,
        "function": "generateResponse",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "content",
            "source_type": "inline",
            "source_hint": "'\\nconst messages = [\\n    { role: \"human\", content: \"What is the capital of France?\" },\\n    { role: \"ai\", content: \"Paris\" }\\n];\\nconst result = await chain.invoke({ \\n    messages,\\n    temperature: 0,\\n    model: \"claude-3\"\\n});\\n'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "file_path",
            "source_type": "variable",
            "source_hint": "temp_dir / 'chain.js'",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'content' from inline",
          "Context 'file_path' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "test_discover_test_detect_custom_wrapper_9f1b5d",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/tests/test_discover.py",
        "line": 371,
        "column": null,
        "function": "test_detect_custom_wrapper",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "content",
            "source_type": "inline",
            "source_hint": "'\\nconst messages = [\\n    { role: \"human\", content: \"What is the capital of France?\" },\\n    { role: \"ai\", content: \"Paris\" }\\n];\\nconst result = await chain.invoke({ \\n    messages,\\n    temperature: 0,\\n    model: \"claude-3\"\\n});\\n'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "file_path",
            "source_type": "variable",
            "source_hint": "temp_dir / 'chain.js'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "calls",
            "source_type": "variable",
            "source_hint": "detect_heuristic_calls(file_path)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "call",
            "source_type": "variable",
            "source_hint": "calls[0]",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": "content",
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [
          "write_text"
        ],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "Output passed to: write_text",
          "No schema validation on output",
          "Context 'content' from inline",
          "Context 'file_path' from variable",
          "Context 'calls' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "test_discover_test_detect_langchain_style_945998",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/tests/test_discover.py",
        "line": 400,
        "column": null,
        "function": "test_detect_langchain_style",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "content",
            "source_type": "inline",
            "source_hint": "'\\nconst messages = [\\n    { role: \"human\", content: \"What is the capital of France?\" },\\n    { role: \"ai\", content: \"Paris\" }\\n];\\nconst result = await chain.invoke({ \\n    messages,\\n    temperature: 0,\\n    model: \"claude-3\"\\n});\\n'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "file_path",
            "source_type": "variable",
            "source_hint": "temp_dir / 'chain.js'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "calls",
            "source_type": "variable",
            "source_hint": "detect_heuristic_calls(file_path)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "call",
            "source_type": "variable",
            "source_hint": "calls[0]",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "result",
            "source_type": "variable",
            "source_hint": "runner.invoke(cli, ['discover', str(cli_path), '-o', str(out_file), '--json'])",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'content' from inline",
          "Context 'file_path' from variable",
          "Context 'calls' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "generate_generate_records_7ed213",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/mimic/generate.py",
        "line": 80,
        "column": 19,
        "function": "generate_records",
        "class_name": null
      },
      "provider": "openai",
      "call_type": "chat",
      "detection_method": "sdk_verified",
      "confidence": 1.0,
      "inputs": {
        "system_prompt": {
          "source_type": "variable",
          "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': user_prompt}]",
          "inline_content": null,
          "variable_name": null
        },
        "messages": [
          {
            "source_type": "variable",
            "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': user_prompt}]",
            "inline_content": null,
            "variable_name": null
          }
        ],
        "context_variables": [
          {
            "name": "SYSTEM_PROMPT",
            "source_type": "inline",
            "source_hint": "'You are a synthetic data generator. You generate realistic fake data based on a learned data profile.\\n\\nRULES:\\n1. Match the EXACT schema structure - same fields, nesting, and data types\\n2. Follow ALL business rules from the profile\\n3. Generate realistic but FAKE values for PII (names, emails, phones, addresses)\\n4. Make each record UNIQUE with varied values\\n5. Output valid JSON only - a JSON object with a \"records\" array'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "client",
            "source_type": "variable",
            "source_hint": "get_client()",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "user_prompt",
            "source_type": "variable",
            "source_hint": "f'Generate exactly {count} synthetic data records based on this profile.\\n\\nPROFILE:\\n{profile_text}\\n\\nIMPORTANT:\\n- Generate {count} COMPLETE records matching the schema\\n- Each record must have ALL fields from the schema\\n- Follow all business_rules (calculations must be correct!)\\n- Use fake but realistic PII values\\n- Make each record unique\\n\\nOutput as: {{\"records\": [... {count} complete records ...]}}'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "response",
            "source_type": "variable",
            "source_hint": "client.chat.completions.create(model=model, messages=[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': user_prompt}], response_format={'type': 'json_object'}, temperature=0.8)",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "handlebars"
      },
      "outputs": {
        "assigned_to": "response",
        "expected_format": "json",
        "response_format_specified": true,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "No schema validation on output",
          "Prompt from variable: [{'role': 'system', 'content': SYSTEM_PROMPT}, {'r",
          "Context 'SYSTEM_PROMPT' from inline",
          "Context 'client' from variable",
          "Context 'user_prompt' from variable",
          "Uses handlebars templates"
        ],
        "suggested_focus": [
          "Probe for JSON format violations",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "learn_analyze_file_5cc314",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/mimic/learn.py",
        "line": 88,
        "column": 19,
        "function": "analyze_file",
        "class_name": null
      },
      "provider": "openai",
      "call_type": "chat",
      "detection_method": "sdk_verified",
      "confidence": 1.0,
      "inputs": {
        "system_prompt": {
          "source_type": "variable",
          "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}]",
          "inline_content": null,
          "variable_name": null
        },
        "messages": [
          {
            "source_type": "variable",
            "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}]",
            "inline_content": null,
            "variable_name": null
          }
        ],
        "context_variables": [
          {
            "name": "SYSTEM_PROMPT",
            "source_type": "inline",
            "source_hint": "'You are a data analyst expert. Analyze the provided data and create a data profile - a descriptive specification of this data structure.\\n\\nYour profile must include:\\n\\n1. **Schema**: The exact structure/shape of the data (fields, nesting, arrays)\\n2. **Data Types**: The type of each field (string, number, boolean, date, etc.)\\n3. **Business Logic**: Any implicit rules you can infer, such as:\\n   - Timestamps must be sequential\\n   - Certain fields are derived from others\\n   - Value ranges or constraints\\n   - Required vs optional fields\\n4. **PII Fields**: Identify any fields that appear to contain personally identifiable information (names, emails, phone numbers, addresses, SSNs, etc.)\\n5. **Patterns**: Any patterns in the data (date formats, ID formats, naming conventions)\\n\\nOutput your analysis as valid JSON with this structure:\\n{\\n    \"schema\": { ... field definitions ... },\\n    \"data_types\": { \"field_name\": \"type\", ... },\\n    \"business_rules\": [ \"rule 1\", \"rule 2\", ... ],\\n    \"pii_fields\": [ \"field1\", \"field2\", ... ],\\n    \"patterns\": { \"field_name\": \"pattern description\", ... },\\n    \"example_formats\": { \"field_name\": \"format description or pattern\", ... }\\n}\\n\\nCRITICAL - PII PROTECTION:\\n- Do NOT copy any actual values from the input data into the profile\\n- For \"example_formats\", describe the FORMAT/PATTERN only (e.g., \"email format: user@domain.com\", \"phone format: +1-555-XXX-XXXX\")\\n- Never include real names, emails, addresses, phone numbers, or any identifiable information\\n- The profile must contain ZERO original data values - only structural descriptions\\n\\nBe thorough but concise. The profile will be used to generate synthetic test data.'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "client",
            "source_type": "variable",
            "source_hint": "get_client()",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "content",
            "source_type": "variable",
            "source_hint": "content[:max_chars]",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "response",
            "source_type": "variable",
            "source_hint": "client.chat.completions.create(model=model, messages=[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}], response_format={'type': 'json_object'}, temperature=0.2)",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": "response",
        "expected_format": "json",
        "response_format_specified": true,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "No schema validation on output",
          "Prompt from variable: [{'role': 'system', 'content': SYSTEM_PROMPT}, {'r",
          "Context 'SYSTEM_PROMPT' from inline",
          "Context 'client' from variable",
          "Context 'content' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Probe for JSON format violations",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "learn_analyze_file_c0de5b",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/mimic/learn.py",
        "line": 72,
        "column": null,
        "function": "analyze_file",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "SYSTEM_PROMPT",
            "source_type": "inline",
            "source_hint": "'You are a data analyst expert. Analyze the provided data and create a data profile - a descriptive specification of this data structure.\\n\\nYour profile must include:\\n\\n1. **Schema**: The exact structure/shape of the data (fields, nesting, arrays)\\n2. **Data Types**: The type of each field (string, number, boolean, date, etc.)\\n3. **Business Logic**: Any implicit rules you can infer, such as:\\n   - Timestamps must be sequential\\n   - Certain fields are derived from others\\n   - Value ranges or constraints\\n   - Required vs optional fields\\n4. **PII Fields**: Identify any fields that appear to contain personally identifiable information (names, emails, phone numbers, addresses, SSNs, etc.)\\n5. **Patterns**: Any patterns in the data (date formats, ID formats, naming conventions)\\n\\nOutput your analysis as valid JSON with this structure:\\n{\\n    \"schema\": { ... field definitions ... },\\n    \"data_types\": { \"field_name\": \"type\", ... },\\n    \"business_rules\": [ \"rule 1\", \"rule 2\", ... ],\\n    \"pii_fields\": [ \"field1\", \"field2\", ... ],\\n    \"patterns\": { \"field_name\": \"pattern description\", ... },\\n    \"example_formats\": { \"field_name\": \"format description or pattern\", ... }\\n}\\n\\nCRITICAL - PII PROTECTION:\\n- Do NOT copy any actual values from the input data into the profile\\n- For \"example_formats\", describe the FORMAT/PATTERN only (e.g., \"email format: user@domain.com\", \"phone format: +1-555-XXX-XXXX\")\\n- Never include real names, emails, addresses, phone numbers, or any identifiable information\\n- The profile must contain ZERO original data values - only structural descriptions\\n\\nBe thorough but concise. The profile will be used to generate synthetic test data.'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "client",
            "source_type": "variable",
            "source_hint": "get_client()",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "content",
            "source_type": "variable",
            "source_hint": "content[:max_chars]",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "max_chars",
            "source_type": "variable",
            "source_hint": "50000",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "response",
            "source_type": "variable",
            "source_hint": "client.chat.completions.create(model=model, messages=[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}], response_format={'type': 'json_object'}, temperature=0.2)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "profile",
            "source_type": "variable",
            "source_hint": "analyze_file(file_path, model)",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'SYSTEM_PROMPT' from inline",
          "Context 'client' from variable",
          "Context 'content' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "generate_generate_batch_b99cd7",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/flightline/generate.py",
        "line": 76,
        "column": 15,
        "function": "generate_batch",
        "class_name": null
      },
      "provider": "openai",
      "call_type": "chat",
      "detection_method": "sdk_verified",
      "confidence": 1.0,
      "inputs": {
        "system_prompt": {
          "source_type": "variable",
          "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': user_prompt}]",
          "inline_content": null,
          "variable_name": null
        },
        "messages": [
          {
            "source_type": "variable",
            "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': user_prompt}]",
            "inline_content": null,
            "variable_name": null
          }
        ],
        "context_variables": [
          {
            "name": "SYSTEM_PROMPT",
            "source_type": "inline",
            "source_hint": "'You are a synthetic data generator. You generate realistic fake data based on a learned data profile.\\n\\nRULES:\\n1. Match the EXACT schema structure - same fields, nesting, and data types\\n2. Follow ALL business rules from the profile\\n3. Generate realistic but FAKE values for PII (names, emails, phones, addresses)\\n4. Make each record UNIQUE with varied values\\n5. Output valid JSON only - a JSON object with a \"records\" array'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "user_prompt",
            "source_type": "variable",
            "source_hint": "f'Generate exactly {count} synthetic data records based on this profile.\\n\\nPROFILE:\\n{profile_text}\\n\\nIMPORTANT:\\n- Generate {count} COMPLETE records matching the schema\\n- Each record must have ALL fields from the schema\\n- Follow all business_rules (calculations must be correct!)\\n- Use fake but realistic PII values\\n- Make each record unique\\n\\nOutput as: {{\"records\": [... {count} complete records ...]}}'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "response",
            "source_type": "variable",
            "source_hint": "client.chat.completions.create(model=model, messages=[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': user_prompt}], response_format={'type': 'json_object'}, temperature=0.8)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "client",
            "source_type": "variable",
            "source_hint": "get_client()",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "handlebars"
      },
      "outputs": {
        "assigned_to": "response",
        "expected_format": "json",
        "response_format_specified": true,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "No schema validation on output",
          "Prompt from variable: [{'role': 'system', 'content': SYSTEM_PROMPT}, {'r",
          "Context 'SYSTEM_PROMPT' from inline",
          "Context 'user_prompt' from variable",
          "Context 'response' from variable",
          "Uses handlebars templates"
        ],
        "suggested_focus": [
          "Probe for JSON format violations",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "learn_analyze_file_5cc314",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/flightline/learn.py",
        "line": 88,
        "column": 19,
        "function": "analyze_file",
        "class_name": null
      },
      "provider": "openai",
      "call_type": "chat",
      "detection_method": "sdk_verified",
      "confidence": 1.0,
      "inputs": {
        "system_prompt": {
          "source_type": "variable",
          "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}]",
          "inline_content": null,
          "variable_name": null
        },
        "messages": [
          {
            "source_type": "variable",
            "source_hint": "[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}]",
            "inline_content": null,
            "variable_name": null
          }
        ],
        "context_variables": [
          {
            "name": "SYSTEM_PROMPT",
            "source_type": "inline",
            "source_hint": "'You are a data analyst expert. Analyze the provided data and create a data profile - a descriptive specification of this data structure.\\n\\nYour profile must include:\\n\\n1. **Schema**: The exact structure/shape of the data (fields, nesting, arrays)\\n2. **Data Types**: The type of each field (string, number, boolean, date, etc.)\\n3. **Business Logic**: Any implicit rules you can infer, such as:\\n   - Timestamps must be sequential\\n   - Certain fields are derived from others\\n   - Value ranges or constraints\\n   - Required vs optional fields\\n4. **PII Fields**: Identify any fields that appear to contain personally identifiable information (names, emails, phone numbers, addresses, SSNs, etc.)\\n5. **Patterns**: Any patterns in the data (date formats, ID formats, naming conventions)\\n\\nOutput your analysis as valid JSON with this structure:\\n{\\n    \"schema\": { ... field definitions ... },\\n    \"data_types\": { \"field_name\": \"type\", ... },\\n    \"business_rules\": [ \"rule 1\", \"rule 2\", ... ],\\n    \"pii_fields\": [ \"field1\", \"field2\", ... ],\\n    \"patterns\": { \"field_name\": \"pattern description\", ... },\\n    \"example_formats\": { \"field_name\": \"format description or pattern\", ... }\\n}\\n\\nCRITICAL - PII PROTECTION:\\n- Do NOT copy any actual values from the input data into the profile\\n- For \"example_formats\", describe the FORMAT/PATTERN only (e.g., \"email format: user@domain.com\", \"phone format: +1-555-XXX-XXXX\")\\n- Never include real names, emails, addresses, phone numbers, or any identifiable information\\n- The profile must contain ZERO original data values - only structural descriptions\\n\\nBe thorough but concise. The profile will be used to generate synthetic test data.'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "client",
            "source_type": "variable",
            "source_hint": "get_client()",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "content",
            "source_type": "variable",
            "source_hint": "content[:max_chars]",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "response",
            "source_type": "variable",
            "source_hint": "client.chat.completions.create(model=model, messages=[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}], response_format={'type': 'json_object'}, temperature=0.2)",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": "response",
        "expected_format": "json",
        "response_format_specified": true,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "No schema validation on output",
          "Prompt from variable: [{'role': 'system', 'content': SYSTEM_PROMPT}, {'r",
          "Context 'SYSTEM_PROMPT' from inline",
          "Context 'client' from variable",
          "Context 'content' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Probe for JSON format violations",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "learn_analyze_file_c0de5b",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/flightline/learn.py",
        "line": 72,
        "column": null,
        "function": "analyze_file",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "SYSTEM_PROMPT",
            "source_type": "inline",
            "source_hint": "'You are a data analyst expert. Analyze the provided data and create a data profile - a descriptive specification of this data structure.\\n\\nYour profile must include:\\n\\n1. **Schema**: The exact structure/shape of the data (fields, nesting, arrays)\\n2. **Data Types**: The type of each field (string, number, boolean, date, etc.)\\n3. **Business Logic**: Any implicit rules you can infer, such as:\\n   - Timestamps must be sequential\\n   - Certain fields are derived from others\\n   - Value ranges or constraints\\n   - Required vs optional fields\\n4. **PII Fields**: Identify any fields that appear to contain personally identifiable information (names, emails, phone numbers, addresses, SSNs, etc.)\\n5. **Patterns**: Any patterns in the data (date formats, ID formats, naming conventions)\\n\\nOutput your analysis as valid JSON with this structure:\\n{\\n    \"schema\": { ... field definitions ... },\\n    \"data_types\": { \"field_name\": \"type\", ... },\\n    \"business_rules\": [ \"rule 1\", \"rule 2\", ... ],\\n    \"pii_fields\": [ \"field1\", \"field2\", ... ],\\n    \"patterns\": { \"field_name\": \"pattern description\", ... },\\n    \"example_formats\": { \"field_name\": \"format description or pattern\", ... }\\n}\\n\\nCRITICAL - PII PROTECTION:\\n- Do NOT copy any actual values from the input data into the profile\\n- For \"example_formats\", describe the FORMAT/PATTERN only (e.g., \"email format: user@domain.com\", \"phone format: +1-555-XXX-XXXX\")\\n- Never include real names, emails, addresses, phone numbers, or any identifiable information\\n- The profile must contain ZERO original data values - only structural descriptions\\n\\nBe thorough but concise. The profile will be used to generate synthetic test data.'",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "client",
            "source_type": "variable",
            "source_hint": "get_client()",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "content",
            "source_type": "variable",
            "source_hint": "content[:max_chars]",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "max_chars",
            "source_type": "variable",
            "source_hint": "50000",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "response",
            "source_type": "variable",
            "source_hint": "client.chat.completions.create(model=model, messages=[{'role': 'system', 'content': SYSTEM_PROMPT}, {'role': 'user', 'content': f'Analyze this data:\\n\\n{content}'}], response_format={'type': 'json_object'}, temperature=0.2)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "profile",
            "source_type": "variable",
            "source_hint": "analyze_file(file_path, model)",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "fstring"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'SYSTEM_PROMPT' from inline",
          "Context 'client' from variable",
          "Context 'content' from variable",
          "Uses fstring templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "trace_trace_js_inputs_1ec498",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/flightline/discover/trace.py",
        "line": 528,
        "column": null,
        "function": "trace_js_inputs",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "source_type",
            "source_type": "variable",
            "source_hint": "_classify_source(var_value)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "source",
            "source_type": "variable",
            "source_hint": "file_path.read_text(encoding='utf-8', errors='ignore')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "obs",
            "source_type": "variable",
            "source_hint": "InputObservations()",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "lines",
            "source_type": "variable",
            "source_hint": "source.splitlines()",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "end",
            "source_type": "variable",
            "source_hint": "min(len(lines), call.location.line + 20)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "call_block",
            "source_type": "variable",
            "source_hint": "_extract_js_call_block(lines, call_line_idx)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "messages_match",
            "source_type": "variable",
            "source_hint": "re.search('messages\\\\s*:\\\\s*\\\\[', call_block)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "messages_content",
            "source_type": "variable",
            "source_hint": "_extract_js_array(call_block, messages_match.end() - 1)",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "match",
            "source_type": "variable",
            "source_hint": "assign_pattern.search(lines[i])",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "line",
            "source_type": "variable",
            "source_hint": "lines[i]",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "handlebars"
      },
      "outputs": {
        "assigned_to": "messages_content",
        "expected_format": null,
        "response_format_specified": false,
        "validation": {
          "type": "pydantic",
          "schema_location": null,
          "schema_name": null
        }
      },
      "usage": {
        "used_in_conditional": true,
        "conditional_location": {
          "file": "/Users/jtc/Github/flightline_frontend/cli/flightline/discover/trace.py",
          "line": 539,
          "column": null,
          "function": null,
          "class_name": null
        },
        "conditional_type": "if",
        "returned_from_function": false,
        "passed_to_functions": [
          "_classify_source",
          "append",
          "InputSource",
          "len"
        ],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "high",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "Output controls if at L539",
          "Output passed to: _classify_source, append, InputSource (+1 more)",
          "pydantic validation present",
          "Context 'source_type' from variable",
          "Context 'source' from variable",
          "Context 'obs' from variable",
          "Uses handlebars templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test classification across full output space",
          "Focus on boundary cases between categories"
        ]
      }
    },
    {
      "id": "heuristics_module_803864",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/flightline/discover/heuristics.py",
        "line": 20,
        "column": null,
        "function": null,
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "MESSAGE_PATTERNS",
            "source_type": "variable",
            "source_hint": "['role', 'content']",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "PARAM_PATTERNS",
            "source_type": "variable",
            "source_hint": "['temperature', 'max_tokens', 'model', 'top_p', 'presence_penalty', 'frequency_penalty', 'stop_sequences', 'system_prompt']",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "i",
            "source_type": "variable",
            "source_hint": "0",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "handlebars"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": null
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "low",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "No schema validation on output",
          "Context 'MESSAGE_PATTERNS' from variable",
          "Context 'PARAM_PATTERNS' from variable",
          "Context 'i' from variable",
          "Uses handlebars templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation",
          "Test with adversarial inputs"
        ]
      }
    },
    {
      "id": "schema_name_3db609",
      "location": {
        "file": "/Users/jtc/Github/flightline_frontend/cli/flightline/discover/schema.py",
        "line": 133,
        "column": null,
        "function": "name",
        "class_name": null
      },
      "provider": "unknown",
      "call_type": "chat",
      "detection_method": "heuristic",
      "confidence": 0.8,
      "inputs": {
        "system_prompt": null,
        "messages": [],
        "context_variables": [
          {
            "name": "line",
            "source_type": "variable",
            "source_hint": "Field(..., description='Line number (1-indexed)')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "source_type",
            "source_type": "variable",
            "source_hint": "Field(..., description='Where this variable comes from')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "source_hint",
            "source_type": "variable",
            "source_hint": "Field(None, description='Code pattern that reveals source')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "inline_content",
            "source_type": "variable",
            "source_hint": "Field(None, description='If inline, the actual string content (truncated if long)')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "variable_name",
            "source_type": "variable",
            "source_hint": "Field(None, description='If from variable, the variable name')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "name",
            "source_type": "variable",
            "source_hint": "Field(..., description='Variable name in code')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "shape_hint",
            "source_type": "variable",
            "source_hint": "Field(None, description='Inferred shape: string, object, array, unknown')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "type_reference",
            "source_type": "variable",
            "source_hint": "Field(None, description='If typed, the type/interface name')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "system_prompt",
            "source_type": "variable",
            "source_hint": "Field(None, description='System prompt source, if present')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "type",
            "source_type": "variable",
            "source_hint": "Field(..., description='Artifact type: prompt_source, schema, etc.')",
            "shape_hint": null,
            "type_reference": null
          },
          {
            "name": "reference",
            "source_type": "variable",
            "source_hint": "Field(..., description='How to access this artifact')",
            "shape_hint": null,
            "type_reference": null
          }
        ],
        "template_engine": "jinja"
      },
      "outputs": {
        "assigned_to": null,
        "expected_format": null,
        "response_format_specified": false,
        "validation": {
          "type": "pydantic",
          "schema_location": null,
          "schema_name": null
        }
      },
      "usage": {
        "used_in_conditional": false,
        "conditional_location": null,
        "conditional_type": null,
        "returned_from_function": false,
        "passed_to_functions": [],
        "assigned_to_property": null,
        "sinks": []
      },
      "interpretation": {
        "version": "0.1.2",
        "risk_tier": "medium",
        "scenario_complexity": "high",
        "observations_summary": [
          "Candidate AI operation (detected via footprint)",
          "pydantic validation present",
          "Context 'line' from variable",
          "Context 'source_type' from variable",
          "Context 'source_hint' from variable",
          "Uses jinja templates"
        ],
        "suggested_focus": [
          "Verify if this candidate is an AI operation"
        ]
      }
    }
  ],
  "artifacts": []
}