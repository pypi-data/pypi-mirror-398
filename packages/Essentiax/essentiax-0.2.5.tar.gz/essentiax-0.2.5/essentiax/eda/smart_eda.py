"""
smartEDA.py
===========================================
EssentiaX ‚Äì Smart Exploratory Data Analysis (EDA)

A professional-grade EDA engine that produces:
‚Ä¢ Structural insights
‚Ä¢ Missing value diagnostics
‚Ä¢ Outlier detection
‚Ä¢ Skewness analysis
‚Ä¢ Cardinality summary
‚Ä¢ Numeric + Categorical profiling
‚Ä¢ Correlation intelligence
‚Ä¢ Actionable insights

Designed to outperform Pandas-Profiling/SweetViz in clarity.
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")


def smart_eda(df: pd.DataFrame, sample_size: int = 50000):
    print("\nüß† **Starting EssentiaX Smart EDA**")
    print("=" * 70)

    # Optional Sampling (for large datasets)
    if sample_size and len(df) > sample_size:
        df = df.sample(sample_size, random_state=42)
        print(f"üìâ Dataset sampled to {sample_size:,} rows to improve speed\n")

    # BASIC STRUCTURE
    print("1Ô∏è‚É£ DATASET OVERVIEW")
    print("-" * 70)
    print(f"‚Ä¢ Rows: {df.shape[0]:,}")
    print(f"‚Ä¢ Columns: {df.shape[1]}")
    print(f"‚Ä¢ Total Cells: {df.size:,}")
    print(f"‚Ä¢ Memory Usage: {df.memory_usage(deep=True).sum()/1024**2:.2f} MB")
    print(f"‚Ä¢ Duplicate Rows: {df.duplicated().sum():,}")

    # DATA TYPES
    print("\n2Ô∏è‚É£ DATA TYPES & COLUMN DISTRIBUTION")
    print("-" * 70)
    dtypes = df.dtypes.value_counts()
    for dtype, count in dtypes.items():
        print(f"‚Ä¢ {dtype}: {count} columns")

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()
    datetime_cols = df.select_dtypes(include=["datetime64"]).columns.tolist()

    print(f"\n‚Ä¢ Numeric Columns: {len(numeric_cols)}")
    print(f"‚Ä¢ Categorical Columns: {len(categorical_cols)}")
    print(f"‚Ä¢ Date Columns: {len(datetime_cols)}")

    # MISSING VALUES
    print("\n3Ô∏è‚É£ MISSING VALUE ANALYSIS")
    print("-" * 70)
    missing = df.isnull().sum()
    missing = missing[missing > 0].sort_values(ascending=False)

    if missing.empty:
        print("‚úî No missing values in dataset.")
    else:
        total_missing = missing.sum()
        print(f"‚ö† Missing Values Found: {total_missing:,}")
        print("\nTop Missing Columns:")
        for col, val in missing.head(8).items():
            pct = 100 * val / len(df)
            print(f"‚Ä¢ {col:20s} ‚Üí {val:8,} missing ({pct:.2f}%)")

    # NUMERIC SUMMARY
    print("\n4Ô∏è‚É£ NUMERIC FEATURE PROFILE")
    print("-" * 70)
    if numeric_cols:
        desc = df[numeric_cols].describe().T
        desc["skew"] = df[numeric_cols].skew()
        desc["missing_%"] = (df[numeric_cols].isnull().sum() / len(df)) * 100

        print(desc[["mean", "std", "min", "25%", "50%", "75%", "max", "skew", "missing_%"]]
              .head(8)
              .round(3)
              .to_string())

        # Outlier discovery
        print("\nüìå Outlier Detection (IQR Method)")
        for col in numeric_cols:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
            outliers = df[(df[col] < lower) | (df[col] > upper)][col].count()
            if outliers > 0:
                print(f"‚Ä¢ {col}: {outliers:,} outliers")

        # Skewness ranking
        print("\nüìä Skewness Ranking (most skewed first)")
        skew_sorted = df[numeric_cols].skew().sort_values(ascending=False)
        for col, skew in skew_sorted.head(5).items():
            print(f"‚Ä¢ {col:20s} ‚Üí skew = {skew:.2f}")
    else:
        print("‚ö† No numeric columns.")

    # CATEGORICAL SUMMARY
    print("\n5Ô∏è‚É£ CATEGORICAL FEATURE PROFILE")
    print("-" * 70)
    if categorical_cols:
        for col in categorical_cols[:8]:
            unique = df[col].nunique()
            top = df[col].value_counts().head(3)
            print(f"\nüìå {col}")
            print(f"‚Ä¢ Unique Values: {unique}")
            for val, cnt in top.items():
                pct = 100 * cnt / len(df)
                print(f"   - {val}  ({pct:.2f}%)")

        if len(categorical_cols) > 8:
            print(f"\n... {len(categorical_cols) - 8} more categorical columns.")
    else:
        print("‚ö† No categorical columns.")

    # CORRELATION ANALYSIS
    print("\n6Ô∏è‚É£ CORRELATION INTELLIGENCE")
    print("-" * 70)
    if len(numeric_cols) > 1:
        corr = df[numeric_cols].corr()
        strong = []

        for i in range(len(corr.columns)):
            for j in range(i + 1, len(corr.columns)):
                val = corr.iloc[i, j]
                if abs(val) > 0.7:
                    strong.append((corr.index[i], corr.columns[j], val))

        if strong:
            strong = sorted(strong, key=lambda x: abs(x[2]), reverse=True)
            for col1, col2, val in strong[:10]:
                relation = "Positive" if val > 0 else "Negative"
                print(f"‚Ä¢ {col1} ‚Üî {col2} ‚Üí {val:.3f} ({relation})")
        else:
            print("No strong correlations found.")
    else:
        print("‚ö† Not enough numeric columns for correlation.")

    # FINAL INSIGHTS
    print("\n" + "=" * 70)
    print("‚úÖ EDA Completed ‚Äî EssentiaX Intelligence Report")
    print("=" * 70)

    print("\nüí° Recommended Next Steps:")
    print("1. Use smart_clean() to handle missing values & encode data.")
    print("2. Remove outliers if they distort your model.")
    print("3. Normalize numerical columns before ML.")
    print("4. Perform feature engineering on categorical values.")
    print("\n")


# For local testing
if __name__ == "__main__":
    df = pd.DataFrame({
        "A": np.random.randint(1, 100, 200),
        "B": np.random.normal(50, 10, 200),
        "C": np.random.choice(["X", "Y", "Z"], 200)
    })
    df.loc[10:20, "B"] = np.nan
    smart_eda(df)
