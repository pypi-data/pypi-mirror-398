# coding: utf-8

"""
    Mixpeek API

    This is the Mixpeek API, providing access to various endpoints for data processing and retrieval.

    The version of the OpenAPI document: 0.81
    Contact: info@mixpeek.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from mixpeek.models.image_embedding_model import ImageEmbeddingModel
from mixpeek.models.ocr_mode import OcrMode
from mixpeek.models.ocr_provider import OcrProvider
from mixpeek.models.pii_detection_method import PiiDetectionMethod
from mixpeek.models.pii_redaction_mode import PiiRedactionMode
from mixpeek.models.store_images_as import StoreImagesAs
from mixpeek.models.summary_model import SummaryModel
from mixpeek.models.table_extraction_method import TableExtractionMethod
from mixpeek.models.table_format import TableFormat
from mixpeek.models.text_embedding_model import TextEmbeddingModel
from typing import Optional, Set
from typing_extensions import Self

class PdfExtractorParams(BaseModel):
    """
    Parameters for the PDF extractor.  The PDF extractor decomposes PDFs into multiple specialized collections, enabling flexible retrieval patterns through document joins. This architecture aligns with Mixpeek's core principles of composability, flexibility, and developer-first design.  **When to Use**:     - Legal document search with PII redaction requirements     - Technical manual search with images and tables     - Research paper analysis with citations and figures     - Financial report processing with structured data extraction     - Contract analysis with clause-level search     - Academic paper repositories with multimodal content     - Regulatory document compliance with audit trails     - Enterprise knowledge bases with mixed content types  **When NOT to Use**:     - Simple text-only documents → Use text_extractor instead     - Image-only documents → Use image_extractor instead     - Real-time document processing → Consider streaming alternatives     - Very small PDFs (<1 page) → Overhead may not be worth it  **Multi-Collection Architecture**:     Each extractor run outputs to ONE collection, but users create multiple collections with     different parameters to achieve multi-collection patterns:     - Pages collection: extract_text=true → document_type=\"page\"     - Images collection: extract_images=true → document_type=\"image\"     - Tables collection: extract_tables=true → document_type=\"table\"     - Metadata collection: minimal params → document_type=\"metadata\"  **Performance Characteristics**:     - Processing Speed: 50ms-1000ms per page (depends on features enabled)     - Text Extraction: 5-20ms per page     - OCR: 200-300ms per page (if needed)     - Image Extraction: 10-30ms per page     - Table Extraction: 20-300ms per page (depends on method)     - PII Redaction: 10-300ms per page (depends on method)  **Cost Estimates** (per page):     - Minimal (text + E5 embeddings): $0.0001     - Balanced (text + OCR + tables + E5): $0.0027     - Full (all features + summaries): $0.0060  Requirements:     - pdf: REQUIRED (accessible PDF file URL or S3 path)     - Document type determined by enabled extraction parameters     - All feature parameters: OPTIONAL (defaults provided)
    """ # noqa: E501
    split_by_pages: Optional[StrictBool] = Field(default=True, description="Split PDF into individual pages (one document per page). Recommended for most use cases as it provides predictable, consistent chunking that works for all PDFs.")
    split_by_sections: Optional[StrictBool] = Field(default=False, description="Advanced: Split by detected sections/headings instead of pages. Provides more semantic units but detection can be unreliable. Best for long documents with clear section structure.")
    extract_text: Optional[StrictBool] = Field(default=True, description="Extract native text from PDF pages. Fast and accurate for digital PDFs. When enabled, produces document_type='page' outputs.")
    run_ocr: Optional[StrictBool] = Field(default=True, description="Run OCR on pages with no/minimal text for scanned PDFs. Automatically detects when OCR is needed based on ocr_mode setting.")
    ocr_mode: Optional[OcrMode] = Field(default=None, description="OCR processing strategy. 'auto': OCR only pages with <50 characters (recommended). 'always': OCR all pages regardless of text content. 'never': Skip OCR entirely (faster, but fails on scanned PDFs).")
    ocr_provider: Optional[OcrProvider] = Field(default=None, description="OCR engine to use for text extraction. 'gemini': Best accuracy (95-98%), layout-aware, $0.0025/page. 'tesseract': Good accuracy (85-92%), free, faster but less layout-aware.")
    ocr_language: Optional[StrictStr] = Field(default='en', description="Primary language for OCR processing (ISO 639-1 code). Examples: 'en' (English), 'es' (Spanish), 'fr' (French), 'de' (German). Gemini supports 100+ languages, Tesseract requires language packs.")
    extract_images: Optional[StrictBool] = Field(default=False, description="Extract embedded images from PDF pages. When enabled, produces document_type='image' outputs. Useful for visual search and image-based content discovery.")
    image_min_size: Optional[Annotated[List[Any], Field(min_length=2, max_length=2)]] = Field(default=None, description="Minimum width and height in pixels to extract images. Filters out decorative images, icons, and low-quality graphics. Format: (width, height). Recommended: (100, 100) or higher.")
    store_images_as: Optional[StoreImagesAs] = Field(default=None, description="How to store extracted images. 's3': Upload to S3 with URL reference (recommended, smaller docs). 'base64': Inline in document (fast access, increases doc size 50-200KB). 'both': Store inline + S3 backup (redundancy, doubles storage cost).")
    extract_tables: Optional[StrictBool] = Field(default=False, description="Extract tables as structured JSON data. When enabled, produces document_type='table' outputs. Useful for structured data analysis and table-based search.")
    table_extraction_method: Optional[TableExtractionMethod] = Field(default=None, description="Algorithm for table detection and extraction. 'pdfplumber': Fast (20ms), good for simple tables, 80-85% accuracy. 'camelot': Medium speed (100ms), excellent for complex bordered tables, 85-90% accuracy. 'gemini': Slow (300ms), best for borderless tables and complex layouts, 90-95% accuracy.")
    table_format: Optional[TableFormat] = Field(default=None, description="Output format for extracted tables. 'json': Structured data with headers/rows (recommended for search). 'csv': Comma-separated values (good for data analysis). 'markdown': Human-readable format (good for display).")
    preserve_layout: Optional[StrictBool] = Field(default=True, description="Extract layout information including bounding boxes, columns, and reading order. Enables better semantic understanding of document structure. Adds 50-100ms per page but improves search quality.")
    detect_headers_footers: Optional[StrictBool] = Field(default=True, description="Identify and mark header/footer regions. Useful for filtering repetitive content and improving content quality. Only applies when preserve_layout=True.")
    detect_columns: Optional[StrictBool] = Field(default=True, description="Detect multi-column layouts and determine reading order. Critical for academic papers and complex document layouts. Only applies when preserve_layout=True.")
    redact_pii: Optional[StrictBool] = Field(default=False, description="Detect and redact Personal Identifiable Information from extracted text. Important for compliance with privacy regulations (GDPR, HIPAA, etc.). Adds 10-300ms per page depending on detection method.")
    pii_detection_method: Optional[PiiDetectionMethod] = Field(default=None, description="Method for PII detection. 'presidio': Fast (10ms), 85-90% accuracy, free, 20+ entity types. 'gemini': Slow (300ms), 92-96% accuracy, $0.0025/page, contextual detection. 'regex': Very fast (1ms), 60-70% accuracy, free, limited patterns.")
    pii_entities: Optional[List[StrictStr]] = Field(default=None, description="Types of PII to detect and redact. Common types: PERSON, EMAIL, PHONE, SSN, CREDIT_CARD, ADDRESS, DATE_TIME, LOCATION, ORGANIZATION, MEDICAL_LICENSE, etc. Available entities depend on detection method.")
    pii_redaction_mode: Optional[PiiRedactionMode] = Field(default=None, description="How to redact detected PII. 'mask': Replace with [REDACTED] or [EMAIL] (preserves context, reversible). 'hash': Replace with deterministic hash (privacy-compliant, enables fuzzy matching). 'remove': Delete entirely (maximum privacy, may break readability). 'synthetic': Replace with fake but realistic data (good for testing, expensive).")
    pii_confidence_threshold: Optional[Union[Annotated[float, Field(le=1.0, strict=True, ge=0.0)], Annotated[int, Field(le=1, strict=True, ge=0)]]] = Field(default=0.8, description="Minimum confidence score to redact PII (0.0-1.0). Higher values = fewer false positives, more false negatives. Recommended: 0.8 (balanced), 0.85+ (high-stakes), 0.7 (comprehensive).")
    run_text_embedding: Optional[StrictBool] = Field(default=True, description="Generate text embeddings for semantic search over page content. Enables semantic similarity search across document text. Recommended for most use cases.")
    text_embedding_model: Optional[TextEmbeddingModel] = Field(default=None, description="Model for text embedding generation. 'e5': E5-Large, 1024D, fast (5ms), free, 85-88% accuracy. 'openai': Ada-002, 1536D, fast (10ms), $0.0001/page, 88-91% accuracy. 'vertex': Multimodal, 1408D, medium (50ms), $0.00001/page, 90-93% accuracy.")
    run_image_embedding: Optional[StrictBool] = Field(default=False, description="Generate embeddings from rendered page images for visual search. Slower processing but enables visual similarity search. Only useful if visual search is required.")
    image_embedding_model: Optional[ImageEmbeddingModel] = Field(default=None, description="Model for image embedding generation. 'clip': CLIP ViT-L/14, 768D, fast (20ms), free, 82-85% accuracy. 'vertex': Multimodal, 1408D, medium (50ms), $0.00001/page, 88-91% accuracy.")
    embedding_fields: Optional[List[StrictStr]] = Field(default=None, description="Which fields to include in text embedding generation. Options: 'text_content', 'ocr_text', 'summary'. Multiple fields are concatenated before embedding.")
    generate_summaries: Optional[StrictBool] = Field(default=False, description="Generate AI summaries for each page/section. Useful for quick content overview and enhanced search. Adds 500ms-2000ms per page depending on model.")
    summary_prompt: Optional[StrictStr] = Field(default='Summarize this PDF page in 2-3 sentences, focusing on key information.', description="Custom prompt for summary generation. Tailor this to your specific use case and content type. Only used when generate_summaries=True.")
    summary_model: Optional[SummaryModel] = None
    extract_keywords: Optional[StrictBool] = Field(default=False, description="Extract key terms and phrases from page content. Useful for tagging and categorization. Lightweight feature with minimal performance impact.")
    extract_entities: Optional[StrictBool] = Field(default=False, description="Extract named entities (people, organizations, locations, dates). Useful for structured data extraction and entity-based search. Adds 50-100ms per page.")
    render_page_images: Optional[StrictBool] = Field(default=True, description="Render each page as PNG for thumbnails and visual search. Required for image embeddings. Useful for UI previews. Adds 10-20ms per page.")
    image_dpi: Optional[Annotated[int, Field(le=300, strict=True, ge=72)]] = Field(default=150, description="DPI for page rendering. 72: Preview quality, smallest files. 150: Balanced quality/size (recommended). 300: High quality, larger files.")
    max_concurrent_pages: Optional[StrictInt] = Field(default=10, description="Maximum pages to process in parallel. Higher values = faster processing but more memory usage. Adjust based on available system resources.")
    __properties: ClassVar[List[str]] = ["split_by_pages", "split_by_sections", "extract_text", "run_ocr", "ocr_mode", "ocr_provider", "ocr_language", "extract_images", "image_min_size", "store_images_as", "extract_tables", "table_extraction_method", "table_format", "preserve_layout", "detect_headers_footers", "detect_columns", "redact_pii", "pii_detection_method", "pii_entities", "pii_redaction_mode", "pii_confidence_threshold", "run_text_embedding", "text_embedding_model", "run_image_embedding", "image_embedding_model", "embedding_fields", "generate_summaries", "summary_prompt", "summary_model", "extract_keywords", "extract_entities", "render_page_images", "image_dpi", "max_concurrent_pages"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of PdfExtractorParams from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of summary_model
        if self.summary_model:
            _dict['summary_model'] = self.summary_model.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of PdfExtractorParams from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "split_by_pages": obj.get("split_by_pages") if obj.get("split_by_pages") is not None else True,
            "split_by_sections": obj.get("split_by_sections") if obj.get("split_by_sections") is not None else False,
            "extract_text": obj.get("extract_text") if obj.get("extract_text") is not None else True,
            "run_ocr": obj.get("run_ocr") if obj.get("run_ocr") is not None else True,
            "ocr_mode": obj.get("ocr_mode"),
            "ocr_provider": obj.get("ocr_provider"),
            "ocr_language": obj.get("ocr_language") if obj.get("ocr_language") is not None else 'en',
            "extract_images": obj.get("extract_images") if obj.get("extract_images") is not None else False,
            "image_min_size": obj.get("image_min_size"),
            "store_images_as": obj.get("store_images_as"),
            "extract_tables": obj.get("extract_tables") if obj.get("extract_tables") is not None else False,
            "table_extraction_method": obj.get("table_extraction_method"),
            "table_format": obj.get("table_format"),
            "preserve_layout": obj.get("preserve_layout") if obj.get("preserve_layout") is not None else True,
            "detect_headers_footers": obj.get("detect_headers_footers") if obj.get("detect_headers_footers") is not None else True,
            "detect_columns": obj.get("detect_columns") if obj.get("detect_columns") is not None else True,
            "redact_pii": obj.get("redact_pii") if obj.get("redact_pii") is not None else False,
            "pii_detection_method": obj.get("pii_detection_method"),
            "pii_entities": obj.get("pii_entities"),
            "pii_redaction_mode": obj.get("pii_redaction_mode"),
            "pii_confidence_threshold": obj.get("pii_confidence_threshold") if obj.get("pii_confidence_threshold") is not None else 0.8,
            "run_text_embedding": obj.get("run_text_embedding") if obj.get("run_text_embedding") is not None else True,
            "text_embedding_model": obj.get("text_embedding_model"),
            "run_image_embedding": obj.get("run_image_embedding") if obj.get("run_image_embedding") is not None else False,
            "image_embedding_model": obj.get("image_embedding_model"),
            "embedding_fields": obj.get("embedding_fields"),
            "generate_summaries": obj.get("generate_summaries") if obj.get("generate_summaries") is not None else False,
            "summary_prompt": obj.get("summary_prompt") if obj.get("summary_prompt") is not None else 'Summarize this PDF page in 2-3 sentences, focusing on key information.',
            "summary_model": SummaryModel.from_dict(obj["summary_model"]) if obj.get("summary_model") is not None else None,
            "extract_keywords": obj.get("extract_keywords") if obj.get("extract_keywords") is not None else False,
            "extract_entities": obj.get("extract_entities") if obj.get("extract_entities") is not None else False,
            "render_page_images": obj.get("render_page_images") if obj.get("render_page_images") is not None else True,
            "image_dpi": obj.get("image_dpi") if obj.get("image_dpi") is not None else 150,
            "max_concurrent_pages": obj.get("max_concurrent_pages") if obj.get("max_concurrent_pages") is not None else 10
        })
        return _obj


