# coding: utf-8

"""
    Mixpeek API

    This is the Mixpeek API, providing access to various endpoints for data processing and retrieval.

    The version of the OpenAPI document: 0.81
    Contact: info@mixpeek.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from typing import Optional, Set
from typing_extensions import Self

class ColbertExtractorParams(BaseModel):
    """
    Parameters for the ColBERT extractor.  ColBERT (Contextualized Late Interaction over BERT) generates token-level embeddings that enable fine-grained matching between query and document tokens. This \"late interaction\" approach achieves the highest accuracy for exact phrase matching and technical document retrieval.  **When to Use**:     - High-precision legal document search requiring exact phrase matching     - Medical/scientific literature retrieval with technical terminology     - Patent search where specific term combinations are critical     - Code search requiring exact function/variable name matching     - Compliance documents where exact wording matters     - Technical documentation with domain-specific jargon     - Any scenario where precision > recall and storage cost is acceptable  **When NOT to Use**:     - General semantic search with moderate accuracy needs → Use text_extractor (125x less storage)     - Real-time search requiring <10ms latency → Use text_extractor (5x faster)     - Cost-sensitive applications on large datasets → Storage costs 125x more than text_extractor     - Datasets over 10M documents → Consider splade_extractor (25x less storage)     - Very short texts (1-10 words) → Overhead not worth it, use text_extractor  **Comparison with Other Text Extractors**:      | Feature | colbert_extractor | text_extractor | splade_extractor |     |---------|-------------------|----------------|------------------|     | **Accuracy (BEIR avg)** | 92% | 88% | 90% |     | **Precision** | Excellent | Good | Excellent |     | **Recall** | Excellent | Excellent | Good |     | **Speed (per doc)** | 15ms | 5ms | 10ms |     | **Storage per doc** | 500KB | 4KB | 20KB |     | **Storage vs dense** | 125x more | Baseline | 5x more |     | **Query Latency** | 50-100ms | <10ms | 20-30ms |     | **Best For** | Precision | General | Hybrid |     | **Exact Matching** | Excellent | Poor | Excellent |     | **Semantic Matching** | Excellent | Excellent | Good |     | **Multi-language** | Good | Excellent | Good |     | **Explainability** | Excellent (token-level) | Poor | Good (keyword weights) |  **Model Details**:     - Model: ColBERTv2 (based on BERT)     - Token Embeddings: 128 dimensions per token     - Max Tokens: Configurable (default 128, range 16-512)     - Context Length: Up to 512 tokens     - Scoring: MaxSim (maximum similarity per query token)     - Distance Metric: Cosine similarity per token pair     - Languages: Primarily English (multilingual variants available)  **How It Works**:     1. **Tokenization**: Text is split into tokens (words/subwords)     2. **Contextualization**: Each token gets its own 128D embedding     3. **Late Interaction**: At query time, each query token finds its best match in document     4. **Scoring**: Sum of maximum similarities (MaxSim) across all query tokens     5. **Result**: Fine-grained matching that preserves phrase structure  **Performance Characteristics**:     - Embedding Generation: 15ms per document (batched: 8ms/doc)     - Index Build: ~5 hours per 10M documents     - Query Time: 50-100ms for top-100 results (5-10x slower than dense)     - Memory: ~500GB per 1M documents (125x more than dense)     - Storage Cost: $50 per 1M documents vs $0.40 for dense  **Use Case Examples**:     1. **Legal Document Search**: Find contracts with exact clause wording, 95%+ precision     2. **Medical Literature**: Search 1M PubMed articles for specific drug-disease combinations     3. **Patent Search**: Find prior art with specific technical term combinations     4. **Code Search**: Search 100K code files for exact function signatures     5. **Compliance Search**: Find regulatory documents with specific requirement phrases  **Storage Warning**:     ColBERT uses significantly more storage than dense embeddings:     - 1K docs: 500MB vs 4MB (text_extractor)     - 100K docs: 50GB vs 400MB     - 1M docs: 500GB vs 4GB     - 10M docs: 5TB vs 40GB      Budget accordingly! For cost-sensitive applications, consider text_extractor or splade_extractor.  **Limitations**:     - 125x more storage than dense embeddings     - 5-10x slower query latency than dense embeddings     - Primarily English (multilingual support limited)     - Requires more GPU memory for indexing     - Not suitable for very large datasets (>10M documents) without significant infrastructure  Requirements:     - text field: REQUIRED (string or text type)     - max_doc_tokens: OPTIONAL (defaults to 128)
    """ # noqa: E501
    max_doc_tokens: Optional[Annotated[int, Field(le=512, strict=True, ge=16)]] = Field(default=128, description="NOT REQUIRED. Maximum number of tokens per document. Defaults to 128. Longer documents are truncated. WARNING: Higher values = 125x more storage! Typical: 128 (balanced), 256 (long documents), 32 (short).")
    __properties: ClassVar[List[str]] = ["max_doc_tokens"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ColbertExtractorParams from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ColbertExtractorParams from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "max_doc_tokens": obj.get("max_doc_tokens") if obj.get("max_doc_tokens") is not None else 128
        })
        return _obj


