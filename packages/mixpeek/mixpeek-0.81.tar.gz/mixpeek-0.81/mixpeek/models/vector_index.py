# coding: utf-8

"""
    Mixpeek API

    This is the Mixpeek API, providing access to various endpoints for data processing and retrieval.

    The version of the OpenAPI document: 0.81
    Contact: info@mixpeek.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from mixpeek.models.bucket_schema_field_type import BucketSchemaFieldType
from mixpeek.models.vector_data_type import VectorDataType
from mixpeek.models.vector_type import VectorType
from typing import Optional, Set
from typing_extensions import Self

class VectorIndex(BaseModel):
    """
    Configuration for a single vector index in Qdrant.  Defines the fully-qualified vector index including storage name, dimensions, distance metric, and inference service. This is the actual index that gets created in Qdrant and used for vector similarity search.  Key Concepts:     - The `name` field is the FULL qualified name used as the Qdrant collection name     - Format: {extractor}_{version}_{output} (e.g., \"text_extractor_v1_embedding\")     - This ensures namespace isolation between extractors and versions     - Different from VectorIndexDefinition.name which is the short user-facing name  Use Cases:     - Define vector storage configuration for feature extractors     - Specify inference service and model parameters     - Configure distance metrics for similarity search     - Set storage optimization (on-disk for large vectors)  Requirements:     - name: REQUIRED - Must be unique across all extractors in namespace     - description: REQUIRED - Explain what this vector represents     - dimensions: REQUIRED for DENSE vectors, OPTIONAL for SPARSE     - type: REQUIRED - Must match VectorType enum     - inference_name: REQUIRED - Must reference a valid inference service
    """ # noqa: E501
    name: Annotated[str, Field(min_length=1, strict=True)] = Field(description="REQUIRED. Fully-qualified vector index name (Qdrant collection name). Format: {extractor}_{version}_{output} (e.g., 'text_extractor_v1_embedding'). This is the STORAGE name used internally in Qdrant, NOT the user-facing short name. Must be unique across all extractors in the namespace to prevent collisions. Different versions of same extractor use different names for isolation.")
    description: Annotated[str, Field(min_length=10, strict=True)] = Field(description="REQUIRED. Human-readable description of what this vector index represents. Explain the content type, use cases, and search characteristics. Shown in API documentation and collection metadata. Be specific about what embeddings are stored here.")
    dimensions: Optional[Annotated[int, Field(strict=True, ge=1)]] = Field(default=None, description="Number of vector dimensions. REQUIRED for DENSE vectors (e.g., 1024 for E5-Large, 1408 for multimodal). NOT REQUIRED for SPARSE vectors (dimensions determined dynamically). Must match the output dimensions of the inference service. Cannot be changed after index creation without recreating the collection.")
    type: VectorType = Field(description="REQUIRED. Vector storage format type. Determines how vectors are stored and searched in Qdrant. Use DENSE for traditional embeddings (most common), SPARSE for keyword-based models like SPLADE, MULTI_DENSE for late-interaction models like ColBERT. Must match the output format of your inference service.")
    distance: Optional[StrictStr] = Field(default='cosine', description="Distance metric for similarity search. OPTIONAL - defaults to 'cosine' (normalized dot product). Options: 'cosine' (most common, normalized), 'dot' (raw dot product), 'euclidean' (L2 distance), 'manhattan' (L1 distance). Cosine recommended for most embeddings as it's scale-invariant. Must match the metric your model was trained with.")
    datatype: Optional[VectorDataType] = Field(default=None, description="Data type for storing vector values. OPTIONAL - defaults to FLOAT32 (standard precision). Use FLOAT32 for general use (4 bytes per dimension). Use FLOAT16 to save 50% storage with minimal quality loss. Use UINT8 for maximum compression (quantization, ~2% quality loss). Lower precision = smaller storage + faster search, slightly lower accuracy.")
    on_disk: Optional[StrictBool] = Field(default=None, description="OPTIONAL. If true, vectors stored on disk instead of RAM. Use for very large vectors (>2GB total) to save memory. Trade-off: ~10x slower search, but unlimited capacity. Defaults to false (RAM storage) for fast search. Enable for: massive datasets, high-dimensional vectors (>2048 dims), or when RAM is constrained. Recommended for ColBERT (500KB/doc).")
    supported_inputs: Optional[List[BucketSchemaFieldType]] = Field(default=None, description="OPTIONAL. List of bucket schema field types this vector can process. Validates that input fields are compatible with this index. Examples: TEXT and STRING for text embeddings, VIDEO and IMAGE for multimodal embeddings, DOCUMENT for PDF extractors. Used for validation during collection creation.")
    inference_name: Optional[StrictStr] = Field(default=None, description="REQUIRED. Identifier of the inference service to generate embeddings. Must reference a valid inference service registered in the system. Examples: 'multilingual_e5_large_instruct_v1' for text, 'vertex_multimodal_embedding' for video, 'laion_clip_vit_l_14_v1' for images. This determines which model creates the vectors during ingestion. Cannot be changed after collection creation.")
    __properties: ClassVar[List[str]] = ["name", "description", "dimensions", "type", "distance", "datatype", "on_disk", "supported_inputs", "inference_name"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of VectorIndex from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of VectorIndex from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "name": obj.get("name"),
            "description": obj.get("description"),
            "dimensions": obj.get("dimensions"),
            "type": obj.get("type"),
            "distance": obj.get("distance") if obj.get("distance") is not None else 'cosine',
            "datatype": obj.get("datatype"),
            "on_disk": obj.get("on_disk"),
            "supported_inputs": obj.get("supported_inputs"),
            "inference_name": obj.get("inference_name")
        })
        return _obj


