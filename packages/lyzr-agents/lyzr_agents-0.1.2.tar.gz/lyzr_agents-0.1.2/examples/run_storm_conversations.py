"""
Run STORM with TRUE PARALLEL per-persona conversations.

Each expert has their own Q&A session running in parallel:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXPERT 1        â”‚ EXPERT 2        â”‚ EXPERT 3        â”‚
â”‚ Q1 â†’ Research   â”‚ Q1 â†’ Research   â”‚ Q1 â†’ Research   â”‚
â”‚ Q2 â†’ Research   â”‚ Q2 â†’ Research   â”‚ Q2 â†’ Research   â”‚
â”‚ (follow-ups!)   â”‚ (follow-ups!)   â”‚ (follow-ups!)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              All running simultaneously!
"""

import asyncio
import sys
import time
from src.agents import StormAgent, StormAgentConfig, StormEvent, StormEventType, test_config


start_time = None


def on_event(event: StormEvent):
    """Display events with timing and conversation grouping."""
    global start_time

    if start_time is None:
        start_time = time.time()

    elapsed = time.time() - start_time
    icons = {"running": "â³", "completed": "âœ…", "failed": "âŒ"}
    icon = icons.get(event.status, "â€¢")
    step = event.step_name or event.event_type.value

    # Show conversation structure
    if event.event_type == StormEventType.PERSONA_CONVERSATION_STARTED:
        print(f"\n[{elapsed:6.1f}s] â”Œâ”€â”€ {icon} {step}")
        print(f"          â”‚    Persona: {event.data.get('persona', '')[:40]}")
    elif event.event_type == StormEventType.PERSONA_CONVERSATION_COMPLETED:
        chars = event.data.get('total_research_chars', 0)
        print(f"[{elapsed:6.1f}s] â””â”€â”€ {icon} {step} ({chars} chars researched)")
    elif event.event_type in [StormEventType.QUESTION_GENERATION_STARTED,
                               StormEventType.QUESTION_CREATED,
                               StormEventType.RESEARCH_STARTED,
                               StormEventType.RESEARCH_ANSWER_RECEIVED]:
        # Inside conversation
        detail = ""
        if event.event_type == StormEventType.QUESTION_CREATED:
            detail = f" â†’ {event.data.get('question', '')[:40]}..."
        elif event.event_type == StormEventType.RESEARCH_ANSWER_RECEIVED:
            detail = f" â†’ {event.data.get('answer_length', 0)} chars"
        print(f"[{elapsed:6.1f}s]     â”‚ {icon} {step}{detail}")
    elif event.event_type == StormEventType.STORM_COMPLETED:
        total = time.time() - start_time
        print(f"\n{'='*55}")
        print(f"âš¡ Completed in {total:.1f}s with PARALLEL conversations!")
    else:
        indent = "    " if event.parallel_group else "  "
        print(f"[{elapsed:6.1f}s] {indent}{icon} {step}")

    sys.stdout.flush()


async def main():
    global start_time

    print("=" * 60)
    print("ğŸŒ©ï¸  STORM - Parallel Expert Conversations")
    print("=" * 60)
    print("""
Each expert runs their Q&A session in parallel:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Expert 1    â”‚ Expert 2    â”‚ Expert 3    â”‚
â”‚ Qâ†’Râ†’Qâ†’R     â”‚ Qâ†’Râ†’Qâ†’R     â”‚ Qâ†’Râ†’Qâ†’R     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         All simultaneous!
""")

    # Use real Lyzr API with parallel conversations
    agent = StormAgent(
        lyzr_api_key="sk-default-obhGvAo6gG9YT9tu6ChjyXLqnw7TxSGY",
        user_id="demo@lyzr.ai",
        config=StormAgentConfig(),  # All defaults
        no_of_personas=3,
        no_of_questions=2,
        no_of_sections=4,
        on_event=on_event,
    )

    topic = "The Future of Renewable Energy"

    print(f"ğŸ“ Topic: {topic}")
    print(f"ğŸ‘¥ Parallel Expert Sessions: {agent.no_of_personas}")
    print(f"â“ Questions per expert (with follow-ups): {agent.no_of_questions}")
    print("-" * 60)

    start_time = time.time()

    # Run with parallel conversations
    result = await agent.write_async(topic)

    print("-" * 60)

    if result.success:
        print(f"\nğŸ“Š Summary:")
        print(f"   â€¢ Personas: {len(result.personas)}")
        print(f"   â€¢ Questions: {sum(len(q) for q in result.questions.values())}")
        print(f"   â€¢ Research: {len(result.research)} answers")
        print(f"   â€¢ Sections: {len(result.sections)}")
        print(f"   â€¢ Events: {len(result.events)}")

        # Count conversation events
        conv_events = [e for e in result.events
                       if e.event_type == StormEventType.PERSONA_CONVERSATION_COMPLETED]
        print(f"\n   âœ… {len(conv_events)} parallel conversations completed!")

    else:
        print(f"\nâŒ Error: {result.error}")


if __name__ == "__main__":
    asyncio.run(main())
