[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm-radar-mcp"
version = "0.1.1"
description = "MCP server providing real-time AI model intelligence - pricing, capabilities, and recommendations"
readme = "README.md"
license = "MIT"
requires-python = ">=3.10"
authors = [
    { name = "ajentsor" }
]
keywords = ["mcp", "llm", "ai", "models", "anthropic", "openai", "google", "gemini", "claude"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]

dependencies = [
    "mcp>=1.0.0",
    "httpx>=0.27.0",
    "anthropic>=0.40.0",
    "python-dotenv>=1.0.0",
    "uvicorn>=0.30.0",
    "starlette>=0.38.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
]

[project.scripts]
llm-radar-mcp = "llm_radar.mcp_server:main"

[project.urls]
Homepage = "https://llm-radar.ajents.company"
Repository = "https://github.com/ajentsor/llm-radar"
Documentation = "https://github.com/ajentsor/llm-radar#readme"

[tool.hatch.build.targets.wheel]
packages = ["src/llm_radar"]

[tool.hatch.build.targets.sdist]
include = [
    "/src",
    "/data/models.json",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W"]
ignore = ["E501"]
