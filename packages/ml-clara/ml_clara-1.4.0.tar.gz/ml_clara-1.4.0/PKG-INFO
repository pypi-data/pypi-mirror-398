Metadata-Version: 2.4
Name: ml-clara
Version: 1.4.0
Summary: Local LLM Inference Platform with adapter support and evaluation toolkit
Author: ML-Clara Team
License-Expression: LicenseRef-Apple
Project-URL: Homepage, https://github.com/Mojo-Solo/clara/blob/main/README_ML_CLARA.md
Project-URL: Documentation, https://github.com/Mojo-Solo/clara/blob/main/README_ML_CLARA.md
Project-URL: Repository, https://github.com/Mojo-Solo/clara
Project-URL: Changelog, https://github.com/Mojo-Solo/clara/blob/main/CHANGELOG.md
Project-URL: Issues, https://github.com/Mojo-Solo/clara/issues
Keywords: llm,inference,lora,fine-tuning,mistral,transformers,cli,mps,apple-silicon
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Operating System :: OS Independent
Classifier: Environment :: Console
Requires-Python: <3.13,>=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch>=2.0.0
Requires-Dist: transformers>=4.30.0
Requires-Dist: huggingface-hub>=0.15.0
Requires-Dist: peft>=0.4.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: rich>=13.0.0
Requires-Dist: click>=8.0.0
Requires-Dist: datasets>=2.14.0
Requires-Dist: tqdm>=4.65.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: pytest-xdist>=3.0.0; extra == "dev"
Requires-Dist: httpx>=0.27.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Provides-Extra: eval
Requires-Dist: datasets>=2.14.0; extra == "eval"
Provides-Extra: server
Requires-Dist: fastapi>=0.110.0; extra == "server"
Requires-Dist: uvicorn[standard]>=0.27.0; extra == "server"
Dynamic: license-file

# ML-Clara

ML-Clara is a small, config-driven CLI + Python API for:

- Local LLM inference with streaming (`clara run`)
- Lightweight benchmarking (`clara eval`)
- LoRA fine-tuning (`clara train`) and adapter merging (`clara export`)
- Device auto-detection (MPS/CUDA/CPU)

This repository also contains Appleâ€™s **CLaRa** research codebase; ML-Clara lives in the `clara/` package.

---

## Install

```bash
pip install ml-clara
clara info
```

If your platform needs a specific PyTorch build, install PyTorch first, then install ML-Clara.

---

## Quickstart

### Run

```bash
clara run "Explain LoRA in one paragraph" --model gpt2
clara run "Write a haiku about debugging" --model gpt2 --stream
```

### Create a config (recommended)

```bash
clara init-config --type default -o config.yaml
clara run "Hello" --config config.yaml
```

### Eval

```bash
clara eval --model gpt2 --benchmarks perplexity --samples 50
```

### Fine-tune (LoRA)

```bash
clara init-config --type finetune -o finetune.yaml
clara train --config finetune.yaml
```

### Web UI (FastAPI)

```bash
pip install "ml-clara[server]"
clara serve --model gpt2
```

Then open `http://127.0.0.1:8000`.

The server also exposes OpenAI-compatible endpoints (for Open WebUI/LangChain):
- `GET /v1/models`
- `POST /v1/chat/completions` (supports `stream: true` via SSE)

### Export (merge adapter)

```bash
clara export outputs/my-adapter/final --output models/merged
```

---

## Docs

- Troubleshooting: `docs/TROUBLESHOOTING.md`
- Full repository README (CLaRa research + ML-Clara section): `README.md`
