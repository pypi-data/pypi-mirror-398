# ML-Clara inference config template
#
# Works with:
#   clara run --config config.yaml "Hello"
#   clara eval --config config.yaml --benchmarks perplexity --samples 50

model:
  # Hugging Face model id OR a local folder containing a model + tokenizer.
  hf_id: mistralai/Mistral-7B-Instruct-v0.2
  local_path: null

  # float32 | float16 | bfloat16 | auto
  dtype: auto

  # Needed for some community models; keep false unless required.
  trust_remote_code: false

device:
  # null = auto-detect (MPS > CUDA > CPU)
  device: null

inference:
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  repetition_penalty: 1.1
  do_sample: true
  stop_tokens: []

adapters:
  available: []
  active: null
  settings:
    validate_compatibility: true
    merge_weights: true

