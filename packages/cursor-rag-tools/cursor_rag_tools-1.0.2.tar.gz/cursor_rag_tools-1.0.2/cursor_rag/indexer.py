"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –ø—Ä–æ–µ–∫—Ç–æ–≤ –¥–ª—è cursor-rag-tools.
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–º–µ–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∞.
"""

import os
import re
import sys
import time
import warnings
from pathlib import Path
from typing import Any, Optional

import chromadb
from sentence_transformers import SentenceTransformer

from .chunking import Chunk, chunk_file, text_chunks
from .config import (
    MAX_RETRIES,
    RETRY_DELAY,
    ensure_db_path,
    get_allowed_ext,
    get_chunk_overlap,
    get_chunk_size,
    get_db_path,
    get_enable_semantic_chunking,
    get_ignore_dirs,
    get_ignore_ext,
    get_max_chunks_per_file,
    get_max_file_bytes,
    get_min_chunk_size,
    get_model,
    get_slow_file_seconds,
)

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫
warnings.filterwarnings("ignore")


def transliterate_cyrillic(text: str) -> str:
    """
    –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É –≤ –ª–∞—Ç–∏–Ω–∏—Ü—É –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å ChromaDB.

    Args:
        text: –¢–µ–∫—Å—Ç —Å –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏

    Returns:
        str: –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    cyrillic_to_latin = {
        "–∞": "a",
        "–±": "b",
        "–≤": "v",
        "–≥": "g",
        "–¥": "d",
        "–µ": "e",
        "—ë": "yo",
        "–∂": "zh",
        "–∑": "z",
        "–∏": "i",
        "–π": "y",
        "–∫": "k",
        "–ª": "l",
        "–º": "m",
        "–Ω": "n",
        "–æ": "o",
        "–ø": "p",
        "—Ä": "r",
        "—Å": "s",
        "—Ç": "t",
        "—É": "u",
        "—Ñ": "f",
        "—Ö": "h",
        "—Ü": "ts",
        "—á": "ch",
        "—à": "sh",
        "—â": "sch",
        "—ä": "",
        "—ã": "y",
        "—å": "",
        "—ç": "e",
        "—é": "yu",
        "—è": "ya",
        "–ê": "A",
        "–ë": "B",
        "–í": "V",
        "–ì": "G",
        "–î": "D",
        "–ï": "E",
        "–Å": "Yo",
        "–ñ": "Zh",
        "–ó": "Z",
        "–ò": "I",
        "–ô": "Y",
        "–ö": "K",
        "–õ": "L",
        "–ú": "M",
        "–ù": "N",
        "–û": "O",
        "–ü": "P",
        "–†": "R",
        "–°": "S",
        "–¢": "T",
        "–£": "U",
        "–§": "F",
        "–•": "H",
        "–¶": "Ts",
        "–ß": "Ch",
        "–®": "Sh",
        "–©": "Sch",
        "–™": "",
        "–´": "Y",
        "–¨": "",
        "–≠": "E",
        "–Æ": "Yu",
        "–Ø": "Ya",
    }

    result = []
    for char in text:
        result.append(cyrillic_to_latin.get(char, char))
    return "".join(result)


def auto_detect_project_name(project_path: Path) -> str:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞ –∏–∑ –ø—É—Ç–∏.
    –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ—Ç –∫–∏—Ä–∏–ª–ª–∏—Ü—É, —É–±–∏—Ä–∞–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –∏ –¥–µ–ª–∞–µ—Ç –∏–º—è —á–∏—Ç–∞–µ–º—ã–º.

    Args:
        project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É

    Returns:
        str: –û—á–∏—â–µ–Ω–Ω–æ–µ –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    """
    name = project_path.name

    # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ–º –∫–∏—Ä–∏–ª–ª–∏—Ü—É
    name = transliterate_cyrillic(name)

    # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    name = re.sub(r"[^a-zA-Z0-9\s_-]", "", name)
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –¥–µ—Ñ–∏—Å—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    name = re.sub(r"[\s-]+", "_", name)
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è
    name = re.sub(r"_+", "_", name)
    # –£–±–∏—Ä–∞–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    name = name.strip("_")

    # –ï—Å–ª–∏ –∏–º—è –ø—É—Å—Ç–æ–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ
    if not name or len(name) < 2:
        name = "project"

    return name.lower()


class Indexer:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π ChromaDB.
    """

    def __init__(
        self,
        db_path: Optional[Path] = None,
        model_name: Optional[str] = None,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞.

        Args:
            db_path: –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
        """
        self.db_path = db_path if db_path else get_db_path()
        self.model_name = model_name if model_name else get_model()
        self.client: Any | None = None
        self.model: Optional[SentenceTransformer] = None

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ë–î –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        ensure_db_path(self.db_path)

    def _get_client(self) -> Any:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å ChromaDB –∫–ª–∏–µ–Ω—Ç–∞ —Å retry –ª–æ–≥–∏–∫–æ–π.

        Returns:
            chromadb.PersistentClient: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç

        Raises:
            RuntimeError: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫
        """
        if self.client is not None:
            return self.client

        for attempt in range(MAX_RETRIES):
            try:
                self.client = chromadb.PersistentClient(path=str(self.db_path))
                return self.client
            except Exception as e:
                error_msg = str(e)
                if "database is locked" in error_msg.lower() or "locked" in error_msg.lower():
                    if attempt < MAX_RETRIES - 1:
                        print(
                            f"‚ö†Ô∏è  –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{MAX_RETRIES}...",
                            file=sys.stderr,
                        )
                        time.sleep(RETRY_DELAY)
                    else:
                        raise RuntimeError(
                            f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ ChromaDB –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫.\n"
                            f"–í–æ–∑–º–æ–∂–Ω–æ, –¥—Ä—É–≥–æ–π –ø—Ä–æ—Ü–µ—Å—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ë–î: {self.db_path}\n"
                            f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å –ë–î."
                        ) from e
                else:
                    raise RuntimeError(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB: {e}") from e

        raise RuntimeError("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å ChromaDB –∫–ª–∏–µ–Ω—Ç")

    def _get_model(self) -> SentenceTransformer:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.

        Returns:
            SentenceTransformer: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        """
        if self.model is None:
            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...")
            self.model = SentenceTransformer(self.model_name)
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return self.model

    def get_files(self, root_dir: Path) -> list[Path]:
        """
        –°–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.

        Args:
            root_dir: –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            list[Path]: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
        """
        ignore_dirs = get_ignore_dirs()
        ignore_ext = get_ignore_ext()
        allowed_ext = get_allowed_ext()

        files_to_process = []
        print(f"üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –≤: {root_dir}")

        for root, dirs, files in os.walk(root_dir):
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–∞–ø–æ–∫ in-place
            dirs[:] = [d for d in dirs if d not in ignore_dirs and not d.startswith(".")]

            for file in files:
                file_path = Path(root) / file

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                if file_path.suffix in ignore_ext:
                    continue

                # –ï—Å–ª–∏ –∑–∞–¥–∞–Ω—ã —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö
                if allowed_ext and file_path.suffix not in allowed_ext:
                    continue

                files_to_process.append(file_path)

        return files_to_process

    def chunk_text(self, text: str, chunk_size: Optional[int] = None, overlap: Optional[int] = None) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º.

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (–µ—Å–ª–∏ None, –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
            overlap: –†–∞–∑–º–µ—Ä –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è (–µ—Å–ª–∏ None, –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)

        Returns:
            list[str]: –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤
        """
        if not text:
            return []

        chunk_size = chunk_size if chunk_size else get_chunk_size()
        overlap = overlap if overlap else get_chunk_overlap()

        chunks = []
        for i in range(0, len(text), chunk_size - overlap):
            chunks.append(text[i : i + chunk_size])

        return chunks

    def chunk_document(
        self,
        *,
        content: str,
        file_path: Path,
        chunk_size: Optional[int] = None,
        overlap: Optional[int] = None,
    ) -> list[Chunk]:
        """
        Chunk a file content. Prefers semantic chunking for code files when enabled.
        """
        chunk_size = chunk_size if chunk_size else get_chunk_size()
        overlap = overlap if overlap else get_chunk_overlap()
        min_chunk_size = get_min_chunk_size()
        enable_semantic = get_enable_semantic_chunking()

        try:
            return chunk_file(
                content=content,
                file_path=file_path,
                max_chars=chunk_size,
                overlap=overlap,
                min_chars=min_chunk_size,
                enable_semantic=enable_semantic,
            )
        except Exception:
            # Safety net: never fail indexing because of chunking.
            return text_chunks(content, max_chars=chunk_size, overlap=overlap)

    def index_project(
        self,
        project_path: str | Path,
        project_name: Optional[str] = None,
        force: bool = False,
    ) -> tuple[int, int]:
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –ø—Ä–æ–µ–∫—Ç –≤ ChromaDB.

        Args:
            project_path: –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
            project_name: –ò–º—è –ø—Ä–æ–µ–∫—Ç–∞ (–µ—Å–ª–∏ None, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            force: –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å

        Returns:
            tuple[int, int]: (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤)

        Raises:
            ValueError: –ï—Å–ª–∏ –ø—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            RuntimeError: –ï—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ force=False
        """
        path = Path(project_path).resolve()
        if not path.exists():
            raise ValueError(f"‚ùå –ü—É—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")

        # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –ø—Ä–æ–µ–∫—Ç–∞
        if project_name is None:
            project_name = auto_detect_project_name(path)

        project_name = project_name.lower()

        print(f"üîç –ò–º—è –ø—Ä–æ–µ–∫—Ç–∞: '{project_name}'")
        print(f"üìÅ –ü—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É: {path}")
        print(f"üì¶ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {self.db_path}")

        # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞
        client = self._get_client()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        existing_collections = [c.name for c in client.list_collections()]
        if project_name in existing_collections:
            if force:
                print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ '{project_name}'...")
                client.delete_collection(project_name)
            else:
                raise RuntimeError(
                    f"‚ö†Ô∏è  –ü—Ä–æ–µ–∫—Ç '{project_name}' —É–∂–µ –µ—Å—Ç—å –≤ –∏–Ω–¥–µ–∫—Å–µ.\n"
                    f"   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–µ –∏–º—è."
                )

        # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
        collection = client.get_or_create_collection(name=project_name)

        # –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
        files = self.get_files(path)
        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")

        if not files:
            print("‚ö†Ô∏è  –§–∞–π–ª—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return 0, 0

        # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model = self._get_model()

        count = 0
        total_chunks = 0

        print("üöÄ –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")
        try:
            max_file_bytes = get_max_file_bytes()
            max_chunks_per_file = get_max_chunks_per_file()
            slow_file_seconds = get_slow_file_seconds()

            skipped_by_size = 0
            skipped_by_chunks = 0
            errored_files = 0

            # Keep a small leaderboard of slow files to help diagnose "hangs".
            slow_files: list[tuple[float, str, dict[str, float], int, int]] = []

            for idx, file_path in enumerate(files, start=1):
                try:
                    # Print "in progress" to avoid perceived hangs on heavy files.
                    print(f"\r‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞: {idx}/{len(files)} ({file_path.name})", end="")

                    # Quick size check before reading the file into memory.
                    try:
                        file_size = file_path.stat().st_size
                    except Exception:
                        file_size = 0
                    if max_file_bytes is not None and file_size > max_file_bytes:
                        skipped_by_size += 1
                        print(
                            f"\n‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫ (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª): {file_path} "
                            f"({file_size} bytes > {max_file_bytes} bytes)"
                        )
                        continue

                    t0 = time.perf_counter()
                    with open(file_path, encoding="utf-8", errors="ignore") as f:
                        content = f.read()
                    t_read = time.perf_counter()

                    if not content.strip():
                        continue

                    t1 = time.perf_counter()
                    chunks = self.chunk_document(content=content, file_path=file_path)
                    t_chunk = time.perf_counter()
                    if not chunks:
                        continue

                    if max_chunks_per_file is not None and len(chunks) > max_chunks_per_file:
                        skipped_by_chunks += 1
                        print(
                            f"\n‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫ (—Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —á–∞–Ω–∫–æ–≤): {file_path} ({len(chunks)} > {max_chunks_per_file})"
                        )
                        continue

                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –±–∞—Ç—á–µ–º –¥–ª—è —Ñ–∞–π–ª–∞
                    documents = [c.text for c in chunks]
                    t2 = time.perf_counter()
                    embeddings = model.encode(documents)
                    t_encode = time.perf_counter()

                    source_str = str(file_path)
                    ids = []
                    metadatas = []
                    for i, c in enumerate(chunks):
                        start_line = c.start_line if c.start_line is not None else 0
                        end_line = c.end_line if c.end_line is not None else 0
                        ids.append(f"{source_str}::{start_line}-{end_line}::{i}")
                        raw_meta = {
                            "source": source_str,
                            "chunk": i,
                            "start_line": c.start_line,
                            "end_line": c.end_line,
                            "symbol_type": c.symbol_type,
                            "symbol_name": c.symbol_name,
                            "language": c.language,
                        }
                        # Chroma metadata values must be non-null primitives.
                        metadatas.append({k: v for k, v in raw_meta.items() if v is not None})

                    collection.add(
                        ids=ids,
                        documents=documents,
                        embeddings=embeddings.tolist(),
                        metadatas=metadatas,
                    )
                    t_add = time.perf_counter()

                    total_chunks += len(chunks)
                    count += 1
                    print(f"\r‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {count}/{len(files)} ({file_path.name})", end="")

                    total_s = t_add - t0
                    if slow_file_seconds > 0 and total_s >= slow_file_seconds:
                        timings = {
                            "read_s": t_read - t0,
                            "chunk_s": t_chunk - t1,
                            "encode_s": t_encode - t2,
                            "add_s": t_add - t_encode,
                            "total_s": total_s,
                        }
                        slow_files.append((total_s, str(file_path), timings, file_size, len(chunks)))
                        # Keep only top 10 slowest
                        slow_files.sort(key=lambda x: x[0], reverse=True)
                        slow_files = slow_files[:10]

                except Exception as e:
                    errored_files += 1
                    print(f"\n‚ùå –û—à–∏–±–∫–∞ —Å —Ñ–∞–π–ª–æ–º {file_path.name}: {e}")

            print(f"\n\n‚ú® –ì–æ—Ç–æ–≤–æ! –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {count}, –≤—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
            if skipped_by_size or skipped_by_chunks or errored_files:
                print(
                    "üìå –°–≤–æ–¥–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤/–æ—à–∏–±–æ–∫:\n"
                    f"  - –ü—Ä–æ–ø—É—â–µ–Ω–æ –ø–æ —Ä–∞–∑–º–µ—Ä—É: {skipped_by_size}\n"
                    f"  - –ü—Ä–æ–ø—É—â–µ–Ω–æ –ø–æ —á–∞–Ω–∫–∞–º: {skipped_by_chunks}\n"
                    f"  - –û—à–∏–±–æ–∫ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {errored_files}"
                )
            if slow_files:
                print("\nüê¢ –°–∞–º—ã–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (top 10):")
                for total_s, path_str, timings, size_b, n_chunks in slow_files:
                    print(
                        f"  - {total_s:.2f}s | chunks={n_chunks} | size={size_b}B | {path_str}\n"
                        f"    read={timings['read_s']:.2f}s, chunk={timings['chunk_s']:.2f}s, "
                        f"encode={timings['encode_s']:.2f}s, add={timings['add_s']:.2f}s"
                    )
            print(f"üí° –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MCP —Å –∏–º–µ–Ω–µ–º –ø—Ä–æ–µ–∫—Ç–∞: '{project_name}'")

            return count, total_chunks

        except KeyboardInterrupt:
            print("\n‚õî –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return count, total_chunks

    def list_projects(self) -> list[tuple[str, int]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.

        Returns:
            list[tuple[str, int]]: –°–ø–∏—Å–æ–∫ (–∏–º—è –ø—Ä–æ–µ–∫—Ç–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
        """
        client = self._get_client()
        collections = client.list_collections()

        result = []
        for col in collections:
            try:
                count = col.count()
                result.append((col.name, count))
            except Exception:
                result.append((col.name, 0))

        return result

    def delete_project(self, project_name: str) -> bool:
        """
        –£–¥–∞–ª–∏—Ç—å –ø—Ä–æ–µ–∫—Ç –∏–∑ –∏–Ω–¥–µ–∫—Å–∞.

        Args:
            project_name: –ò–º—è –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è

        Returns:
            bool: True –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –ø—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        client = self._get_client()
        existing = [c.name for c in client.list_collections()]

        if project_name not in existing:
            return False

        client.delete_collection(project_name)
        return True
