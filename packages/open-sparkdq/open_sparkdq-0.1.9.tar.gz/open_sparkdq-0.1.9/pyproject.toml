[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "open-sparkdq"
version = "0.1.9"
description = "Plug-and-play Data Quality + Unit Testing for PySpark (batch & streaming) with YAML config, profiling, and optional OpenTelemetry hooks."
readme = "README.md"
license = { file = "LICENSE" }
authors = [{ name = "Aashish Kumar", email = "aashish72.it@gmail.com" }]
requires-python = ">=3.9"

dependencies = [
  "pyspark>=3.3,<3.6",
  "pyyaml>=6.0",
  "chispa>=0.9.2",
  "jsonschema>=4.0",
  "pydeequ>=1.2.0",
]

[project.optional-dependencies]
otel = ["opentelemetry-sdk>=1.24.0", "opentelemetry-api>=1.24.0"]
docs = ["mkdocs", "mkdocs-material"]
dev = ["pytest>=7.0", "pytest-cov", "build", "twine"]

[project.scripts]
# If your CLI exposes main()
sparkdq = "sparkdq.cli.main:main"

[project.urls]
Homepage = "https://github.com/aashish72it/open-spark-dlh-dq"
Issues   = "https://github.com/aashish72it/open-spark-dlh-dq/issues"

[tool.setuptools]
include-package-data = true

[tool.setuptools.packages.find]
where = ["."]
include = ["sparkdq*"]

[tool.setuptools.package-data]
sparkdq = [
  "resources/*.yml",
  "resources/*.yaml",
  "resources/deequ/*.jar",
]