# Code Quality Gate
# Enforces formatting, linting, compilation safety, attribution guards, and tests.
# Split into semantic jobs for clarity and parallel execution.
#
# Job Structure:
#   - code-quality: Formatting, linting, attribution (runs once on 3.11)
#   - core-security-tests: Critical security and core module validation
#   - ui-tests: Textual UI, screens, and app lifecycle tests
#   - utils-cli-tests: Utility functions, CLI, and edge case tests
#
# Performance tests (marked @pytest.mark.slow) are excluded from CI.
# They run via scheduled workflow or manual trigger.

name: Code Quality

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

# Cancel in-progress runs for the same PR or branch
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

# Permissions for GITHUB_TOKEN
permissions:
  contents: read
  pull-requests: write

jobs:
  # ==========================================================================
  # Job 1: Code Quality Checks (Formatting, Linting, Attribution)
  # ==========================================================================
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python 3.11
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          pip install black pylint isort pre-commit

      - name: Check formatting (black)
        run: black --check --diff passfx/

      - name: Check import sorting (isort)
        run: isort --check-only --diff --profile black passfx/

      - name: Lint (pylint)
        run: pylint passfx/ --rcfile=.pylintrc --fail-under=10.0

      - name: Compilation check
        run: find passfx/ -name "*.py" -type f | xargs python -m py_compile

      - name: Attribution guard
        run: |
          python scripts/attribution_guard.py $(find . \
            -type f \( -name "*.py" -o -name "*.md" -o -name "*.txt" -o -name "*.yaml" -o -name "*.yml" -o -name "*.toml" \) \
            ! -path "./.git/*" \
            ! -path "./.venv/*" \
            ! -path "./venv/*" \
            ! -path "./__pycache__/*" \
            ! -path "./.pytest_cache/*" \
            ! -path "./.mypy_cache/*" \
            ! -path "./.ruff_cache/*" \
            ! -path "./dist/*" \
            ! -path "./build/*" \
            ! -path "./*.egg-info/*" \
            ! -name "CLAUDE.md" \
            2>/dev/null || true)

      - name: Pre-commit parity check
        run: pre-commit run --all-files

  # ==========================================================================
  # Job 2: Core & Security Tests
  # Critical security and data integrity validation
  # Includes: crypto, vault, models, integration, security, regression tests
  # ==========================================================================
  core-security-tests:
    name: Core & Security (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: code-quality

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run core & security tests
        run: |
          pytest tests/unit/core tests/integration tests/security tests/regression \
            --cov=passfx.core \
            --cov-report=term-missing \
            --cov-report=xml:coverage-core.xml \
            --cov-fail-under=0 \
            -v \
            --tb=short \
            -ra

      - name: Test summary
        if: always()
        run: |
          echo "## Core & Security Tests (Python ${{ matrix.python-version }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Categories Executed:**" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/unit/core/\` - Crypto, Vault, Models (~950 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/integration/\` - Encryption round-trips (~50 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/security/\` - Threat model validation (~190 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/regression/\` - Security invariant locks (~100 tests)" >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage
        uses: codecov/codecov-action@v5
        if: matrix.python-version == '3.11'
        with:
          files: ./coverage-core.xml
          flags: core-security
          name: core-security-coverage
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # ==========================================================================
  # Job 3: UI & Screens Tests
  # Textual TUI, screen behavior, and app lifecycle validation
  # Includes: UI, screens, app lifecycle tests
  # ==========================================================================
  ui-tests:
    name: UI & Screens (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: code-quality

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run UI & screens tests
        run: |
          pytest tests/ui tests/app tests/screens \
            --cov=passfx.screens \
            --cov=passfx.app \
            --cov-report=term-missing \
            --cov-report=xml:coverage-ui.xml \
            --cov-fail-under=0 \
            -v \
            --tb=short \
            -ra

      - name: Test summary
        if: always()
        run: |
          echo "## UI & Screens Tests (Python ${{ matrix.python-version }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Categories Executed:**" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/ui/\` - Login security, search state machine (~130 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/app/\` - App lifecycle management (~30 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/screens/\` - Credential screen behavior (~50 tests)" >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage
        uses: codecov/codecov-action@v5
        if: matrix.python-version == '3.11'
        with:
          files: ./coverage-ui.xml
          flags: ui-screens
          name: ui-screens-coverage
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # ==========================================================================
  # Job 4: Utilities & CLI Tests
  # Helper functions, CLI entry points, and edge case validation
  # Includes: utils, CLI, edge case tests
  # ==========================================================================
  utils-cli-tests:
    name: Utilities & CLI (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: code-quality

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run utility & CLI tests
        run: |
          pytest tests/utils tests/cli tests/edge \
            --cov=passfx.utils \
            --cov-report=term-missing \
            --cov-report=xml:coverage-utils.xml \
            --cov-fail-under=0 \
            -v \
            --tb=short \
            -ra

      - name: Test summary
        if: always()
        run: |
          echo "## Utilities & CLI Tests (Python ${{ matrix.python-version }})" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Categories Executed:**" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/utils/\` - Password generator, strength, clipboard, I/O (~310 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/cli/\` - CLI entry point validation (~20 tests)" >> $GITHUB_STEP_SUMMARY
          echo "- \`tests/edge/\` - Failure modes and edge cases (~100 tests)" >> $GITHUB_STEP_SUMMARY

      - name: Upload coverage
        uses: codecov/codecov-action@v5
        if: matrix.python-version == '3.11'
        with:
          files: ./coverage-utils.xml
          flags: utils-cli
          name: utils-cli-coverage
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # ==========================================================================
  # Job 5: Performance Test Status
  # Documents that slow tests are intentionally excluded from CI
  # ==========================================================================
  performance-status:
    name: Performance Tests (Skipped)
    runs-on: ubuntu-latest
    needs: code-quality

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python 3.11
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Report skipped performance tests
        run: |
          echo "## Performance Tests Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "⏭️ **Intentionally Skipped in CI**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Performance tests marked with \`@pytest.mark.slow\` are excluded from the" >> $GITHUB_STEP_SUMMARY
          echo "fast CI pipeline to maintain quick feedback for contributors." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**What's Skipped:**" >> $GITHUB_STEP_SUMMARY
          pytest tests/performance --collect-only -q 2>/dev/null | head -20 >> $GITHUB_STEP_SUMMARY || true
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**How to Run Locally:**" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
          echo "pytest tests/performance --run-slow -v" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Scheduled Runs:**" >> $GITHUB_STEP_SUMMARY
          echo "Performance tests run weekly via the [Performance Tests workflow](../../actions/workflows/performance-tests.yml)." >> $GITHUB_STEP_SUMMARY

      - name: Create annotation
        run: |
          echo "::notice title=Performance Tests::Skipped in CI (5 slow tests). Run locally with: pytest tests/performance --run-slow"

  # ==========================================================================
  # Final Summary Job
  # Aggregates all test results and posts PR comment with mergeability verdict
  # ==========================================================================
  ci-summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [code-quality, core-security-tests, ui-tests, utils-cli-tests, performance-status]
    if: always()

    steps:
      - name: Determine job statuses
        id: status
        run: |
          # Map job results to display status
          get_status() {
            case "$1" in
              success) echo "✅ Passed" ;;
              failure) echo "❌ Failed" ;;
              cancelled) echo "⚪ Cancelled" ;;
              skipped) echo "⏭️ Skipped" ;;
              *) echo "❓ Unknown" ;;
            esac
          }

          # Collect all job results
          CODE_QUALITY="${{ needs.code-quality.result }}"
          CORE_SECURITY="${{ needs.core-security-tests.result }}"
          UI_TESTS="${{ needs.ui-tests.result }}"
          UTILS_CLI="${{ needs.utils-cli-tests.result }}"
          PERF_STATUS="${{ needs.performance-status.result }}"

          # Set status outputs
          echo "code_quality=$(get_status $CODE_QUALITY)" >> $GITHUB_OUTPUT
          echo "core_security=$(get_status $CORE_SECURITY)" >> $GITHUB_OUTPUT
          echo "ui_tests=$(get_status $UI_TESTS)" >> $GITHUB_OUTPUT
          echo "utils_cli=$(get_status $UTILS_CLI)" >> $GITHUB_OUTPUT
          echo "perf_status=$(get_status $PERF_STATUS)" >> $GITHUB_OUTPUT

          # Determine mergeability (all required jobs must pass)
          if [[ "$CODE_QUALITY" == "success" && \
                "$CORE_SECURITY" == "success" && \
                "$UI_TESTS" == "success" && \
                "$UTILS_CLI" == "success" ]]; then
            echo "mergeable=true" >> $GITHUB_OUTPUT
            echo "verdict=✅ **Mergeable** — All required checks passed." >> $GITHUB_OUTPUT
          else
            echo "mergeable=false" >> $GITHUB_OUTPUT

            # Build failure reason
            FAILURES=""
            [[ "$CODE_QUALITY" != "success" ]] && FAILURES="$FAILURES code quality,"
            [[ "$CORE_SECURITY" != "success" ]] && FAILURES="$FAILURES core/security tests,"
            [[ "$UI_TESTS" != "success" ]] && FAILURES="$FAILURES UI tests,"
            [[ "$UTILS_CLI" != "success" ]] && FAILURES="$FAILURES utility tests,"
            FAILURES="${FAILURES%,}"  # Remove trailing comma

            echo "verdict=❌ **Not Mergeable** — Failed:$FAILURES" >> $GITHUB_OUTPUT
          fi

      - name: Generate CI summary
        run: |
          echo "# PassFX CI Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Job Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status | Purpose |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|---------|" >> $GITHUB_STEP_SUMMARY
          echo "| Code Quality | ${{ steps.status.outputs.code_quality }} | Formatting, linting, attribution verification |" >> $GITHUB_STEP_SUMMARY
          echo "| Core & Security | ${{ steps.status.outputs.core_security }} | Encryption, vault storage, security invariants |" >> $GITHUB_STEP_SUMMARY
          echo "| UI & Screens | ${{ steps.status.outputs.ui_tests }} | Terminal UI, screen behavior, app lifecycle |" >> $GITHUB_STEP_SUMMARY
          echo "| Utilities & CLI | ${{ steps.status.outputs.utils_cli }} | Helper functions, CLI, edge case handling |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance | ${{ steps.status.outputs.perf_status }} | Benchmarks (skipped in CI, runs weekly) |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Merge Status:** ${{ steps.status.outputs.verdict }}" >> $GITHUB_STEP_SUMMARY

      - name: Post PR comment
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
        run: |
          # Build comment body
          COMMENT_BODY=$(cat <<'COMMENT_EOF'
          <!-- PASSFX_CI_SUMMARY -->
          ## CI Summary

          | Job | Status | Purpose |
          |-----|--------|---------|
          | **Code Quality** | ${{ steps.status.outputs.code_quality }} | Formatting, linting, attribution verification |
          | **Core & Security** | ${{ steps.status.outputs.core_security }} | Encryption, vault storage, security invariants |
          | **UI & Screens** | ${{ steps.status.outputs.ui_tests }} | Terminal UI, screen behavior, app lifecycle |
          | **Utilities & CLI** | ${{ steps.status.outputs.utils_cli }} | Helper functions, CLI, edge case handling |
          | **Performance** | ${{ steps.status.outputs.perf_status }} | Benchmarks (skipped in CI, runs weekly) |

          ---

          **Merge Status:** ${{ steps.status.outputs.verdict }}

          <sub>
          Python versions tested: 3.10, 3.11 · Coverage: Phase 0 (0% threshold) · [View workflow run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          </sub>
          COMMENT_EOF
          )

          # Find existing comment by marker
          EXISTING_COMMENT_ID=$(gh api \
            "repos/${{ github.repository }}/issues/${PR_NUMBER}/comments" \
            --jq '.[] | select(.body | contains("<!-- PASSFX_CI_SUMMARY -->")) | .id' \
            | head -1)

          if [[ -n "$EXISTING_COMMENT_ID" ]]; then
            # Update existing comment
            gh api \
              "repos/${{ github.repository }}/issues/comments/${EXISTING_COMMENT_ID}" \
              -X PATCH \
              -f body="$COMMENT_BODY"
            echo "Updated existing CI summary comment (ID: $EXISTING_COMMENT_ID)"
          else
            # Create new comment
            gh api \
              "repos/${{ github.repository }}/issues/${PR_NUMBER}/comments" \
              -f body="$COMMENT_BODY"
            echo "Created new CI summary comment"
          fi

      - name: Set exit status
        if: steps.status.outputs.mergeable != 'true'
        run: exit 1

      # ========================================================================
      # Slack CI Notification
      # Sends a summary of CI results to #passfx-ci Slack channel.
      #
      # Design Principles:
      # - ALWAYS runs (if: always()) regardless of prior step failures
      # - NON-BLOCKING: Slack failures never fail CI (exit 0 on all error paths)
      # - SECURE: Webhook URL never logged; treated as bearer token
      # - MINIMAL: Pure bash + curl, no external dependencies
      #
      # Mergeability Logic:
      # - Required jobs: code-quality, core-security-tests, ui-tests, utils-cli-tests
      # - performance-status is informational only (skipped in fast CI)
      # - Mergeable = all required jobs returned "success"
      # - Any required job failure/cancellation = not mergeable
      # ========================================================================
      - name: Send Slack Notification
        if: always()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          WORKFLOW_NAME: ${{ github.workflow }}
          BRANCH: ${{ github.head_ref || github.ref_name }}
          COMMIT_SHA: ${{ github.sha }}
          ACTOR: ${{ github.actor }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          RUN_ID: ${{ github.run_id }}
          # Job results from needs context
          JOB_CODE_QUALITY: ${{ needs.code-quality.result }}
          JOB_CORE_SECURITY: ${{ needs.core-security-tests.result }}
          JOB_UI_TESTS: ${{ needs.ui-tests.result }}
          JOB_UTILS_CLI: ${{ needs.utils-cli-tests.result }}
          JOB_PERF_STATUS: ${{ needs.performance-status.result }}
          # Pre-computed mergeability from earlier step
          MERGEABLE: ${{ steps.status.outputs.mergeable }}
        run: |
          set +e  # Do not exit on error - this step must never fail CI

          # ----------------------------------------------------------------
          # Guard: Exit gracefully if webhook is not configured
          # ----------------------------------------------------------------
          if [[ -z "$SLACK_WEBHOOK_URL" ]]; then
            echo "::warning title=Slack Notification::SLACK_WEBHOOK_URL not configured. Skipping notification."
            exit 0
          fi

          # ----------------------------------------------------------------
          # Helper: Map job result to emoji
          # ----------------------------------------------------------------
          job_emoji() {
            case "$1" in
              success)   echo ":white_check_mark:" ;;
              failure)   echo ":x:" ;;
              cancelled) echo ":warning:" ;;
              skipped)   echo ":warning:" ;;
              *)         echo ":grey_question:" ;;
            esac
          }

          # ----------------------------------------------------------------
          # Helper: Map job result to display text
          # ----------------------------------------------------------------
          job_text() {
            case "$1" in
              success)   echo "Passed" ;;
              failure)   echo "Failed" ;;
              cancelled) echo "Cancelled" ;;
              skipped)   echo "Skipped" ;;
              *)         echo "Unknown" ;;
            esac
          }

          # ----------------------------------------------------------------
          # Compute overall CI status
          # ----------------------------------------------------------------
          if [[ "$MERGEABLE" == "true" ]]; then
            HEADER_EMOJI=":white_check_mark:"
            HEADER_TEXT="CI Passed"
            MERGE_STATUS=":white_check_mark: Branch is mergeable"
          else
            HEADER_EMOJI=":x:"
            HEADER_TEXT="CI Failed"
            MERGE_STATUS=":x: Branch is NOT mergeable"
          fi

          # ----------------------------------------------------------------
          # Build job results block
          # Required jobs are marked, performance-status is informational
          # ----------------------------------------------------------------
          JOBS_TEXT=""
          JOBS_TEXT+="$(job_emoji $JOB_CODE_QUALITY) code-quality: $(job_text $JOB_CODE_QUALITY)\n"
          JOBS_TEXT+="$(job_emoji $JOB_CORE_SECURITY) core-security-tests: $(job_text $JOB_CORE_SECURITY)\n"
          JOBS_TEXT+="$(job_emoji $JOB_UI_TESTS) ui-tests: $(job_text $JOB_UI_TESTS)\n"
          JOBS_TEXT+="$(job_emoji $JOB_UTILS_CLI) utils-cli-tests: $(job_text $JOB_UTILS_CLI)\n"
          JOBS_TEXT+="$(job_emoji $JOB_PERF_STATUS) performance-status: $(job_text $JOB_PERF_STATUS) _(informational)_"

          # ----------------------------------------------------------------
          # Short commit SHA (7 characters)
          # ----------------------------------------------------------------
          SHORT_SHA="${COMMIT_SHA:0:7}"

          # ----------------------------------------------------------------
          # Construct Slack Block Kit payload
          # Using heredoc with proper JSON escaping
          # ----------------------------------------------------------------
          read -r -d '' PAYLOAD << 'PAYLOAD_EOF' || true
          {
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "HEADER_PLACEHOLDER",
                  "emoji": true
                }
              },
              {
                "type": "section",
                "fields": [
                  {
                    "type": "mrkdwn",
                    "text": "*Workflow:*\nWORKFLOW_PLACEHOLDER"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Branch:*\nBRANCH_PLACEHOLDER"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Commit:*\n`COMMIT_PLACEHOLDER`"
                  },
                  {
                    "type": "mrkdwn",
                    "text": "*Actor:*\nACTOR_PLACEHOLDER"
                  }
                ]
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*Job Results:*\nJOBS_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "MERGE_PLACEHOLDER"
                }
              },
              {
                "type": "actions",
                "elements": [
                  {
                    "type": "button",
                    "text": {
                      "type": "plain_text",
                      "text": "View Run",
                      "emoji": true
                    },
                    "url": "RUN_URL_PLACEHOLDER"
                  }
                ]
              }
            ]
          }
          PAYLOAD_EOF

          # ----------------------------------------------------------------
          # Replace placeholders with actual values
          # Using sed for reliable substitution
          # ----------------------------------------------------------------
          PAYLOAD="${PAYLOAD//HEADER_PLACEHOLDER/${HEADER_EMOJI} ${HEADER_TEXT}}"
          PAYLOAD="${PAYLOAD//WORKFLOW_PLACEHOLDER/${WORKFLOW_NAME}}"
          PAYLOAD="${PAYLOAD//BRANCH_PLACEHOLDER/${BRANCH}}"
          PAYLOAD="${PAYLOAD//COMMIT_PLACEHOLDER/${SHORT_SHA}}"
          PAYLOAD="${PAYLOAD//ACTOR_PLACEHOLDER/${ACTOR}}"
          PAYLOAD="${PAYLOAD//RUN_URL_PLACEHOLDER/${RUN_URL}}"
          PAYLOAD="${PAYLOAD//MERGE_PLACEHOLDER/${MERGE_STATUS}}"

          # Handle newlines in JOBS_TEXT for JSON
          JOBS_ESCAPED=$(echo -e "$JOBS_TEXT" | sed ':a;N;$!ba;s/\n/\\n/g')
          PAYLOAD="${PAYLOAD//JOBS_PLACEHOLDER/${JOBS_ESCAPED}}"

          # ----------------------------------------------------------------
          # Validate JSON payload (best effort)
          # ----------------------------------------------------------------
          if command -v jq &> /dev/null; then
            if ! echo "$PAYLOAD" | jq . > /dev/null 2>&1; then
              echo "::warning title=Slack Notification::Malformed JSON payload. Skipping notification."
              exit 0
            fi
          fi

          # ----------------------------------------------------------------
          # Send to Slack with retry logic for rate limiting (HTTP 429)
          # - 10 second timeout
          # - Up to 3 retries on 429
          # - Silent mode (no progress output)
          # ----------------------------------------------------------------
          MAX_RETRIES=3
          RETRY_COUNT=0
          RETRY_DELAY=5

          while [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; do
            HTTP_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" \
              --max-time 10 \
              -X POST \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD" \
              "$SLACK_WEBHOOK_URL" 2>/dev/null || echo "000")

            case "$HTTP_RESPONSE" in
              200)
                echo "Slack notification sent successfully."
                exit 0
                ;;
              429)
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [[ $RETRY_COUNT -lt $MAX_RETRIES ]]; then
                  echo "::warning title=Slack Notification::Rate limited (429). Retry $RETRY_COUNT/$MAX_RETRIES in ${RETRY_DELAY}s..."
                  sleep $RETRY_DELAY
                  RETRY_DELAY=$((RETRY_DELAY * 2))  # Exponential backoff
                else
                  echo "::warning title=Slack Notification::Rate limited after $MAX_RETRIES retries. Giving up."
                fi
                ;;
              000)
                echo "::warning title=Slack Notification::Request failed (timeout or network error). Skipping."
                exit 0
                ;;
              *)
                echo "::warning title=Slack Notification::Unexpected HTTP $HTTP_RESPONSE. Skipping."
                exit 0
                ;;
            esac
          done

          # If we exhausted retries, exit gracefully
          echo "::warning title=Slack Notification::Failed to send after retries. CI continues."
          exit 0
