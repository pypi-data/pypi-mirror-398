# Performance Tests Workflow
# Runs slow performance tests that are excluded from the fast CI pipeline.
#
# Triggers:
#   - Weekly schedule (Sunday 2 AM UTC)
#   - Manual dispatch via GitHub UI
#   - Can be triggered from CLI: gh workflow run performance-tests.yml
#
# These tests validate:
#   - Search performance at 1,000+ credential scale
#   - Levenshtein algorithm efficiency
#   - Memory usage under load
#   - <100ms search timing targets

name: Performance Tests

on:
  # Weekly schedule - runs every Sunday at 2 AM UTC
  schedule:
    - cron: "0 2 * * 0"

  # Manual trigger via GitHub Actions UI
  workflow_dispatch:
    inputs:
      debug_enabled:
        type: boolean
        description: "Enable verbose debug output"
        required: false
        default: false

# Cancel in-progress runs for the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  performance-tests:
    name: Performance Tests (Python 3.11)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Python 3.11
        uses: actions/setup-python@v6
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run slow performance tests
        run: |
          pytest tests/performance \
            --run-slow \
            --cov=passfx \
            --cov-report=term-missing \
            --cov-report=html:htmlcov-performance \
            --cov-report=xml:coverage-performance.xml \
            -v \
            --tb=short \
            -ra
        env:
          PYTEST_DEBUG: ${{ inputs.debug_enabled && '1' || '0' }}

      - name: Performance summary
        if: always()
        run: |
          echo "# Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Categories" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Search Performance**: 1,000+ credential scale benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "- **Levenshtein Efficiency**: Fuzzy matching algorithm performance" >> $GITHUB_STEP_SUMMARY
          echo "- **Memory Usage**: Memory behavior validation under load" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Targets" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Operation | Target |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Search (1,000 credentials) | <100ms |" >> $GITHUB_STEP_SUMMARY
          echo "| Fuzzy match | <50ms |" >> $GITHUB_STEP_SUMMARY
          echo "| Memory baseline | <50MB |" >> $GITHUB_STEP_SUMMARY

      - name: Upload performance report
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: performance-coverage-report
          path: htmlcov-performance/
          retention-days: 30

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage-performance.xml
          flags: performance
          name: performance-coverage
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Create annotation for results
        if: always()
        run: |
          if [ "${{ job.status }}" == "success" ]; then
            echo "::notice title=Performance Tests::All performance tests passed. Search targets validated."
          else
            echo "::warning title=Performance Tests::Some performance tests failed. Review timing targets."
          fi
