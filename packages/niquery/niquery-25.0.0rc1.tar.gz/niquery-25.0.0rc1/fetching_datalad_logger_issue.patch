diff --git a/.github/workflows/test.yml b/.github/workflows/test.yml
index d9b26e1..0ec17e5 100644
--- a/.github/workflows/test.yml
+++ b/.github/workflows/test.yml
@@ -23,7 +23,7 @@ env:
   FORCE_COLOR: true
   TEST_DATA_HOME: /home/runner/niquery-tests/
   NIQUERY_WERRORS: 1
-  TEST_DATA_REPO: https://gin.g-node.org/nipreps-data/tests-niquery
+  TEST_DATA_REPO: https://gin.g-node.org/jhlegarreta/tests-niquery
 
 concurrency:
   group: ${{ github.workflow }}-${{ github.ref }}
diff --git a/README.rst b/README.rst
index ab09b24..caff5e0 100644
--- a/README.rst
+++ b/README.rst
@@ -5,7 +5,7 @@
    :target: https://github.com/nipreps/niquery/blob/main/LICENSE
    :alt: License
 
-.. image:: https://img.shields.io/pypi/v/niquery.svg
+.. image:: https://img.shields.io/pypi/v/niquery.svg # Cannot use this unless Nichols releases it
    :target: https://pypi.python.org/pypi/niquery/
    :alt: Latest Version
 
diff --git a/pyproject.toml b/pyproject.toml
index df137f4..6b9506a 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -23,6 +23,7 @@ dependencies = [
   "boto3",
   "botocore",
   "click",
+  "datalad",
   "nibabel",
   "pandas",
   "requests",
diff --git a/src/niquery/analysis/featuring.py b/src/niquery/analysis/featuring.py
index 3373883..8b72246 100644
--- a/src/niquery/analysis/featuring.py
+++ b/src/niquery/analysis/featuring.py
@@ -35,9 +35,9 @@ from botocore import UNSIGNED  # type: ignore
 from botocore.config import Config  # type: ignore
 from tqdm import tqdm
 
+from niquery.data.remotes import OPENNEURO_BUCKET
 from niquery.utils.attributes import DATASETID, FULLPATH, VOLS
 
-BUCKET = "openneuro.org"
 NBYTES = 512
 BYTE_RANGE = f"bytes=0-{NBYTES}"
 
@@ -63,7 +63,7 @@ def get_nii_timepoints_s3(filename):
         Number of timepoints.
     """
 
-    response = s3.get_object(Bucket=BUCKET, Key=filename, Range=BYTE_RANGE)
+    response = s3.get_object(Bucket=OPENNEURO_BUCKET, Key=filename, Range=BYTE_RANGE)
     data = response["Body"].read()
 
     with gzip.GzipFile(fileobj=io.BytesIO(data), mode="rb") as img:
diff --git a/src/niquery/cli/run.py b/src/niquery/cli/run.py
index 266c9bb..664cff7 100644
--- a/src/niquery/cli/run.py
+++ b/src/niquery/cli/run.py
@@ -48,7 +48,7 @@ from niquery.io.utils import (
     write_dataset_paths,
     write_dataset_tags,
 )
-from niquery.query.querying import (
+from niquery.query.querying import (  ## Not very happy with the naming, alternatives ??
     edges_to_dataframe,
     fetch_pages,
     get_cursors,
@@ -85,7 +85,7 @@ def cli() -> None:
 @cli.command()
 @click.argument("out_filename", type=click.Path(dir_okay=False, path_type=Path))
 @force_output
-def index(out_filename, force) -> None:
+def index(out_filename, force) -> None:  ## Stores tasks (specific to fMRI) (open issue)
     """Index existing dataset information from OpenNeuro.
 
     The 'id', 'name', 'species', 'tag', 'dataset_doi', 'modalities', and 'tasks'
@@ -174,27 +174,34 @@ def collect(in_filename, out_dirname, force) -> None:
     mri_datasets_fname = Path.joinpath(out_dirname, fname)
     df.to_csv(mri_datasets_fname, sep=sep, index=False)
 
-    success_results, failed_results = query_datasets(df, max_workers=MAX_WORKERS)
+    success_results, failure_results = query_datasets(df, max_workers=MAX_WORKERS)
 
     end = time.time()
     duration = end - start
 
-    result_count = len(success_results) + len(failed_results)
-    logging.info(f"Collected {result_count} datasets in {duration:.2f} seconds.")
-    logging.info(f"{len(success_results)} queries succeeded.")
-    logging.info(f"{len(failed_results)} queries failed.")
+    # Compute success/failure ratios
+    success_ds = len(success_results)
+    failure_ds = len(failure_results)
+    ds_count = success_ds + failure_ds
+
+    success_ds_ratio = success_ds / ds_count * 100
+    failure_ds_ratio = failure_ds / ds_count * 100
+
+    logging.info(f"Collected {ds_count} datasets in {duration:.2f} seconds.")
+    logging.info(f"{len(success_results)} queries succeeded ({success_ds_ratio:.2f}%).")
+    logging.info(f"{len(failure_results)} queries failed ({failure_ds_ratio:.2f}%).")
 
     # Serialize
     write_dataset_file_lists(success_results, out_dirname, sep)
     failed_datasets_info_fname = Path.joinpath(out_dirname, "failed_dataset_tag_queries.tsv")
-    write_dataset_tags(failed_results, failed_datasets_info_fname, sep)
+    write_dataset_tags(failure_results, failed_datasets_info_fname, sep)
 
 
 @cli.command()
 @click.argument("in_dirname", type=click.Path(exists=True, file_okay=False, path_type=Path))
 @click.argument("out_dirname", type=click.Path(exists=True, file_okay=False, path_type=Path))
 @force_output
-def analyze(in_dirname, out_dirname, force) -> None:
+def analyze(in_dirname, out_dirname, force) -> None:    ## Generalize name or approach to allow other modalities (open issue)
     """Analyze BOLD runs in datasets to extract relevant features.
 
     Analyzes the BOLD data files contained in the records of each dataset in the
@@ -228,7 +235,7 @@ def analyze(in_dirname, out_dirname, force) -> None:
 
     logging.info(f"Found {sum(len(item) for item in bold_files.values())} BOLD runs.")
 
-    success_results, failed_results = extract_bold_features(bold_files)
+    success_results, failure_results = extract_bold_features(bold_files)
 
     end = time.time()
     duration = end - start
@@ -238,11 +245,11 @@ def analyze(in_dirname, out_dirname, force) -> None:
         f"BOLD runs in {duration:.2f} seconds."
     )
     logging.info(f"{sum(len(v) for v in success_results.values())} analyses succeeded.")
-    logging.info(f"{len(failed_results)} analyses failed.")
+    logging.info(f"{len(failure_results)} analyses failed.")
 
     write_dataset_file_lists(success_results, out_dirname, sep)
     failed_files = Path(out_dirname, "failed_dataset_tag_queries.tsv")
-    write_dataset_paths(failed_results, failed_files, sep)
+    write_dataset_paths(failure_results, failed_files, sep)
 
 
 @cli.command()
@@ -382,17 +389,26 @@ def aggregate(in_filename, out_dirname, name, force) -> None:
 
     success_results, failure_results = fetch_datalad_remote_files(df, out_dirname, name)
 
-    success_files = sum(len(v) for v in success_results.values())
-    failure_files = sum(len(v) for v in failure_results.values())
+    # Compute success/failure ratios
     success_ds = len(success_results)
     failure_ds = len(failure_results)
-    all_datasets = success_ds + failure_ds
-    all_files = success_files + failure_files
+    ds_count = success_ds + failure_ds
+
+    success_files = sum(len(v) for v in success_results.values())
+    failure_files = sum(len(v) for v in failure_results.values())
+    file_count = success_files + failure_files
+
+    success_ds_ratio = success_ds / ds_count * 100
+    failure_ds_ratio = failure_ds / ds_count * 100
+
+    success_files_ratio = success_files / file_count * 100
+    failure_files_ratio = failure_files / file_count * 100
+
     logging.info(
-        f"Failures reported for {failure_files}/{all_files} files "
-        f"from {failure_ds}/{all_datasets} datasets"
+        f"Failures reported for {failure_files}/{file_count} ({failure_files_ratio:.2f}%) files "
+        f"from {failure_ds}/{ds_count} datasets ({failure_ds_ratio:.2f}%)."
     )
-    logging.info(f"Aggregated {success_files} files from {success_ds} datasets into {out_dirname}")
+    logging.info(f"Aggregated {success_files} ({success_files_ratio:.2f}%) files from {success_ds} ({success_ds_ratio:.2f}%) datasets into {out_dirname}.")
 
 
 if __name__ == "__main__":
diff --git a/src/niquery/data/fetching.py b/src/niquery/data/fetching.py
index 313dd46..e4d44fa 100644
--- a/src/niquery/data/fetching.py
+++ b/src/niquery/data/fetching.py
@@ -21,8 +21,10 @@
 #     https://www.nipreps.org/community/licensing/
 #
 
-import subprocess
+from datalad.api import Dataset
+from datalad.support.exceptions import IncompleteResultsError
 
+from niquery.data.remotes import OPENNEURO_DS_TEMPLATE
 from niquery.utils.attributes import DATASETID, FULLPATH
 
 
@@ -62,31 +64,41 @@ def fetch_datalad_remote_files(df, out_dirname, dataset_name) -> tuple:
 
     # Create new datalad dataset
     aggr_ds_path = out_dirname / dataset_name
-    subprocess.run(["datalad", "create", "-c", "text2git", str(aggr_ds_path)], check=True)
+    aggr_ds_path.mkdir(parents=True, exist_ok=True)
+    if not (aggr_ds_path / ".datalad").exists():
+        aggr_ds = Dataset(str(aggr_ds_path))
+        aggr_ds.create(cfg_proc="text2git")
+    else:
+        aggr_ds = Dataset(str(aggr_ds_path))
 
     success_results: dict[str, list[str]] = {}
     failure_results: dict[str, list[str]] = {}
 
     # Loop over datasets
     for dataset_id, file_list in grouped:
-        ds_url = f"https://github.com/OpenNeuroDatasets/{dataset_id}.git"
+        # ToDo
+        # Eventually make this a parameter of the function
+        ds_url = OPENNEURO_DS_TEMPLATE.format(DATASET_ID=dataset_id)
         ds_path = aggr_ds_path / str(dataset_id)
         if not ds_path.exists():
-            subprocess.run(["datalad", "clone", ds_url, str(ds_path)], check=True)
+            ds = aggr_ds.clone(source=ds_url, path=str(ds_path))
         else:
             # If already cloned, ensure it's a datalad dataset
+            ds = Dataset(str(ds_path))
             assert (ds_path / ".datalad").exists()
 
         # Now, get each relevant file in this dataset
         for _, file in file_list.iterrows():
             fullpath = str(file[FULLPATH])
-            result = subprocess.run(["datalad", "get", fullpath], cwd=ds_path, check=True)
-
-            if result.returncode == 0:
+            try:
+                bat = ds.get(fullpath)
                 success_results.setdefault(dataset_id, []).append(fullpath)
-            else:
+            except (RuntimeError, IncompleteResultsError) as _:
                 failure_results.setdefault(dataset_id, []).append(fullpath)
 
-        subprocess.run(["datalad", "save", "-d", str(aggr_ds_path), str(ds_path)], check=True)
+        aggr_ds.save(path=str(ds_path))
 
+    # TODO
+    # Log the datalad output
+    # stdout = logfile, stderr = logfile
     return success_results, failure_results
diff --git a/src/niquery/query/querying.py b/src/niquery/query/querying.py
index 682c792..44d4490 100644
--- a/src/niquery/query/querying.py
+++ b/src/niquery/query/querying.py
@@ -29,6 +29,7 @@ import pandas as pd
 import requests
 from tqdm import tqdm
 
+from niquery.data.remotes import OPENNEURO_GRAPHQL_URL
 from niquery.utils.attributes import (
     DATASET_DOI,
     DATASETID,
@@ -43,7 +44,6 @@ from niquery.utils.attributes import (
     TASKS,
 )
 
-OPENNEURO_GRAPHQL_URL = "https://openneuro.org/crn/graphql"
 HEADERS = {"Content-Type": "application/json"}
 
 MAX_QUERY_SIZE = 100
diff --git a/test/test_main.py b/test/test_main.py
index 48de303..813ddd6 100644
--- a/test/test_main.py
+++ b/test/test_main.py
@@ -28,6 +28,7 @@ from pathlib import Path
 
 import numpy as np
 import pandas as pd
+import pytest
 from click.testing import CliRunner
 
 from niquery.__main__ import cli
@@ -38,6 +39,8 @@ from niquery.utils.attributes import DATASETID
 entry_points = importlib.metadata.entry_points(group="console_scripts")
 cli_name = [ep.name for ep in entry_points if ep.value.startswith("niquery.cli.run:cli")][0]
 
+os.environ['TEST_OUTPUT_DIR'] = "/mnt/data/nipreps/nifreeze/tests/niquery/"
+os.environ['TEST_DATA_HOME'] = "/mnt/data/nipreps/nifreeze/tests/niquery/"
 
 def test_main_help():
     runner = CliRunner()
@@ -57,6 +60,7 @@ def test_index_help():
 def test_index_run(tmp_path):
     cmd_str = "index"
     runner = CliRunner()
+    out_fname = Path(os.getenv("TEST_OUTPUT_DIR")) / "openneuro_datasets.tsv"
     out_fname = tmp_path / "openneuro_datasets.tsv"
     result = runner.invoke(cli, [cmd_str, str(out_fname)], prog_name=cli_name)
     assert result.exit_code == 0
@@ -77,6 +81,9 @@ def test_collect_run(tmp_path):
     cmd_str = "collect"
     runner = CliRunner()
     in_fname = Path(os.getenv("TEST_DATA_HOME")) / "openneuro_datasets_sample.tsv"
+    out_dirname = (
+        Path(os.getenv("TEST_OUTPUT_DIR")) / "dataset_files"
+    )  ## Change these to use tmp_path
     out_dirname = tmp_path / "dataset_files"
     os.makedirs(out_dirname, exist_ok=False)
     result = runner.invoke(cli, [cmd_str, str(in_fname), str(out_dirname)], prog_name=cli_name)
@@ -111,6 +118,7 @@ def test_analyze_run(tmp_path):
     cmd_str = "analyze"
     runner = CliRunner()
     in_dirname = Path(os.getenv("TEST_DATA_HOME")) / "dataset_files"
+    out_dirname = Path(os.getenv("TEST_OUTPUT_DIR")) / "dataset_features"
     out_dirname = tmp_path / "dataset_features"
     os.makedirs(out_dirname, exist_ok=False)
     result = runner.invoke(cli, [cmd_str, str(in_dirname), str(out_dirname)], prog_name=cli_name)
@@ -143,6 +151,7 @@ def test_select_run(tmp_path):
     cmd_str = "select"
     runner = CliRunner()
     in_dirname = Path(os.getenv("TEST_DATA_HOME")) / "dataset_features"
+    out_fname = Path(os.getenv("TEST_OUTPUT_DIR")) / "selected_openneuro_datasets.tsv"
     out_fname = tmp_path / "selected_openneuro_datasets.tsv"
     seed = 1234
     total_runs = 30
@@ -181,3 +190,31 @@ def test_aggregate_help():
     assert result.output.startswith(
         f"Usage: {cli_name} {cmd_str} [OPTIONS] IN_FILENAME OUT_DIRNAME"
     )
+
+
+def test_aggregate_run(tmp_path):
+    in_filename = Path(os.getenv("TEST_DATA_HOME")) / "selected_openneuro_datasets_subset.tsv"
+    out_dirname = tmp_path / "aggregate_dataset"
+    os.makedirs(out_dirname, exist_ok=False)
+    dataset_name = "ds000001"
+
+    cmd_str = "aggregate"
+    runner = CliRunner()
+    result = runner.invoke(
+        cli,
+        [
+            cmd_str,
+            str(in_filename),
+            str(out_dirname),
+            dataset_name,
+        ]
+    )
+    # The command should finish without error
+    assert result.exit_code == 0
+    # Output should mention aggregation (success/failure), but exact text may vary with real fetch
+    assert "Aggregated" in result.output
+
+
+if __name__ == "__main__":
+    tmp_path = Path("/mnt/data/nipreps/aggregate_out/")
+    test_aggregate_run(tmp_path)
\ No newline at end of file
