{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TransformerKit Demo\n",
                "\n",
                "This notebook demonstrates the key features of TransformerKit, including:\n",
                "- Basic model creation and usage\n",
                "- Training on a simple task\n",
                "- Attention weight visualization\n",
                "- Model architecture exploration"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Installation\n",
                "\n",
                "First, ensure TransformerKit is installed:\n",
                "\n",
                "```bash\n",
                "pip install transformerkit\n",
                "```\n",
                "\n",
                "Or for development:\n",
                "\n",
                "```bash\n",
                "pip install -e .\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from transformerkit import (\n",
                "    create_transformer,\n",
                "    TransformerConfig,\n",
                "    count_parameters,\n",
                "    create_padding_mask,\n",
                "    create_target_mask,\n",
                "    greedy_decode,\n",
                ")\n",
                "from transformerkit.visualization import (\n",
                "    plot_attention_heatmap,\n",
                "    plot_multihead_attention,\n",
                ")\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "# Device selection\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device('cuda')\n",
                "    print(\"Using CUDA (NVIDIA GPU)\")\n",
                "elif torch.backends.mps.is_available():\n",
                "    device = torch.device('mps')\n",
                "    print(\"Using MPS (Apple Silicon GPU)\")\n",
                "else:\n",
                "    device = torch.device('cpu')\n",
                "    print(\"Using CPU\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Basic Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a small model for demonstration\n",
                "config = TransformerConfig(\n",
                "    d_model=128,\n",
                "    n_heads=4,\n",
                "    n_layers=2,\n",
                "    d_ff=256,\n",
                "    dropout=0.1,\n",
                "    vocab_size=1000,\n",
                "    max_seq_length=50\n",
                ")\n",
                "\n",
                "model = create_transformer(config).to(device)\n",
                "print(f\"Model created with {count_parameters(model):,} parameters\")\n",
                "print(f\"Configuration: {config.n_layers} layers, {config.n_heads} heads, d_model={config.d_model}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple forward pass\n",
                "src = torch.randint(3, 1000, (2, 10)).to(device)  # (batch_size, src_len)\n",
                "tgt = torch.randint(3, 1000, (2, 8)).to(device)   # (batch_size, tgt_len)\n",
                "\n",
                "# Forward pass\n",
                "output = model(src, tgt)\n",
                "\n",
                "print(f\"Input shapes:\")\n",
                "print(f\"  Source: {src.shape}\")\n",
                "print(f\"  Target: {tgt.shape}\")\n",
                "print(f\"\\nOutput shape: {output.shape}\")\n",
                "print(f\"  Expected: (batch_size={src.shape[0]}, seq_len={tgt.shape[1]}, vocab_size={config.vocab_size})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Demo\n",
                "\n",
                "Let's train a small model on a copy task to demonstrate the training loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "class SimpleCopyDataset(Dataset):\n",
                "    \"\"\"Simple dataset for copy task.\"\"\"\n",
                "    \n",
                "    def __init__(self, num_samples=1000, seq_len=8, vocab_size=100):\n",
                "        self.data = np.random.randint(3, vocab_size, size=(num_samples, seq_len))\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.data)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        seq = self.data[idx]\n",
                "        src = torch.tensor(seq, dtype=torch.long)\n",
                "        tgt_input = torch.cat([torch.tensor([1]), torch.tensor(seq, dtype=torch.long)])\n",
                "        tgt_output = torch.cat([torch.tensor(seq, dtype=torch.long), torch.tensor([2])])\n",
                "        return src, tgt_input, tgt_output\n",
                "\n",
                "# Create dataset\n",
                "train_dataset = SimpleCopyDataset(num_samples=500, seq_len=8, vocab_size=100)\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
                "\n",
                "print(f\"Created training dataset with {len(train_dataset)} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training loop\n",
                "model.train()\n",
                "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "num_epochs = 5\n",
                "losses = []\n",
                "\n",
                "print(f\"Training for {num_epochs} epochs...\\n\")\n",
                "\n",
                "for epoch in range(num_epochs):\n",
                "    epoch_loss = 0\n",
                "    \n",
                "    for batch_idx, (src, tgt_input, tgt_output) in enumerate(train_loader):\n",
                "        src = src.to(device)\n",
                "        tgt_input = tgt_input.to(device)\n",
                "        tgt_output = tgt_output.to(device)\n",
                "        \n",
                "        # Create masks\n",
                "        src_mask = create_padding_mask(src, pad_idx=0)\n",
                "        tgt_mask = create_target_mask(tgt_input, pad_idx=0)\n",
                "        \n",
                "        # Forward pass\n",
                "        output = model(src, tgt_input, src_mask, tgt_mask)\n",
                "        \n",
                "        # Calculate loss\n",
                "        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n",
                "        \n",
                "        # Backward pass\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "        optimizer.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    avg_loss = epoch_loss / len(train_loader)\n",
                "    losses.append(avg_loss)\n",
                "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
                "\n",
                "print(\"\\nTraining complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training loss\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(range(1, num_epochs + 1), losses, marker='o', linewidth=2, markersize=8)\n",
                "plt.xlabel('Epoch', fontsize=12)\n",
                "plt.ylabel('Loss', fontsize=12)\n",
                "plt.title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Attention Visualization\n",
                "\n",
                "Now let's visualize attention weights to understand what the model is learning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get a sample for visualization\n",
                "model.eval()\n",
                "sample_src, sample_tgt_input, sample_tgt_output = train_dataset[0]\n",
                "sample_src = sample_src.unsqueeze(0).to(device)\n",
                "sample_tgt_input = sample_tgt_input.unsqueeze(0).to(device)\n",
                "\n",
                "print(f\"Sample source sequence: {sample_src.squeeze().cpu().numpy()}\")\n",
                "print(f\"Sample target sequence: {sample_tgt_output.cpu().numpy()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create synthetic attention weights for demonstration\n",
                "# In a real scenario, you'd extract these from the model during forward pass\n",
                "tgt_len = sample_tgt_input.shape[1]\n",
                "src_len = sample_src.shape[1]\n",
                "n_heads = config.n_heads\n",
                "\n",
                "# Simulate attention pattern (diagonal for copy task)\n",
                "attention_weights = torch.zeros(tgt_len, src_len)\n",
                "for i in range(min(tgt_len, src_len)):\n",
                "    attention_weights[i, i] = 0.8\n",
                "    if i > 0:\n",
                "        attention_weights[i, i-1] = 0.15\n",
                "    if i < src_len - 1:\n",
                "        attention_weights[i, i+1] = 0.05\n",
                "\n",
                "# Normalize\n",
                "attention_weights = attention_weights / attention_weights.sum(dim=1, keepdim=True)\n",
                "\n",
                "print(f\"Attention weights shape: {attention_weights.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot single attention heatmap\n",
                "fig, ax = plot_attention_heatmap(\n",
                "    attention_weights,\n",
                "    title=\"Self-Attention Pattern (Copy Task)\",\n",
                "    figsize=(8, 6)\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate multi-head attention\n",
                "multihead_attention = torch.stack([\n",
                "    attention_weights + torch.randn(tgt_len, src_len) * 0.1\n",
                "    for _ in range(n_heads)\n",
                "])\n",
                "# Ensure valid probabilities\n",
                "multihead_attention = torch.clamp(multihead_attention, min=0)\n",
                "multihead_attention = multihead_attention / multihead_attention.sum(dim=2, keepdim=True)\n",
                "\n",
                "fig = plot_multihead_attention(\n",
                "    multihead_attention,\n",
                "    n_heads=n_heads,\n",
                "    layer_idx=0,\n",
                "    figsize=(15, 8)\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Architecture Overview"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"Transformer Architecture Overview\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nConfiguration:\")\n",
                "print(f\"  Model dimension (d_model): {config.d_model}\")\n",
                "print(f\"  Number of attention heads: {config.n_heads}\")\n",
                "print(f\"  Dimension per head: {config.d_model // config.n_heads}\")\n",
                "print(f\"  Number of layers: {config.n_layers}\")\n",
                "print(f\"  Feed-forward dimension: {config.d_ff}\")\n",
                "print(f\"  Dropout rate: {config.dropout}\")\n",
                "print(f\"  Vocabulary size: {config.vocab_size}\")\n",
                "print(f\"  Maximum sequence length: {config.max_seq_length}\")\n",
                "\n",
                "print(f\"\\nTotal parameters: {count_parameters(model):,}\")\n",
                "\n",
                "print(f\"\\nModel Structure:\")\n",
                "print(f\"  Encoder:\")\n",
                "print(f\"    - Token Embedding\")\n",
                "print(f\"    - Positional Encoding\")\n",
                "print(f\"    - {config.n_layers}x Encoder Layers:\")\n",
                "print(f\"        - Multi-Head Self-Attention ({config.n_heads} heads)\")\n",
                "print(f\"        - Add & Norm\")\n",
                "print(f\"        - Feed-Forward Network (d_ff={config.d_ff})\")\n",
                "print(f\"        - Add & Norm\")\n",
                "print(f\"\\n  Decoder:\")\n",
                "print(f\"    - Token Embedding\")\n",
                "print(f\"    - Positional Encoding\")\n",
                "print(f\"    - {config.n_layers}x Decoder Layers:\")\n",
                "print(f\"        - Masked Multi-Head Self-Attention ({config.n_heads} heads)\")\n",
                "print(f\"        - Add & Norm\")\n",
                "print(f\"        - Multi-Head Cross-Attention ({config.n_heads} heads)\")\n",
                "print(f\"        - Add & Norm\")\n",
                "print(f\"        - Feed-Forward Network (d_ff={config.d_ff})\")\n",
                "print(f\"        - Add & Norm\")\n",
                "print(f\"\\n  Output:\")\n",
                "print(f\"    - Linear projection to vocabulary (d_model → vocab_size)\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Sequence Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test sequence generation with greedy decoding\n",
                "test_src = torch.tensor([[5, 10, 15, 20, 25, 30]]).to(device)\n",
                "src_mask = create_padding_mask(test_src, pad_idx=0)\n",
                "\n",
                "generated = greedy_decode(\n",
                "    model,\n",
                "    test_src,\n",
                "    src_mask,\n",
                "    max_len=10,\n",
                "    start_idx=1,\n",
                "    end_idx=2\n",
                ")\n",
                "\n",
                "print(f\"Source sequence: {test_src.squeeze().cpu().numpy()}\")\n",
                "print(f\"Generated sequence: {generated[0].cpu().numpy()}\")\n",
                "print(f\"Length: {len(generated[0])}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "This notebook demonstrated:\n",
                "- ✅ Creating and configuring a Transformer model\n",
                "- ✅ Training on a simple copy task\n",
                "- ✅ Visualizing attention weights\n",
                "- ✅ Understanding the model architecture\n",
                "- ✅ Generating sequences with the trained model\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "- Try different model configurations\n",
                "- Train on real-world tasks (translation, text generation)\n",
                "- Experiment with different decoding strategies (beam search)\n",
                "- Analyze attention patterns for different tasks\n",
                "\n",
                "For more information, visit: https://github.com/charansoma3001/transformerkit"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}