Metadata-Version: 2.4
Name: beanllm
Version: 0.1.0
Summary: Unified toolkit for managing and using multiple LLM providers with automatic model detection
Author-email: leebeanbin <wjdqlsdu388@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/leebeanbin/beanllm
Project-URL: Documentation, https://github.com/leebeanbin/beanllm#readme
Project-URL: Repository, https://github.com/leebeanbin/beanllm
Project-URL: Bug Tracker, https://github.com/leebeanbin/beanllm/issues
Keywords: llm,llmkit,kit,openai,claude,gemini,ollama,ai,model-manager,rag,langchain,embedding,vector-store,chatbot,gpt
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: httpx>=0.24.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: rich>=13.0.0
Requires-Dist: beautifulsoup4>=4.12.0
Requires-Dist: requests>=2.31.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: tiktoken>=0.5.0
Requires-Dist: pytest<10.0.0,>=9.0.2
Provides-Extra: openai
Requires-Dist: openai>=1.0.0; extra == "openai"
Provides-Extra: anthropic
Requires-Dist: anthropic>=0.18.0; extra == "anthropic"
Provides-Extra: gemini
Requires-Dist: google-generativeai>=0.3.0; extra == "gemini"
Provides-Extra: ollama
Requires-Dist: ollama>=0.1.0; extra == "ollama"
Provides-Extra: audio
Requires-Dist: openai-whisper>=20231117; extra == "audio"
Provides-Extra: all
Requires-Dist: openai>=1.0.0; extra == "all"
Requires-Dist: anthropic>=0.18.0; extra == "all"
Requires-Dist: google-generativeai>=0.3.0; extra == "all"
Requires-Dist: ollama>=0.1.0; extra == "all"
Requires-Dist: openai-whisper>=20231117; extra == "all"
Provides-Extra: evaluation
Requires-Dist: apscheduler>=3.10.0; extra == "evaluation"
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Dynamic: license-file

# ğŸš€ beanllm

**Production-ready LLM toolkit with Clean Architecture and unified interface for multiple providers**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub](https://img.shields.io/github/stars/leebeanbin/beanllm?style=social)](https://github.com/leebeanbin/beanllm)

**beanllm** is a comprehensive, production-ready toolkit for building LLM applications with a unified interface across OpenAI, Anthropic, Google, and Ollama. Built with **Clean Architecture** and **SOLID principles** for maintainability and scalability.

---

## âœ¨ Key Features

### ğŸ¯ **Core Features**
- ğŸ”„ **Unified Interface** - Single API for OpenAI, Anthropic, Google, Ollama
- ğŸ›ï¸ **Intelligent Adaptation** - Automatic parameter conversion between providers
- ğŸ“Š **Model Registry** - Auto-detect available models from API keys
- ğŸ” **CLI Tools** - Inspect models and capabilities from command line
- ğŸ’° **Cost Tracking** - Accurate token counting and cost estimation
- ğŸ—ï¸ **Clean Architecture** - Layered architecture with clear separation of concerns

### ğŸ—ï¸ **RAG & Document Processing**
- ğŸ“„ **Document Loaders** - PDF, CSV, TXT with automatic format detection
- âœ‚ï¸ **Smart Text Splitters** - Semantic chunking with tiktoken
- ğŸ” **Vector Search** - Chroma, FAISS, Pinecone, Qdrant, Weaviate
- ğŸ¯ **RAG Pipeline** - Complete question-answering system in one line
- ğŸ› **RAG Debugging** - Comprehensive debugging toolkit

### ğŸ¤– **Advanced LLM Features**
- ğŸ› ï¸ **Tools & Agents** - Function calling with ReAct pattern
- ğŸ§  **Memory Systems** - Buffer, window, token-based, summary memory
- â›“ï¸ **Chains** - Sequential, parallel, and custom chain composition
- ğŸ“Š **Output Parsers** - Pydantic, JSON, datetime, enum parsing
- ğŸ” **Streaming** - Real-time response streaming with stats

### ğŸ“ˆ **Graph & Multi-Agent**
- ğŸ•¸ï¸ **Graph Workflows** - LangGraph-style DAG execution
- ğŸ¤ **Multi-Agent** - Sequential, parallel, hierarchical, debate patterns
- ğŸ”„ **State Management** - Automatic state threading and checkpoints
- ğŸ“ **Communication** - Inter-agent message passing

### ğŸ¨ **Multimodal AI**
- ğŸ–¼ï¸ **Vision RAG** - Image-based question answering with CLIP
- ğŸ™ï¸ **Audio Processing** - Whisper STT, multi-provider TTS
- ğŸ”Š **Audio RAG** - Search and QA across audio files
- ğŸŒ **Web Search** - Google, Bing, DuckDuckGo integration
- ğŸ§® **ML Integration** - TensorFlow, PyTorch, Scikit-learn

### ğŸ­ **Production Features**
- ğŸ’µ **Token & Cost** - tiktoken-based accurate counting, cost optimization
- ğŸ“ **Prompt Templates** - Few-shot, chat, chain-of-thought templates
- ğŸ“Š **Evaluation** - BLEU, ROUGE, LLM-as-Judge, RAG metrics, Context Recall
- ğŸ‘¤ **Human-in-the-Loop** - í”¼ë“œë°± ìˆ˜ì§‘ ë° í•˜ì´ë¸Œë¦¬ë“œ í‰ê°€
- ğŸ”„ **Continuous Evaluation** - ì •ê¸° í‰ê°€ ë° ì¶”ì 
- ğŸ“‰ **Drift Detection** - ëª¨ë¸ ë“œë¦¬í”„íŠ¸ ê°ì§€
- ğŸ“ˆ **Evaluation Dashboard** - í‰ê°€ ê²°ê³¼ ì‹œê°í™”
- ğŸ“‹ **Rubric-Driven Grading** - êµ¬ì¡°í™”ëœ ë£¨ë¸Œë¦­ ê¸°ë°˜ í‰ê°€
- âœ… **CheckEval** - ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ Boolean í‰ê°€
- ğŸ“Š **Evaluation Analytics** - íŠ¸ë Œë“œ ë° ìƒê´€ê´€ê³„ ë¶„ì„
- ğŸ¯ **Fine-tuning** - OpenAI fine-tuning API integration
- ğŸ›¡ï¸ **Error Handling** - Retry, circuit breaker, rate limiting
- ğŸ“ˆ **Tracing** - Distributed tracing with OpenTelemetry export

---

## ğŸ—ï¸ Architecture

beanllmì€ **Clean Architecture**ì™€ **SOLID ì›ì¹™**ì„ ë”°ë¥´ëŠ” ê³„ì¸µí˜• ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ë ˆì´ì–´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Facade Layer                          â”‚
â”‚  (ì‚¬ìš©ì ì¹œí™”ì  API) - Client, RAGChain, Agent ë“±       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Handler Layer                          â”‚
â”‚  (Controller ì—­í• ) - ì…ë ¥ ê²€ì¦, ì—ëŸ¬ ì²˜ë¦¬                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Service Layer                          â”‚
â”‚  (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§) - ì¸í„°í˜ì´ìŠ¤ + êµ¬í˜„ì²´                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Domain Layer                           â”‚
â”‚  (í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤) - ì—”í‹°í‹°, ì¸í„°í˜ì´ìŠ¤, ê·œì¹™              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Infrastructure Layer                       â”‚
â”‚  (ì™¸ë¶€ ì‹œìŠ¤í…œ) - Provider, Vector Store êµ¬í˜„              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
src/beanllm/
â”œâ”€â”€ facade/          # ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤ (Facade íŒ¨í„´)
â”œâ”€â”€ handler/         # ìš”ì²­ ì²˜ë¦¬ (Controller ì—­í• )
â”œâ”€â”€ service/         # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (Service ì¸í„°í˜ì´ìŠ¤ + êµ¬í˜„ì²´)
â”œâ”€â”€ domain/          # ë„ë©”ì¸ ëª¨ë¸ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™
â”œâ”€â”€ infrastructure/ # ì™¸ë¶€ ì‹œìŠ¤í…œ ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ dto/             # ë°ì´í„° ì „ì†¡ ê°ì²´
â”œâ”€â”€ decorators/      # ê³µí†µ ë°ì½”ë ˆì´í„°
â””â”€â”€ utils/           # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
```

### SOLID ì›ì¹™ ì ìš©

- **SRP**: ê° ë ˆì´ì–´ê°€ ë‹¨ì¼ ì±…ì„ë§Œ ë‹´ë‹¹
- **OCP**: ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ í™•ì¥ ê°€ëŠ¥
- **LSP**: ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ì²´ëŠ” ì–¸ì œë“  êµì²´ ê°€ëŠ¥
- **ISP**: ì‘ì€, íŠ¹í™”ëœ ì¸í„°í˜ì´ìŠ¤
- **DIP**: ì¸í„°í˜ì´ìŠ¤ì— ì˜ì¡´, êµ¬í˜„ì²´ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ

ìì„¸í•œ ì•„í‚¤í…ì²˜ ì„¤ëª…ì€ [ARCHITECTURE.md](ARCHITECTURE.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

---

## ğŸ“¦ Installation

### Poetry ì‚¬ìš© (ê¶Œì¥)

```bash
# í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/yourusername/beanllm.git
cd beanllm

# ì˜ì¡´ì„± ì„¤ì¹˜
poetry install --extras all  # ëª¨ë“  Provider í¬í•¨
# ë˜ëŠ”
poetry install --extras openai  # OpenAIë§Œ

# ê°€ìƒ í™˜ê²½ í™œì„±í™”
poetry shell
```

### pip ì‚¬ìš©

```bash
# ê¸°ë³¸ ì„¤ì¹˜ (ì˜ì¡´ì„± ì—†ìŒ)
pip install beanllm

# íŠ¹ì • Provider ì¶”ê°€
pip install beanllm[openai]
pip install beanllm[anthropic]
pip install beanllm[gemini]
pip install beanllm[ollama]

# ëª¨ë“  Provider
pip install beanllm[all]

# ê°œë°œ ë„êµ¬ í¬í•¨
pip install beanllm[dev,all]
```

> **ì°¸ê³ **: ProviderëŠ” ì„ íƒì  ì˜ì¡´ì„±ì…ë‹ˆë‹¤. í•„ìš”í•œ Providerë§Œ ì„¤ì¹˜í•˜ë©´ ë©ë‹ˆë‹¤.

---

## ğŸš€ Quick Start

### Environment Setup

`.env` íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìƒì„±í•˜ì„¸ìš”:

```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << EOF
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GEMINI_API_KEY=...
OLLAMA_HOST=http://localhost:11434
EOF
```

### Basic Usage

```python
import asyncio
from beanllm import Client

async def main():
    # Unified interface - works with any provider
    client = Client(model="gpt-4o")
    response = await client.chat(
        messages=[{"role": "user", "content": "Explain quantum computing in simple terms"}]
    )
    print(response.content)
    
    # Switch providers seamlessly
    client = Client(model="claude-3-5-sonnet-20241022")
    response = await client.chat(
        messages=[{"role": "user", "content": "Same question, different provider"}]
    )
    
    # Streaming
    async for chunk in client.stream_chat(
        messages=[{"role": "user", "content": "Tell me a story"}]
    ):
        print(chunk, end="", flush=True)

asyncio.run(main())
```

### RAG in One Line

```python
import asyncio
from beanllm import RAGChain

async def main():
    # Create RAG system from documents
    rag = RAGChain.from_documents("docs/")
    
    # Ask questions
    answer = await rag.query("What is this document about?")
    print(answer)
    
    # With sources
    result = await rag.query("Explain the main concept", include_sources=True)
    print(result.answer)
    for source in result.sources:
        print(f"Source: {source.metadata.get('source', 'unknown')}")
    
    # Streaming query
    async for chunk in rag.stream_query("ì§ˆë¬¸"):
        print(chunk, end="", flush=True)

asyncio.run(main())
```

### Tools & Agents

```python
import asyncio
from beanllm import Agent, Tool

async def main():
    # Define tools
    @Tool.from_function
    def calculator(expression: str) -> str:
        """Evaluate a math expression"""
        return str(eval(expression))

    # Create agent
    agent = Agent(
        model="gpt-4o-mini",
        tools=[calculator],
        max_iterations=10
    )
    
    # Run agent
    result = await agent.run("What is 25 * 17?")
    print(result.answer)
    print(f"Steps: {result.total_steps}")

asyncio.run(main())
```

### Graph Workflows

```python
import asyncio
from beanllm import StateGraph, Client

async def main():
    client = Client(model="gpt-4o-mini")
    
    # Create graph
    graph = StateGraph()
    
    async def analyze(state):
        response = await client.chat(
            messages=[{"role": "user", "content": f"Analyze: {state['input']}"}]
        )
        state["analysis"] = response.content
        return state
    
    def decide(state):
        score = float(state["analysis"].split("Score:")[1]) if "Score:" in state["analysis"] else 0.5
        return "good" if score > 0.8 else "bad"
    
    # Build graph
    graph.add_node("analyze", analyze)
    graph.add_conditional_edges("analyze", decide, {
        "good": "END",
        "bad": "improve"
    })
    
    # Run
    result = await graph.invoke({"input": "Draft text"})
    print(result)

asyncio.run(main())
```

---

## ğŸ“– Examples

ë” ë§ì€ ì‚¬ìš© ì˜ˆì œëŠ” [examples/](examples/) ë””ë ‰í† ë¦¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”:

- `basic_usage.py` - ê¸°ë³¸ ì‚¬ìš©ë²•
- `rag_demo.py` - RAG íŒŒì´í”„ë¼ì¸ ì˜ˆì œ
- `rag_chain_demo.py` - RAG Chain ì˜ˆì œ
- `state_graph_demo.py` - Graph Workflow ì˜ˆì œ
- `embeddings_demo.py` - ì„ë² ë”© ì˜ˆì œ
- `vector_stores_demo.py` - Vector Store ì˜ˆì œ

---

## ğŸ“š Core Modules

### 1. Client & Adapters

Unified interface with automatic parameter adaptation:

```python
from beanllm import Client

# Works across all providers
client = Client(model="gpt-4o")

# Parameters automatically adapted
response = await client.chat(
    messages=[{"role": "user", "content": "Hello"}],
    temperature=0.7,
    max_tokens=1000,  # â†’ max_completion_tokens for GPT-5
                       # â†’ max_output_tokens for Gemini
                       # â†’ num_predict for Ollama
)
```

### 2. Document Processing

```python
from beanllm import DocumentLoader, RecursiveCharacterTextSplitter

# Load documents
docs = DocumentLoader.load("docs/")  # PDF, CSV, TXT

# Smart splitting
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", " "]
)
chunks = splitter.split_documents(docs)
```

### 3. Embeddings & Vector Stores

```python
from beanllm import OpenAIEmbedding, ChromaVectorStore

# Create embeddings
embedding = OpenAIEmbedding(model="text-embedding-3-small")

# Vector store
store = ChromaVectorStore.from_documents(
    documents=chunks,
    embedding=embedding,
    persist_directory="./chroma_db"
)

# Search
results = store.similarity_search("query", k=5)

# MMR search (diversity)
diverse_results = store.mmr_search("query", k=5, lambda_mult=0.5)
```

### 4. Multi-Agent Systems

```python
import asyncio
from beanllm import MultiAgentCoordinator, Agent

async def main():
    # Create agents
    researcher = Agent(model="gpt-4o-mini", tools=[], max_iterations=10)
    writer = Agent(model="gpt-4o-mini", tools=[], max_iterations=10)
    
    # Coordinate
    coordinator = MultiAgentCoordinator(
        agents={"researcher": researcher, "writer": writer}
    )
    
    result = await coordinator.execute_sequential(
        task="Write an article about quantum computing",
        agent_order=["researcher", "writer"]
    )
    print(result["final_result"])

asyncio.run(main())
```

---

## ğŸ”§ CLI Usage

```bash
# List available models
beanllm list

# Show model details
beanllm show gpt-4o

# Check providers
beanllm providers

# Quick summary
beanllm summary

# Export model info
beanllm export > models.json
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# With coverage
pytest --cov=src/beanllm --cov-report=html

# Specific module
pytest tests/test_facade/ -v
```

**í˜„ì¬ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: 61% (624 tests, 593 passed)

---

## ğŸ› ï¸ Development

### Makefile ì‚¬ìš© (ê¶Œì¥)

```bash
# ê°œë°œ ë„êµ¬ ì„¤ì¹˜
make install-dev

# ë¹ ë¥¸ ìë™ ìˆ˜ì •
make quick-fix

# íƒ€ì… ì²´í¬
make type-check

# ë¦°íŠ¸ ì²´í¬
make lint

# ì „ì²´ ê²€ì‚¬ ë° ìˆ˜ì •
make all
```

### ìˆ˜ë™ ì‹¤í–‰

```bash
# Install in editable mode
pip install -e ".[dev,all]"

# Format code
ruff format src/beanllm

# Lint
ruff check src/beanllm

# Type check
mypy src/beanllm
```

---

## ğŸ—ºï¸ Roadmap

### âœ… ì™„ë£Œëœ ì£¼ìš” ê¸°ëŠ¥
- âœ… Clean Architecture & SOLID principles
- âœ… Unified multi-provider interface (OpenAI, Anthropic, Google, Ollama)
- âœ… RAG pipeline & Document Processing
- âœ… Tools & Agents (ReAct pattern)
- âœ… Graph workflows (LangGraph-style)
- âœ… Multi-agent systems
- âœ… Vision & Audio processing
- âœ… Production features (evaluation, monitoring, cost tracking)
- âœ… í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ & A/B í…ŒìŠ¤íŠ¸
- âœ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë²„í¼ë§
- âœ… í‰ê°€ ì‹œìŠ¤í…œ í™•ì¥ (Human-in-the-Loop, Continuous Evaluation, Drift Detection)
- âœ… ë‚´ë¶€ ì„±ëŠ¥ ìµœì í™” (ë³‘ë ¬ ì²˜ë¦¬, ë°°ì¹˜ ê²€ìƒ‰, íˆìŠ¤í† ë¦¬ ì••ì¶•)

### ğŸ“‹ ê³„íš ì¤‘
- â¬œ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ

---

## ğŸ“š Documentation

- **[QUICK_START.md](QUICK_START.md)** - ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- **[docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)** - PyPI ë°°í¬ ê°€ì´ë“œ
- **[docs/theory/](docs/theory/)** - ì´ë¡  ë¬¸ì„œ ë° í•™ìŠµ ìë£Œ
- **[docs/tutorials/](docs/tutorials/)** - íŠœí† ë¦¬ì–¼ ì½”ë“œ
- **[examples/](examples/)** - ì‚¬ìš© ì˜ˆì œ ì½”ë“œ

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Inspired by:
- **[LangChain](https://github.com/langchain-ai/langchain)** - LLM application framework
- **[LangGraph](https://github.com/langchain-ai/langgraph)** - Graph workflow patterns
- **[Anthropic Claude](https://www.anthropic.com/)** - Clear code philosophy

Special thanks to:
- OpenAI for GPT models and APIs
- Anthropic for Claude API
- Google for Gemini API
- Ollama team for local LLM support

---

## ğŸ“§ Contact

- **GitHub**: https://github.com/leebeanbin/beanllm
- **Issues**: https://github.com/leebeanbin/beanllm/issues
- **Discussions**: https://github.com/leebeanbin/beanllm/discussions

---

**Built with â¤ï¸ for the LLM community**

Transform your LLM applications from prototype to production with beanllm.
