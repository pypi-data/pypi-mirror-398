from typing import Literal, Optional
import zipfile
import os
from pathlib import Path
from datetime import datetime

import oss2
from oss2 import Bucket
from rich.console import Console
from rich.table import Table
from rich.progress import (
    Progress,
    TextColumn,
    BarColumn,
    TimeElapsedColumn,
    TimeRemainingColumn,
    TransferSpeedColumn,
)
from jsonargparse import auto_cli, set_parsing_settings
import srsly

set_parsing_settings(parse_optionals_as_positionals=True)

console = Console()


def get_dir_info(dir_path):
    """è·å–ç›®å½•çš„æ€»å¤§å°å’Œæ–‡ä»¶æ•°"""
    total_size = 0
    file_count = 0
    try:
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    total_size += os.path.getsize(file_path)
                    file_count += 1
                except (OSError, IOError):
                    # è·³è¿‡æ— æ³•è®¿é—®çš„æ–‡ä»¶
                    pass
    except (OSError, IOError):
        pass
    return total_size, file_count


def zip_all_files(dir, zipFile, pre_dir, progress_callback=None):
    """é€’å½’å‹ç¼©æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    å‚æ•°:
    - dir: è¦å‹ç¼©çš„æ–‡ä»¶å¤¹è·¯å¾„
    - zipFile: zipfileå¯¹è±¡
    - pre_dir: å‹ç¼©æ–‡ä»¶æ ¹ç›®å½•
    - progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œå‚æ•°ä¸º(current_size, total_size)
    """
    for f in os.listdir(dir):
        absFile = os.path.join(dir, f)  # å­æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
        pre_d = os.path.join(pre_dir, f)
        if os.path.isdir(absFile):  # åˆ¤æ–­æ˜¯æ–‡ä»¶å¤¹ï¼Œç»§ç»­æ·±åº¦è¯»å–ã€‚
            zipFile.write(absFile, pre_d)  # åœ¨zipæ–‡ä»¶ä¸­åˆ›å»ºæ–‡ä»¶å¤¹
            zip_all_files(
                absFile, zipFile, pre_dir=pre_d, progress_callback=progress_callback
            )
        else:  # åˆ¤æ–­æ˜¯æ™®é€šæ–‡ä»¶ï¼Œç›´æ¥å†™åˆ°zipæ–‡ä»¶ä¸­ã€‚
            file_size = os.path.getsize(absFile)
            zipFile.write(absFile, pre_d)
            if progress_callback:
                # ä¼ é€’å½“å‰æ–‡ä»¶å¤§å°çš„å¢é‡
                progress_callback(file_size, 0)  # ç¬¬äºŒä¸ªå‚æ•°0è¡¨ç¤ºè¿™æ˜¯å¢é‡å¤§å°


def save_auth(auth_file: Path, access_key_id: str, access_key_secret: str):
    if not auth_file.exists():
        auth_file.parent.mkdir(parents=True, exist_ok=True)
    srsly.write_json(
        auth_file,
        {"access_key_id": access_key_id, "access_key_secret": access_key_secret},
    )


def load_auth(auth_file: Path):
    if not auth_file.exists():
        access_key_id = None
        access_key_secret = None
    else:
        auth = srsly.read_json(auth_file)
        access_key_id = auth.get("access_key_id", None)
        access_key_secret = auth.get("access_key_secret", None)
    if access_key_id is None or access_key_secret is None:
        access_key_id = console.input("access_key_id: ")
        if access_key_id == "":
            raise ValueError("access_key_id cannot be empty")
        access_key_secret = console.input("access_key_secret: ")
        if access_key_secret == "":
            raise ValueError("access_key_secret cannot be empty")
        save_auth(auth_file, access_key_id, access_key_secret)
    return access_key_id, access_key_secret


class OSSStorer:
    """é˜¿é‡Œäº‘osså¯¹è±¡å­˜å‚¨"""

    def __init__(
        self,
        access_key_id: str | None = None,
        access_key_secret: str | None = None,
        cache_dir: str | Path = Path().home() / ".cache" / "d-oss",
    ):
        super().__init__()
        self.auth_file = Path(cache_dir) / "auth.json"
        access_key_id, access_key_secret = load_auth(self.auth_file)
        self.auth = oss2.Auth(access_key_id, access_key_secret)
        beijing_endpoint: str = "http://oss-cn-beijing.aliyuncs.com"
        hangzhou_endpoint: str = "http://oss-cn-hangzhou.aliyuncs.com"
        data_bucket: str = "deepset"
        model_bucket: str = "pretrained-model"
        asset_bucket: str = "deepasset"
        corpus_bucket: str = "deepcorpus"
        pipe_bucket: str = "spacy-pipeline"
        self.data_bucket = oss2.Bucket(
            self.auth, beijing_endpoint, bucket_name=data_bucket
        )
        self.model_bucket = oss2.Bucket(
            self.auth, beijing_endpoint, bucket_name=model_bucket
        )
        self.assets_bucket = oss2.Bucket(
            self.auth, beijing_endpoint, bucket_name=asset_bucket
        )
        self.corpus_bucket = oss2.Bucket(
            self.auth, hangzhou_endpoint, bucket_name=corpus_bucket
        )
        self.pipe_bucket = oss2.Bucket(
            self.auth, beijing_endpoint, bucket_name=pipe_bucket
        )

        self.buckets = {
            "data": self.data_bucket,
            "model": self.model_bucket,
            "asset": self.assets_bucket,
            "corpus": self.corpus_bucket,
            "pipeline": self.pipe_bucket,
        }

        self.cache_dir = cache_dir

    def list(
        self,
        bucket: Optional[
            Literal["data", "model", "asset", "corpus", "pipeline"]
        ] = None,
    ) -> None:
        """è·å–bucketä¸‹çš„æ‰€æœ‰æ–‡ä»¶

        Args:
            bucket: è¦åˆ—å‡ºçš„bucketåç§°ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™æ˜¾ç¤ºæ‰€æœ‰bucketçš„å†…å®¹
        """
        # éªŒè¯bucketå‚æ•°
        valid_buckets = ["data", "model", "asset", "corpus", "pipeline"]
        if bucket is not None and bucket not in valid_buckets:
            console.print(
                f"[bold red]é”™è¯¯ï¼šæ— æ•ˆçš„bucketåç§° '{bucket}'ï¼Œæœ‰æ•ˆé€‰é¡¹ï¼š{', '.join(valid_buckets)}[/bold red]"
            )
            return

        if bucket is None:
            # æ˜¾ç¤ºæ‰€æœ‰bucketçš„å†…å®¹
            bucket_names = list(self.buckets.keys())

            for bucket_name in bucket_names:
                bucket_obj = self.buckets[bucket_name]

                # è·å–bucketä¸­çš„æ–‡ä»¶åˆ—è¡¨
                objects = list(oss2.ObjectIterator(bucket_obj))
                file_count = len(objects)

                # æ˜¾ç¤ºbucketæ ‡é¢˜å’Œæ–‡ä»¶æ•°é‡
                console.print(
                    f"\n[bold cyan]ğŸ“ Bucket: {bucket_name} ({file_count} files)[/bold cyan]"
                )

                if file_count == 0:
                    console.print("  [dim](empty)[/dim]")
                    continue

                # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºæ–‡ä»¶
                table = Table(show_header=True, header_style="bold blue")
                table.add_column("File Name", style="cyan")
                table.add_column("Size", style="green", justify="right")
                table.add_column("Last Modified", style="yellow", justify="center")

                for obj in objects:
                    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                    size_mb = obj.size / 1024 / 1024 if obj.size else 0
                    size_str = (
                        f"{size_mb:.2f} MB"
                        if obj.size >= 1024 * 1024
                        else f"{obj.size or 0} B"
                    )

                    # æ ¼å¼åŒ–æ—¶é—´
                    last_modified = (
                        datetime.fromtimestamp(obj.last_modified).strftime(
                            "%Y-%m-%d %H:%M:%S"
                        )
                        if hasattr(obj, "last_modified") and obj.last_modified
                        else "Unknown"
                    )

                    table.add_row(obj.key, size_str, last_modified)

                console.print(table)

            console.print(
                f"\n[bold green]âœ… Listed contents of {len(bucket_names)} buckets[/bold green]"
            )

        else:
            # æ˜¾ç¤ºå•ä¸ªbucketçš„å†…å®¹
            bucket_obj = self.buckets.get(bucket)

            # è·å–bucketä¸­çš„æ–‡ä»¶åˆ—è¡¨
            objects = list(oss2.ObjectIterator(bucket_obj))
            file_count = len(objects)

            console.print(
                f"[bold cyan]ğŸ“ Bucket: {bucket} ({file_count} files)[/bold cyan]"
            )

            if file_count == 0:
                console.print("  [dim](empty)[/dim]")
                return

            # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºæ–‡ä»¶
            table = Table(show_header=True, header_style="bold blue")
            table.add_column("File Name", style="cyan")
            table.add_column("Size", style="green", justify="right")
            table.add_column("Last Modified", style="yellow", justify="center")

            for obj in objects:
                # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                size_mb = obj.size / 1024 / 1024 if obj.size else 0
                size_str = (
                    f"{size_mb:.2f} MB"
                    if obj.size >= 1024 * 1024
                    else f"{obj.size or 0} B"
                )

                # æ ¼å¼åŒ–æ—¶é—´
                last_modified = (
                    datetime.fromtimestamp(obj.last_modified).strftime(
                        "%Y-%m-%d %H:%M:%S"
                    )
                    if hasattr(obj, "last_modified") and obj.last_modified
                    else "Unknown"
                )

                table.add_row(obj.key, size_str, last_modified)

            console.print(table)

    def upload(
        self, file: str, bucket: Literal["data", "model", "asset", "corpus", "pipeline"]
    ):
        """ä¸Šä¼ æ–‡ä»¶æˆ–è€…ç›®å½•åˆ°bucket
        - file: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
        - bucket: è¦ä¸Šä¼ åˆ°çš„bucket
        """
        file_path: Path = Path(file)
        if not file_path.exists():
            console.print(f"[bold red] file {file} not exists!")
            return
        bucket_obj: oss2.Bucket = self.buckets.get(bucket)

        if file_path.is_dir():
            # ç›®å½•ä¸Šä¼ ï¼šå‹ç¼© + ä¸Šä¼ ä¸¤ä¸ªé˜¶æ®µ
            file_zip_path = file_path.name + ".zip"
            total_size, file_count = get_dir_info(file_path)

            with Progress(
                TextColumn("[bold blue]{task.description}", justify="left"),
                BarColumn(bar_width=30),
                TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                TextColumn("[bold green]{task.fields[size_info]}", justify="left"),
                TransferSpeedColumn(),
                TextColumn("[cyan]å·²ç”¨æ—¶:"),
                TimeElapsedColumn(),
                TextColumn("[yellow]å‰©ä½™:"),
                TimeRemainingColumn(),
            ) as progress:
                # å‹ç¼©é˜¶æ®µ
                zip_task = progress.add_task(
                    f"ğŸ“¦ compressing {file_path.name}",
                    size_info=f"0/{file_count} files â€¢ 0.0/{total_size / 1024 / 1024:.1f} MB",
                    total=total_size,
                )

                compressed_size = 0
                compressed_files = 0

                def zip_progress(size_increment, _):
                    nonlocal compressed_size, compressed_files
                    # ç´¯åŠ å·²å‹ç¼©å¤§å°
                    compressed_size += size_increment
                    compressed_files += 1

                    if total_size > 0:
                        size_mb = compressed_size / 1024 / 1024
                        total_mb = total_size / 1024 / 1024
                        progress.update(
                            zip_task,
                            completed=compressed_size,
                            total=total_size,
                            size_info=f"{compressed_files}/{file_count} files â€¢ {size_mb:.1f}/{total_mb:.1f} MB",
                        )
                    else:
                        size_mb = compressed_size / 1024 / 1024
                        progress.update(
                            zip_task,
                            completed=compressed_size,
                            total=compressed_size or 1,  # é¿å…é™¤é›¶é”™è¯¯
                            size_info=f"{compressed_files}/{file_count} files â€¢ {size_mb:.1f}/0.0 MB",
                        )

                with zipfile.ZipFile(file=file_zip_path, mode="w") as z:
                    zip_all_files(
                        file_path, z, file_path.name, progress_callback=zip_progress
                    )

                # å®Œæˆå‹ç¼©ä»»åŠ¡
                progress.update(zip_task, completed=total_size)

                # ä¸Šä¼ é˜¶æ®µ
                zip_size = os.path.getsize(file_zip_path)
                upload_task = progress.add_task(
                    f"â˜ï¸  uploading {file_zip_path}",
                    total=zip_size,
                    size_info=f"{zip_size / 1024 / 1024:.1f} MB",
                )

                # ç§»é™¤å·²å®Œæˆçš„å‹ç¼©ä»»åŠ¡
                progress.remove_task(zip_task)

                def upload_progress(consumed_bytes, total_bytes):
                    consumed_mb = consumed_bytes / 1024 / 1024
                    total_mb = total_bytes / 1024 / 1024
                    progress.update(
                        upload_task,
                        completed=consumed_bytes,
                        total=total_bytes,
                        size_info=f"{consumed_mb:.1f}/{total_mb:.1f} MB",
                    )

                upload_success = False
                try:
                    bucket_obj.put_object_from_file(
                        key=file_zip_path,
                        filename=file_zip_path,
                        progress_callback=upload_progress,
                    )
                    upload_success = True
                except Exception as e:
                    console.print(
                        f"[bold red]âŒ upload {file_path} to {bucket} failed with error: {e}"
                    )
                except KeyboardInterrupt:
                    console.print("[yellow]âš ï¸  upload cancelled by user")
                finally:
                    if os.path.exists(file_zip_path):
                        os.remove(path=file_zip_path)

            if upload_success:
                console.print(f"[bold green]âœ… upload {file_path} to {bucket} succeed")
        else:
            # å•ä¸ªæ–‡ä»¶ä¸Šä¼ 
            file_size = os.path.getsize(file_path)
            with Progress(
                TextColumn("[bold blue]{task.description}", justify="left"),
                BarColumn(bar_width=30),
                TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                TransferSpeedColumn(),
                TextColumn("[cyan]å·²ç”¨æ—¶:"),
                TimeElapsedColumn(),
                TextColumn("[yellow]å‰©ä½™:"),
                TimeRemainingColumn(),
            ) as progress:
                task = progress.add_task(
                    f"â˜ï¸  uploading {file_path.name}", total=file_size
                )

                def upload_progress(consumed_bytes, total_bytes):
                    progress.update(task, completed=consumed_bytes, total=total_bytes)

                upload_success = False
                try:
                    bucket_obj.put_object_from_file(
                        key=file_path.name,
                        filename=file_path,
                        progress_callback=upload_progress,
                    )
                    upload_success = True
                except Exception as e:
                    console.print(
                        f"[bold red]âŒ upload {file_path} to {bucket} failed with error: {e}"
                    )
                except KeyboardInterrupt:
                    console.print("[yellow]âš ï¸  upload cancelled by user")

            if upload_success:
                console.print(f"[bold green]âœ… upload {file_path} to {bucket} succeed")

    def download(
        self,
        file: str,
        bucket: Literal["data", "model", "asset", "corpus", "pipeline"],
        save_dir: str = "./",
        force: bool = False,
    ):
        """ä¸‹è½½æ•°æ®é›†
        - file: è¦ä¸‹è½½çš„æ–‡ä»¶
        - bucket: è¦ä¸‹è½½çš„bucket
        - save_dir: ä¿å­˜ç›®å½•, é»˜è®¤å½“å‰ç›®å½•
        """
        if save_dir is None:
            save_dir = bucket
        save_dir: Path = Path(save_dir)
        if not save_dir.exists():
            save_dir.mkdir(parents=True, exist_ok=True)
        bucket_obj: Bucket = self.buckets.get(bucket)
        file_path = save_dir / file

        if file_path.exists() and not force:
            file_size = file_path.stat().st_size
            console.print(
                f"[yellow]âš ï¸  File '{file}' already exists in {save_dir} ({file_size / 1024 / 1024:.1f} MB)[/yellow]"
            )
            console.print(
                "[bold cyan]ğŸ’¡ Tip: Use --force to overwrite existing file[/bold cyan]"
            )
            return

        try:
            console.print(
                f"[blue]ğŸš€ Starting download of '{file}' from bucket '{bucket}'[/blue]"
            )
            with Progress(
                TextColumn("[bold blue]{task.description}", justify="left"),
                BarColumn(bar_width=30),
                TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
                TextColumn("[bold green]{task.fields[size_info]}", justify="left"),
                TransferSpeedColumn(),
                TextColumn("[cyan]å·²ç”¨æ—¶:"),
                TimeElapsedColumn(),
                TextColumn("[yellow]å‰©ä½™:"),
                TimeRemainingColumn(),
            ) as progress:
                # ä¸‹è½½é˜¶æ®µ
                download_task = progress.add_task(
                    f"â¬‡ï¸  downloading {file}", size_info="0.0/0.0 MB"
                )

                def download_progress(consumed_bytes, total_bytes):
                    if total_bytes > 0:
                        consumed_mb = consumed_bytes / 1024 / 1024
                        total_mb = total_bytes / 1024 / 1024
                        progress.update(
                            download_task,
                            total=total_bytes,
                            completed=consumed_bytes,
                            size_info=f"{consumed_mb:.1f}/{total_mb:.1f} MB",
                        )

                bucket_obj.get_object_to_file(
                    key=file,
                    filename=file_path,
                    progress_callback=download_progress,
                )

                # å®Œæˆä¸‹è½½ä»»åŠ¡
                progress.update(download_task, completed=file_path.stat().st_size)
                progress.remove_task(download_task)

                # å¦‚æœæ˜¯zipæ–‡ä»¶ï¼Œè¿›è¡Œè§£å‹
                if file.endswith(".zip"):
                    with zipfile.ZipFile(file=file_path, mode="r") as zf:
                        # è·å–zipæ–‡ä»¶ä¿¡æ¯
                        total_files = len(zf.namelist())
                        extracted_files = 0

                        extract_task = progress.add_task(
                            f"ğŸ“¦ extracting {file}", size_info=f"0/{total_files} files"
                        )

                        def extract_progress():
                            nonlocal extracted_files
                            extracted_files += 1
                            progress.update(
                                extract_task,
                                completed=extracted_files,
                                total=total_files,
                                size_info=f"{extracted_files}/{total_files} files",
                            )

                        # é€ä¸ªæå–æ–‡ä»¶å¹¶æ›´æ–°è¿›åº¦
                        for member in zf.namelist():
                            zf.extract(member, path=save_dir)
                            extract_progress()

                        # å®Œæˆè§£å‹ä»»åŠ¡
                        progress.update(extract_task, completed=total_files)
                        progress.remove_task(extract_task)

                    # åˆ é™¤zipæ–‡ä»¶
                    file_path.unlink()

            console.print(f"[bold green]âœ… download {file} to {save_dir} succeed")
        except Exception as e:
            console.print(
                f"[bold red]âŒ download {file} to {save_dir} failed with error: {e}"
            )
        except KeyboardInterrupt:
            console.print("[yellow]âš ï¸  download cancelled by user")
            # æ¸…ç†æœªå®Œæˆçš„æ–‡ä»¶
            if file_path.exists():
                file_path.unlink()

    def delete(
        self, file: str, bucket: Literal["data", "model", "asset", "corpus", "pipeline"]
    ):
        """åˆ é™¤æ–‡ä»¶æˆ–è€…ç›®å½•

        Args:
            file: è¦åˆ é™¤çš„æ–‡ä»¶åï¼Œæˆ–ä½¿ç”¨ "ALL" åˆ é™¤bucketä¸­çš„æ‰€æœ‰æ–‡ä»¶
            bucket: bucketåç§°

        Examples:
            # åˆ é™¤å•ä¸ªæ–‡ä»¶
            oss delete myfile.zip model

            # åˆ é™¤bucketä¸­çš„æ‰€æœ‰æ–‡ä»¶
            oss delete "ALL" model
        """
        bucket_obj: Bucket = self.buckets.get(bucket)

        if file.upper() == "ALL":
            # åˆ é™¤bucketä¸­çš„æ‰€æœ‰æ–‡ä»¶
            console.print(
                f"[yellow]ğŸ—‘ï¸  Deleting all files from bucket '{bucket}'...[/yellow]"
            )

            deleted_count = 0
            total_size = 0

            try:
                # è·å–æ‰€æœ‰å¯¹è±¡
                objects = list(oss2.ObjectIterator(bucket_obj))

                if not objects:
                    console.print(f"[blue]ğŸ“‚ Bucket '{bucket}' is already empty[/blue]")
                    return

                console.print(f"[dim]Found {len(objects)} files to delete[/dim]")

                # åˆ é™¤æ‰€æœ‰å¯¹è±¡
                for obj in objects:
                    try:
                        bucket_obj.delete_object(obj.key)
                        deleted_count += 1
                        total_size += obj.size if hasattr(obj, "size") else 0

                        # æ¯åˆ é™¤10ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        if deleted_count % 10 == 0 or deleted_count == len(objects):
                            console.print(
                                f"[dim]Deleted {deleted_count}/{len(objects)} files...[/dim]"
                            )

                    except Exception as e:
                        console.print(f"[red]âŒ Failed to delete {obj.key}: {e}[/red]")

                size_mb = total_size / 1024 / 1024
                console.print(
                    f"[bold green]âœ… Successfully deleted {deleted_count} files ({size_mb:.1f} MB) from bucket '{bucket}'[/bold green]"
                )

            except Exception as e:
                console.print(
                    f"[bold red]âŒ Failed to delete files from bucket '{bucket}': {e}[/bold red]"
                )

        else:
            # åˆ é™¤å•ä¸ªæ–‡ä»¶
            if bucket_obj.object_exists(file):
                try:
                    # è·å–æ–‡ä»¶å¤§å°ï¼ˆå¦‚æœå¯èƒ½ï¼‰
                    obj_info = bucket_obj.get_object_meta(file)
                    size = obj_info.headers.get("Content-Length", "unknown")
                    if size != "unknown":
                        size_mb = int(size) / 1024 / 1024
                        size_info = f" ({size_mb:.1f} MB)"
                    else:
                        size_info = ""

                    bucket_obj.delete_object(file)
                    console.print(
                        f"[bold green]âœ… Deleted '{file}'{size_info} from bucket '{bucket}'[/bold green]"
                    )
                except Exception as e:
                    console.print(
                        f"[bold red]âŒ Failed to delete '{file}' from bucket '{bucket}': {e}[/bold red]"
                    )
            else:
                console.print(
                    f"[yellow]âš ï¸  File '{file}' does not exist in bucket '{bucket}'[/yellow]"
                )

    def clear(self):
        """æ¸…ç©ºæœ¬åœ°ç¼“å­˜å’ŒAPIå¯†é’¥"""
        if self.auth_file.exists():
            os.remove(self.auth_file)

    def info(self):
        """
        æ‰“å°å½“å‰çš„authä¿¡æ¯
        """
        access_key_id, access_key_secret = load_auth(self.auth_file)
        console.print("[bold cyan]auth:[/bold cyan]")
        console.print(f"  access_key_id: {access_key_id}")
        console.print(f"  access_key_secret: {access_key_secret}")


def run():
    auto_cli(OSSStorer, as_positional=True)


if __name__ == "__main__":
    run()
