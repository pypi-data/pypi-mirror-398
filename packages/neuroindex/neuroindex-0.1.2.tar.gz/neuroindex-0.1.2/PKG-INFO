Metadata-Version: 2.4
Name: neuroindex
Version: 0.1.2
Summary: Hybrid vector + semantic graph memory system
Author: Umeshkumar Pal
License: MIT
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.23
Requires-Dist: networkx>=3.0
Requires-Dist: faiss-cpu>=1.7
Dynamic: license-file

# ğŸ§  NeuroIndex

**NeuroIndex** is a hybrid **vector + semantic graph memory system** for embeddings.

It combines:
- âš¡ RAM-based LRU cache (working memory)
- ğŸ” FAISS vector search (similarity)
- ğŸ•¸ï¸ Semantic graph traversal (associative recall)
- ğŸ’¾ Persistent SQLite storage (long-term memory)

Designed for **AI memory**, **RAG systems**, **chatbots**, and **semantic search pipelines**.


## âœ¨ Why NeuroIndex?

Most vector databases only answer:
> â€œWhat is similar?â€

NeuroIndex also answers:
> â€œWhat is related?â€

This makes it ideal for:
- Conversational AI memory
- Document understanding
- Knowledge graphs + embeddings
- Long-running agents
- Offline / local-first AI systems

## Where NeuroIndex fits
### ğŸ§© System Architecture

The typical data flow using NeuroIndex is as follows:

```
TEXT / DATA
    â†“
[Embedding Model]  â† OpenAI / HF / Cohere / Local
    â†“
[NeuroIndex]       â† Memory + Retrieval
    â†“
[LLM / App / Agent / API]
```



## ğŸ”Œ Integration patterns
- NeuroIndex can be used as:
- Memory layer for RAG pipelines
- Long-term memory for chatbots
- Knowledge base for document search
- Experience memory for agents
- Offline semantic retrieval system

It does not depend on any specific model, framework, or cloud provider.

Github: https://github.com/Umeshkumar667/NeuroIndex

## ğŸ“¦ Installation
```bash
pip install neuroindex
```
## ğŸš€ Quick Start
```
from neuroindex import NeuroIndex
import numpy as np

# Create index
ni = NeuroIndex(
    path="./memory",   # persistent storage folder
    dim=112            # embedding dimension
)

# Dummy embedding function
def embed(text: str):
    return np.random.rand(112).astype("float32")

# Add documents
ni.add_document("Neural networks use embeddings", embed("doc1"))
ni.add_document("FAISS enables fast vector search", embed("doc2"))
ni.add_document("Graphs capture semantic relationships", embed("doc3"))

# Search by vector
query_vec = embed("search")
results = ni.search(query_vector=query_vec, k=3)

for r in results:
    print(r.source, r.similarity, r.text)


# Search directly with text (recommended)

results = ni.search_text(
    "What is semantic memory?",
    embed_fn=embed,
    k=3
)

for r in results:
    print(r.text)

ni.get_stats()
```
