# Lumen Services Configuration - Single Service Mode
# yaml-language-server: $schema=https://doc.lumilio.org/schema/config-schema.yaml

metadata:
    version: "1.0.0"
    region: "cn" # "cn" for ModelScope, "other" for HuggingFace
    cache_dir: "~/Lumen-Resources"

deployment:
    mode: "single"
    service: "clip"

server:
    port: 50051
    host: "0.0.0.0"
    mdns:
        enabled: true
        service_name: "lumen-clip"

services:
    # CLIP Service
    clip:
        enabled: true
        package: "lumen_clip"
        import:
            registry_class: "lumen_clip.service_registry.CLIPService"
            add_to_server: "lumen_clip.proto.ml_service_pb2_grpc.add_InferenceServicer_to_server"
        backend_settings:
            device: "mps"
            onnx_providers:
                - "CoreMLExecutionProvider"
            batch_size: 8
        models:
            general:
                model: "MobileCLIP2-S2" # CN-CLIP_ViT-L-14
                runtime: torch
                dataset: ImageNet_1k
