# Lumen Services Configuration Schema
# Version: 1.0.0
# Specification: https://json-schema.org/draft-07/schema

$schema: "http://json-schema.org/draft-07/schema#"
$id: "https://github.com/Lumilio-Photos/lumen-config-spec/v1.0.0"

title: Lumen Config
description: Unified configuration schema for all Lumen ML services

type: object
required:
    - metadata
    - deployment
    - server
    - services

properties:
    metadata:
        type: object
        required:
            - version
            - region
            - cache_dir
        properties:
            version:
                type: string
                pattern: "^\\d+\\.\\d+\\.\\d+$"
                description: Configuration version (semantic versioning)
                examples:
                    - "1.0.0"
                    - "2.1.3"

            region:
                type: string
                enum: ["cn", "other"]
                description: Platform region selection (cn=ModelScope, other=HuggingFace)

            cache_dir:
                type: string
                description: Model cache directory path (supports ~ expansion)
                examples:
                    - "~/.lumen/models"
                    - "/opt/lumen/models"

    deployment:
        type: object
        required:
            - mode
        properties:
            mode:
                type: string
                enum: ["single", "hub"]
                description: Deployment mode

            service:
                type: string
                description: Service name for single mode (required if mode=single)
                pattern: "^[a-z][a-z0-9_]*$"

            services:
                type: array
                items:
                    type: string
                    pattern: "^[a-z][a-z0-9_]*$"
                minItems: 1
                uniqueItems: true
                description: Service names for hub mode (required if mode=hub)

        # Conditional validation based on mode
        oneOf:
            - required: ["service"]
              properties:
                  mode:
                      const: "single"
            - required: ["services"]
              properties:
                  mode:
                      const: "hub"

    server:
        type: object
        required:
            - port
        properties:
            port:
                type: integer
                minimum: 1024
                maximum: 65535
                default: 50051
                description: gRPC server port

            host:
                type: string
                default: "0.0.0.0"
                description: Server bind address
                examples:
                    - "0.0.0.0"
                    - "127.0.0.1"
                    - "[::]"

            mdns:
                type: object
                properties:
                    enabled:
                        type: boolean
                        default: false
                        description: Enable mDNS service discovery

                    service_name:
                        type: string
                        description: mDNS service name (required if enabled=true)
                        pattern: "^[a-z][a-z0-9-]*$"
                        examples:
                            - "lumen-clip"
                            - "lumen-hub"

                # If enabled=true, service_name is required
                if:
                    properties:
                        enabled:
                            const: true
                then:
                    required: ["service_name"]

    services:
        type: object
        minProperties: 1
        description: Service definitions

        patternProperties:
            "^[a-z][a-z0-9_]*$":
                type: object
                x-pydantic-config:
                    validate_by_name: true
                    validate_by_alias: true
                required:
                    - enabled
                    - package
                    - import
                    - models

                properties:
                    enabled:
                        type: boolean
                        description: Whether to load this service

                    package:
                        type: string
                        pattern: "^[a-z][a-z0-9_]*$"
                        description: Python package name
                        examples:
                            - "lumen_clip"
                            - "lumen_face"

                    import_info:
                        type: object
                        required:
                            - registry_class
                            - add_to_server
                        properties:
                            registry_class:
                                type: string
                                pattern: "^[a-z_][a-z0-9_.]*\\.[A-Z][a-zA-Z0-9]*$"
                                description: Full dotted path to service registry class
                                examples:
                                    - "lumen_clip.service_registry.ClipService"
                                    - "lumen_face.service_registry.FaceService"

                            add_to_server:
                                type: string
                                pattern: "^[a-z_][a-z0-9_.]*\\.add_[A-Za-z0-9_]+_to_server$"
                                description: Full dotted path to gRPC add_to_server function
                                examples:
                                    - "lumen_clip.proto.ml_service_pb2_grpc.add_InferenceServicer_to_server"
                                    - "lumen_face.proto.ml_service_pb2_grpc.add_FaceServicer_to_server"
                    backend_settings:
                        $ref: "#/definitions/BackendSettings"
                    models:
                        type: object
                        minProperties: 1
                        description: Model configurations (alias â†’ config)

                        patternProperties:
                            "^[a-z][a-z0-9_]*$":
                                $ref: "#/definitions/ModelConfig"

definitions:
    BackendSettings:
        type: object
        description: Optional settings for inference backend configuration.
        properties:
            device:
                type: [string, "null"] # Allow string or null
                description: "Preferred device ('cuda', 'mps', 'cpu'). If null, auto-detects best available."
                default: null
            batch_size:
                type: integer
                description: Maximum batch size for inference.
                minimum: 1
                default: 8
            onnx_providers:
                type: [array, "null"]
                description: "List of ONNX execution providers. Each item can be a string or a tuple of (name, config_dict)."
                default: null

        additionalProperties: false
    ModelConfig:
        type: object
        required:
            - model
            - runtime
        properties:
            model:
                type: string
                description: Model repository name
                examples:
                    - "ViT-B-32"
                    - "CN-CLIP-ViT-B-16"
                    - "MobileCLIP-S2"

            runtime:
                type: string
                enum: ["torch", "onnx", "rknn"]
                description: Model runtime type

            rknn_device:
                type: string
                pattern: "^rk\\d+$"
                description: RKNN device identifier (required if runtime=rknn)
                examples:
                    - "rk3566"
                    - "rk3588"

            dataset:
                type: string
                description: Dataset name for zero-shot classification (optional)
                examples:
                    - "ImageNet_1k"
                    - "TreeOfLife-10M"
            precision:
                type: string
                description: Preferred precision for running the model, valid only when runtime is 'onnx' or 'rknn'. The download validator will check the precision field in model_info.json to verify if the preferred precision is available for the current model.
                examples:
                    - "fp32"
                    - "int8"
                    - "q4fp16"

        # If runtime=rknn, rknn_device is required
        if:
            properties:
                runtime:
                    const: "rknn"
        then:
            required: ["rknn_device"]

# Additional validation rules
additionalProperties: false
