# Agent Redis Framework

ä¸€ä¸ªä¼˜é›…ã€é«˜æ•ˆçš„ Python Redis æ¡†æ¶ï¼Œä¸“ä¸ºå¤šä»»åŠ¡è°ƒåº¦ä¸æ¶ˆæ¯æµå¤„ç†è€Œè®¾è®¡ã€‚æä¾›åŸºäº Redis Sorted Sets çš„è½»é‡ä»»åŠ¡é˜Ÿåˆ—å’ŒåŸºäº Redis Streams çš„æ¶ˆè´¹ç»„å°è£…ï¼Œé€‚åˆæ„å»ºå¯æ‰©å±•çš„åˆ†å¸ƒå¼ä»»åŠ¡ç³»ç»Ÿã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### SortedSetQueue - æ™ºèƒ½ä»»åŠ¡é˜Ÿåˆ—
- **ä¼˜å…ˆçº§è°ƒåº¦**: åŸºäº Redis Sorted Set å®ç°çš„è½»é‡ä»»åŠ¡é˜Ÿåˆ—
- **åŸå­æ“ä½œ**: ä½¿ç”¨ `ZPOPMIN`/`ZPOPMAX` ç¡®ä¿å¤šæ¶ˆè´¹è€…åœºæ™¯ä¸‹çš„ä»»åŠ¡å®‰å…¨åˆ†å‘
- **çµæ´»æ’åº**: æ”¯æŒæŒ‰åˆ†æ•°å‡åº/é™åºå¼¹å‡ºä»»åŠ¡
- **å¤±è´¥å¤„ç†**: å†…ç½®ä»»åŠ¡å¤„ç†å¤±è´¥çš„å›è°ƒæœºåˆ¶
- **æ‰¹é‡å¤„ç†**: æ”¯æŒä¸€æ¬¡æ€§å¼¹å‡ºå¹¶å¤„ç†å¤šä¸ªä»»åŠ¡

### ğŸ“¡ StreamClient - æµå¼æ¶ˆæ¯å¤„ç†
- **æ¶ˆè´¹ç»„ç®¡ç†**: å®Œæ•´çš„ Redis Streams æ¶ˆè´¹ç»„å°è£…
- **è‡ªåŠ¨ ACK**: æ¶ˆæ¯å¤„ç†æˆåŠŸåè‡ªåŠ¨ç¡®è®¤
- **æµé‡æ§åˆ¶**: æ”¯æŒæµé•¿åº¦é™åˆ¶å’Œè‡ªåŠ¨ä¿®å‰ª
- **é˜»å¡æ¶ˆè´¹**: å¯é…ç½®çš„é˜»å¡æ—¶é—´å’Œæ‰¹é‡æ¶ˆè´¹
- **é”™è¯¯æ¢å¤**: å¤„ç†å¾…ç¡®è®¤æ¶ˆæ¯å’Œæ¶ˆè´¹è€…æ•…éšœæ¢å¤
- **å†…ç½®çº¿ç¨‹æ± **: è‡ªåŠ¨ç®¡ç†è¯»å–çº¿ç¨‹å’Œæ¶ˆæ¯å¤„ç†çº¿ç¨‹æ± ï¼Œæä¾›é«˜å¹¶å‘æ€§èƒ½

### ğŸ”§ HashClient - é«˜æ•ˆHashæ“ä½œ
- **ç±»å‹ç»Ÿä¸€**: å†™å…¥æ—¶å°† bytes/int/float è½¬ä¸ºå­—ç¬¦ä¸²ï¼›è¯»å–æ—¶è¿”å› strï¼ˆä¸å­˜åœ¨è¿”å› Noneï¼‰
- **æ‰¹é‡æ“ä½œ**: æ”¯æŒæ‰¹é‡è®¾ç½®å’Œè·å–å¤šä¸ªå­—æ®µ
- **æ•°å€¼æ“ä½œ**: å†…ç½®æ•´æ•°å’Œæµ®ç‚¹æ•°è‡ªå¢åŠŸèƒ½
- **å­—æ®µç®¡ç†**: å®Œæ•´çš„å­—æ®µå­˜åœ¨æ€§æ£€æŸ¥ã€åˆ é™¤å’Œæ¸…ç©ºåŠŸèƒ½
- **è¿‡æœŸæ§åˆ¶**: æ”¯æŒä¸ºæ•´ä¸ªHashè®¾ç½®è¿‡æœŸæ—¶é—´

### ğŸ”§ ä¼ä¸šçº§ç‰¹æ€§
- **è¿æ¥æ± ç®¡ç†**: è‡ªåŠ¨è¿æ¥æ± å¤ç”¨ï¼Œä¼˜åŒ–é«˜å¹¶å‘æ€§èƒ½
- **ç¯å¢ƒé…ç½®**: çµæ´»çš„ `.env` æ–‡ä»¶å’Œç¯å¢ƒå˜é‡æ”¯æŒ
- **ç±»å‹å®‰å…¨**: å®Œæ•´çš„ Python ç±»å‹æ³¨è§£
- **çº¿ç¨‹å®‰å…¨**: æ‰€æœ‰æ ¸å¿ƒç»„ä»¶æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘
- **è½»é‡ä¾èµ–**: ä»…ä¾èµ– `redis` å’Œ `typing-extensions`

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Redis è¿æ¥é…ç½®

#### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=your_password
REDIS_MAX_CONNECTIONS=20
```

```python
from agent_redis_framework import get_redis

# è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®
redis_client = get_redis()
print(redis_client.ping())  # True
```

### SortedSetQueue - ä»»åŠ¡é˜Ÿåˆ—ç¤ºä¾‹

```python
from agent_redis_framework import SortedSetQueue, SortedTask
import time

queue = SortedSetQueue()
queue_key = "my_task_queue"

# æ¸…ç©ºé˜Ÿåˆ—ï¼ˆå¯é€‰ï¼‰
queue.clear(queue_key)

# æ¨é€ä»»åŠ¡ï¼ˆåˆ†æ•°è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
import json
queue.push(queue_key, SortedTask(payload=json.dumps({"priority": "high"})), score=1)
queue.push(queue_key, SortedTask(payload=json.dumps({"priority": "normal"})), score=5)
queue.push(queue_key, SortedTask(payload=json.dumps({"priority": "low"})), score=10)

# å®šä¹‰ä»»åŠ¡å¤„ç†å‡½æ•°
def process_task(score: float, task: SortedTask) -> bool:
    print(f"Processing task at score {score}: {task.payload}")
    # æ¨¡æ‹Ÿä»»åŠ¡å¤„ç†
    time.sleep(0.1)
    return True  # è¿”å› True è¡¨ç¤ºå¤„ç†æˆåŠŸ

# å®šä¹‰å¤±è´¥å¤„ç†å‡½æ•°
def handle_failure(score: float, task: SortedTask) -> None:
    print(f"Task failed at score {score}, logging for retry...")

# åŸå­å¼¹å‡ºå¹¶å¤„ç†ä»»åŠ¡
processed = queue.pop_and_handle(
    queue_key,
    callback=process_task,
    on_failure=handle_failure,
    count=2  # ä¸€æ¬¡å¤„ç† 2 ä¸ªä»»åŠ¡
)

print(f"Processed {len(processed)} tasks")
print(f"Remaining tasks: {queue.size(queue_key)}")
```

### StreamClient - æµå¼æ¶ˆæ¯ç¤ºä¾‹

- StreamMsg.meta çš„ç±»å‹å·²æ”¶ç´§ä¸ºï¼š`dict[str, bytes | str | int | float]`
- push() ä¼šå°† meta æ‰å¹³åŒ–å†™å…¥ Redisï¼Œå­—æ®µåå‰ç¼€ä¸º `__m_`ï¼ˆä¾‹å¦‚ï¼š`__m_trace_id`ï¼‰
- consume() çš„å›è°ƒç­¾åå·²æ›´æ–°ä¸ºï¼š`callback(msg_key: str, msg: StreamMsg) -> bool`

```python
from agent_redis_framework import StreamClient, StreamMsg
import time
import json

# åˆå§‹åŒ– - ä¼ å…¥æµåç§°
stream_client = StreamClient("user_events")

group_name = "analytics_group"
consumer_name = "consumer_1"

# åˆ›å»ºæ¶ˆè´¹ç»„ï¼ˆå¹‚ç­‰æ“ä½œï¼‰
stream_client.ensure_group(group_name)

# æ¨é€æ¶ˆæ¯ï¼ˆpayload å»ºè®®ä¸º JSON å­—ç¬¦ä¸²ï¼›meta ä»…å…è®¸æ ‡é‡å€¼ï¼‰
msg = StreamMsg(
    payload=json.dumps({
        "event_type": "user_login",
        "user_id": "12345",
        "timestamp": time.time(),
        "ip_address": "192.168.1.100"
    }),
    meta={"source": "readme", "request_id": "req-1", "retry": 0}
)
msg_key = stream_client.push(msg)
print(f"Message pushed with ID: {msg_key}")

# å®šä¹‰æ¶ˆæ¯å¤„ç†å‡½æ•°ï¼ˆæ–°ç‰ˆç­¾åï¼‰
def handle_message(msg_key: str, msg: StreamMsg) -> bool:
    print(f"Processing message {msg_key}")
    print(f"Payload: {msg.payload}")  # è‹¥ä¸º JSON å­—ç¬¦ä¸²ï¼Œå¯è‡ªè¡Œ json.loads
    print(f"Meta: {msg.meta}")       # æ¥è‡ª __m_ å‰ç¼€å­—æ®µ
    time.sleep(0.1)
    return True

# å¯åŠ¨æ¶ˆè´¹è€… - StreamClientå†…éƒ¨è‡ªåŠ¨ç®¡ç†çº¿ç¨‹æ± 
stream_client.consume(
    group=group_name,
    consumer=consumer_name,
    callback=handle_message,   # æ³¨æ„ï¼šç­¾åä¸º (msg_key, msg)
    block_ms=5000,             # 5ç§’é˜»å¡è¶…æ—¶
    count=10                   # æ¯æ¬¡æœ€å¤šè¯»å–10æ¡æ¶ˆæ¯
)

# åœ¨å¦ä¸€ä¸ªè¿›ç¨‹æˆ–çº¿ç¨‹ä¸­æ¨é€æ›´å¤šæ¶ˆæ¯
for i in range(3):
    msg = StreamMsg(
        payload=json.dumps({
            "event_type": "page_view",
            "user_id": f"user_{i}",
            "page": f"/page/{i}",
            "timestamp": time.time()
        }),
        meta={"source": "readme", "seq": i}
    )
    stream_client.push(msg)
    time.sleep(1)

# ä¼˜é›…åœæ­¢æ¶ˆè´¹è€…
stream_client.stop()
```

### HashClient - Hash æ“ä½œç¤ºä¾‹

- ç»Ÿä¸€ç±»å‹ï¼šå†™å…¥æ—¶å°† bytes/int/float è½¬ä¸ºå­—ç¬¦ä¸²ï¼›è¯»å–æ—¶è¿”å› strï¼ˆä¸å­˜åœ¨è¿”å› Noneï¼‰ã€‚
- æ”¯æŒçš„æ ‡é‡ç±»å‹ï¼šbytes | str | int | floatï¼ˆå¤æ‚ç»“æ„è¯·å…ˆåºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²ï¼‰ã€‚

```python
from agent_redis_framework import HashClient

# åˆ›å»ºHashClientå®ä¾‹ï¼Œç»‘å®šåˆ°ç‰¹å®šçš„key
h = HashClient("user:1")

# åŸºç¡€å†™å…¥/è¯»å–
h.set("name", "Alice")                # -> 1 è¡¨ç¤ºæ–°å­—æ®µï¼Œ0 è¡¨ç¤ºè¦†ç›–
print(h.get("name"))                     # -> "Alice" æˆ– None

# æ‰¹é‡å†™/è¯»
h.set_many({"age": 18, "score": 99.5})
print(h.get_many(["name", "age", "score", "missing"]))  # -> {'name': 'Alice', 'age': '18', 'score': '99.5', 'missing': None}
print(h.get_all())                          # -> {'name': 'Alice', 'age': '18', 'score': '99.5'}

# æŸ¥è¯¢/ç»Ÿè®¡
print(h.keys())     # -> ["name", "age", "score"]
print(h.values())   # -> ["Alice", "18", "99.5"]
print(h.len())      # -> å­—æ®µæ•°é‡

# æ•°å€¼è‡ªå¢
print(h.incr("visits", 1))       # -> æœ€æ–°æ•´æ•°å€¼
print(h.incr_float("ratio", 0.1)) # -> æœ€æ–°æµ®ç‚¹å€¼

# å­˜åœ¨/åˆ é™¤/è¿‡æœŸ
print(h.exists("name"))    # -> True/False
print(h.delete("age", "score"))  # -> å®é™…åˆ é™¤çš„å­—æ®µæ•°é‡
print(h.expire(60))         # -> æ˜¯å¦è®¾ç½®æˆåŠŸ
# æ¸…ç†
h.clear()              # åˆ é™¤æ•´ä¸ª Hash é”®

## ğŸ—ï¸ é«˜çº§ç”¨æ³•

### æµæ¶ˆæ¯æ‰¹é‡å¤„ç†

```python
from agent_redis_framework import StreamClient, StreamMsg
import json

stream_client = StreamClient("order_stream")

# æ‰¹é‡æ¨é€æ¶ˆæ¯
messages = [
    {"order_id": f"order_{i}", "amount": i * 100, "status": "pending"}
    for i in range(100)
]

for msg in messages:
    stream_msg = StreamMsg(payload=json.dumps(msg), meta={"batch": 1})
    stream_client.push(stream_msg, maxlen=1000)  # é™åˆ¶æµé•¿åº¦

# æ‰¹é‡æ¶ˆè´¹å¤„ç† - å†…ç½®çº¿ç¨‹æ± è‡ªåŠ¨å¤„ç†å¹¶å‘
def batch_process_orders(msg_key: str, msg: StreamMsg) -> bool:
    order_data = json.loads(msg.payload) if msg.payload else {}
    print(f"Processing order: {order_data.get('order_id', 'unknown')} with key {msg_key}")
    return True

stream_client.consume(
    group="order_processors",
    consumer="processor_1",
    callback=batch_process_orders,
    count=50,  # æ¯æ¬¡æ‰¹é‡å¤„ç†50æ¡æ¶ˆæ¯
    block_ms=1000
)

# åœæ­¢æ¶ˆè´¹è€…
stream_client.stop()
```

## ğŸ“š API å‚è€ƒï¼ˆå…³é”®å˜æ›´ï¼‰

### HashClient
- `__init__(key: str, redis_client=None)` - åˆ›å»ºHashClientå®ä¾‹ï¼Œç»‘å®šåˆ°æŒ‡å®šçš„Redis Hashé”®
- `set(field, value: bytes | str | int | float) -> int` - è®¾ç½®å•ä¸ªå­—æ®µï¼›1 è¡¨ç¤ºæ–°å­—æ®µï¼Œ0 è¡¨ç¤ºè¦†ç›–
- `setnx(field, value) -> bool` - ä»…å½“å­—æ®µä¸å­˜åœ¨æ—¶è®¾ç½®
- `set_many(mapping: dict[str, bytes | str | int | float]) -> None` - æ‰¹é‡è®¾ç½®å¤šä¸ªå­—æ®µ
- `get(field) -> str | None` - è·å–å•ä¸ªå­—æ®µï¼›ä¸å­˜åœ¨è¿”å› None
- `get_many(fields: Iterable[str]) -> dict[str, str | None]` - æ‰¹é‡è·å–å¤šä¸ªå­—æ®µ
- `get_all() -> dict[str, str]` - è·å–æ•´ä¸ª Hashï¼Œå­—æ®µå’Œå€¼å‡ä¸º str
- `len() -> int` - è¿”å›å­—æ®µæ•°é‡
- `keys() -> list[str]` - è¿”å›æ‰€æœ‰å­—æ®µåï¼ˆstrï¼‰
- `values() -> list[str]` - è¿”å›æ‰€æœ‰å­—æ®µå€¼ï¼ˆstrï¼‰
- `incr(field, amount: int = 1) -> int` - æ•´æ•°è‡ªå¢å¹¶è¿”å›æœ€æ–°å€¼
- `incr_float(field, amount: float = 1.0) -> float` - æµ®ç‚¹è‡ªå¢å¹¶è¿”å›æœ€æ–°å€¼
- `exists(field) -> bool` - å­—æ®µæ˜¯å¦å­˜åœ¨
- `delete(*fields) -> int` - åˆ é™¤ä¸€ä¸ªæˆ–å¤šä¸ªå­—æ®µï¼Œè¿”å›åˆ é™¤æ•°é‡
- `clear() -> None` - åˆ é™¤æ•´ä¸ª Hash é”®
- `expire(seconds: int) -> bool` - è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰

å¤‡æ³¨ï¼šå†™å…¥çš„æ ‡é‡å€¼éƒ½ä¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²å­˜å‚¨ï¼›è¯»å–ç»Ÿä¸€è¿”å› strï¼ˆæˆ– Noneï¼‰ã€‚

### StreamClient
- `__init__(stream: str)` - åˆå§‹åŒ–æµå®¢æˆ·ç«¯ï¼Œä¼ å…¥æµåç§°
- `push(msg, maxlen=None)` - å°† StreamMsg æ¨é€åˆ°æµä¸­ï¼›meta ä¼šä»¥ `__m_` å‰ç¼€æ‰å¹³åŒ–å†™å…¥
- `consume(group, consumer, callback, block_ms=5000, count=1)` - æ¶ˆè´¹æ¶ˆæ¯ï¼›`callback` ç­¾åä¸º `(msg_key: str, msg: StreamMsg) -> bool`ï¼›å†…ç½®çº¿ç¨‹æ± è‡ªåŠ¨å¤„ç†å¹¶å‘
- `ensure_group(group)` - ç¡®ä¿æ¶ˆè´¹è€…ç»„å­˜åœ¨ï¼Œå¦‚ä¸å­˜åœ¨åˆ™åˆ›å»º
- `stop()` - ä¼˜é›…åœæ­¢æ¶ˆè´¹è€…ï¼Œå…³é—­è¯»å–çº¿ç¨‹å’Œçº¿ç¨‹æ± 

### æ•°æ®ç±»
- `StreamMsg(payload, meta={})` - æµæ¶ˆæ¯æ•°æ®ç±»ï¼Œpayload ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼›meta ç±»å‹ä¸º `dict[str, bytes | str | int | float]`
- `SortedTask(payload, meta={})` - é˜Ÿåˆ—ä»»åŠ¡æ•°æ®ç±»ï¼Œpayload ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼›meta ä¸ºå­—å…¸ç±»å‹

æ³¨æ„ï¼šå¤æ‚ç»“æ„ï¼ˆå¦‚åˆ—è¡¨/å­—å…¸ï¼‰è¯·å…ˆ JSON åºåˆ—åŒ–åæ”¾å…¥ payloadï¼›meta ä»…æ¥å—æ ‡é‡ç±»å‹ã€‚å¦‚æœä¸€å®šè¦åœ¨ meta ä¿ç•™å¤æ‚ç»“æ„ï¼Œè¯·å…ˆè‡ªè¡Œåºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²ã€‚