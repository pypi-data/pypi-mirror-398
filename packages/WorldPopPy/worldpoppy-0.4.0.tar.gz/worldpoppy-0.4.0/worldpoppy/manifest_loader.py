"""
Main public API for loading and interacting with the data manifest for
`worldpoppy`.

This module is the primary entry point for both the end-user and other parts
of the `worldpoppy` package. It provides the public-facing functions (e.g.,
`wp_manifest`, `show_supported_data_products`) for discovering and filtering
supported raster datasets.

Main methods
------------------------

    - :func:`wp_manifest`
        Load and filter the cleaned raster-data manifest for `worldpoppy`.
    - :func:`show_supported_data_products`
        Print a summary table of available data products (with optional filtering).
    - :func:`wp_manifest_constrained`
        Strictly validate a request for a specific product/country/year.

The module is responsible for:

1.  Loading the raw manifest from disk (which is created by the separate
    `manifest_builder` module).
2.  Triggering the `manifest_builder` to run if the raw manifest cache
    is missing.
3.  Cleaning and validating the raw manifest data.
4.  Assigning a curated `product_name` to raster datasets for easier
    user queries.

Note on Terminology
-------------------

In  `worldpoppy`'s terminology, a "dataset" is always single downloadable
raster file with a single band. Each such dataset conveys a concrete, thematic
measurement and is uniquely identified either by a single country or a single
country-year.

We speak of a "data product" to denote a *collection* of the same measurement
across a larger set of countries (=static data product) or country-years
(=multi-year data product).

The Cleaned Manifest DataFrame Schema
-------------------------------------

The primary output of this module (from `wp_manifest`) is a pandas.DataFrame
with one row per supported, downloadable raster dataset. It contains the following
columns:

**Curated Columns:**

- wpy_id (str):
    The unique `worldpoppy` ID for this specific dataset entry. It is
    identical to WorldPop's API 'id' for only "flat" (1-to-1) data products
    (e.g., "12345"). For "multi-year" or "multi-band" products, `wpy_id` is
    a synthetic ID generated by `worldpoppy` to ensure uniqueness
    (e.g., "12345_2020" or "67890_dst011").

- product_name (str):
    The unique, curated name of the data product in which a specific
    raster dataset is conceptually nested (see also our separate note
    on terminology). This is a `worldpoppy`-specific alias (e.g., "pop_g1",
    "dist_esalc_g1_cultivated") and based on definitions contained in
    the 'product_definitions.toml' file.

- iso3 (str):
    The 3-letter ISO code for the country for which the raster dataset (=file)
    contains data. Currently, `worldpoppy` only supports country-specific raster
    data, but not files with continental or global coverage.

- year (Int64):
    The 4-digit year of the dataset, or <NA> for static datasets that
    are not associated with a specific year of measurement.

- multi_year (bool):
    True if the dataset is part of a multi-year time series. False for
    all static datasets.

- product_notes (str):
    The curated, human-readable note for the data product to which the
    raster file belongs.

- data_series (str):
    The larger data series to  which the  raster file belongs (either
    "global1" or "global2").

- arcsecs (Int64):
    The inferred resolution in arc-seconds (e.g., 3, 30) or <NA>.

**Download & File Columns:**

- dataset_name (str):
    The raw filename stem without file-type suffix (e.g., "afg_wpgp_2000_100m").

- remote_path (str):
    The full URL to download the .tif file.

- remote_name (str):
    The filename of the remote .tif file.

- summary_url (str):
    A sample URL to the WorldPop summary page associated with this dataset.

**Raw API Columns (for advanced use):**

- api_path (str):
    The path to the "Leaf Node" in WorldPop's meta-data API that is associated
    with this dataset (e.g., "pop/wpgp" or  "covariates/G2_NT_lights"). This
    is a powerful field for debugging and advanced use. You can use it to
    explore the raw meta-data API data directly. For example:

    - View the "Coverage Index":
      https://hub.worldpop.org/rest/data/{api_path}
    - Make a "Details Call" for a specific country:
      https://hub.worldpop.org/rest/data/{api_path}?iso3=AFG

    (For a full explanation of these terms, see the 'manifest_build_strategy.md'
    documentation file).

- api_slug (str):
    The final part of the `api_path` (e.g., "G2_NT_lights").

- api_entry_title (str):
    The raw title text from the meta-data API.

- api_project (str):
    The raw project name from the meta-data API (e.g., "Covariates").

- api_series_category (str):
    The raw category text from the meta-data API.

- api_series_desc (str):
    The raw long-form description from the meta-data API.

- api_source (str):
    The raw source text from the meta-data API.
"""

import logging
import sys
from datetime import datetime
from functools import lru_cache

import numpy as np
import pandas as pd

from worldpoppy.config import (
    RAW_MANIFEST_CACHE_PATH,
    PRODUCT_BASE_NAME_MAP,
    ESA_LAND_COVER_DESC_MAP,
    ESA_LAND_COVER_ALIAS_MAP,
    PRODUCT_NOTES_MAP,
    DEBUG)
from worldpoppy.func_utils import log_info_context
from worldpoppy.manifest_builder import build_raw_manifest_from_api
from worldpoppy.manifest_utils import (
    infer_resolution_from_description,
    infer_data_series,
    format_url_to_emoji
)

_IS_NOTEBOOK = "ipykernel" in sys.modules


__all__ = [
    "wp_manifest",
    "wp_manifest_constrained",
    "show_supported_data_products",
    "get_product_info",
    "get_all_isos",
    "get_all_product_names",
    "get_static_product_names",
    "get_all_dataset_names",
    "resolve_product_years",
]


logger = logging.getLogger(__name__)


class ManifestValidationError(RuntimeError):
    """
    Raised by if the raw data from the crawler fails a validity check.
    """

    pass


def wp_manifest(
    product_name=None,
    iso3_codes=None,
    years=None,
    static_only=False,
    multi_year_only=False,
    keywords=None,
):
    """
    Load the `worldpoppy` raster-data manifest and filter it.

    Together with `show_supported_data_products`, this function offers users
    a way of discovering and selecting for download. While `show_supported_data_products`
    only provides a high-level overview of available data, this function will
    return the full raster-data manifest for `worldpoppy` (when called without
    any filter arguments).

    Parameters
    ----------
    product_name : str, optional
        The *exact*, curate name of the data product (e.g., 'pop_g1') for which to
        return manifest entries. Mutually exclusive with 'keyword'.
    iso3_codes : str or List[str], optional
        One or more three-letter ISO codes indicating the countries
        of interest.
    years : int, List[Union[int, str]], or str, optional
        One or more years of interest or a keyword string.

        - If years are provided (as ints or keywords), filters the manifest
          to those specific years.
        - If 'all': Returns entries for all available years.
        - If 'first': Returns the earliest available year (requires `product_name`).
        - If 'last': Returns the most recent available year (requires `product_name`).
        - If None (default), no filtering on year is performed.

    static_only : bool, optional
        If True, only return manifest entries for static datasets (i.e., those
        *not* part of a multi-year time series). Mutually exclusive with
        'multi_year_only'.
    multi_year_only : bool, optional
        If True, only return manifest entries for multi-year time series.
        Mutually exclusive with 'static_only'.
    keywords : str, optional
        A single search term (str) or a list of search terms by which to
        perform a case-insensitive search of manifest entries. Mutually
        exclusive with 'product_name'. Note that the search is performed
        using certain product-level fields only: 'product_name', 'product_notes',
        'project', and 'data_series'.


    Returns
    -------
    pandas.DataFrame
        A DataFrame containing the (optionally filtered) manifest, with one
        row per downloadable raster dataset.

        For a detailed description of all columns, see the
        :mod:`~worldpoppy.manifest_loader` module documentation.
    """

    # validate user args
    if product_name is not None and keywords is not None:
        raise ValueError("`product_name` and `keyword` are mutually exclusive.")
    if static_only and multi_year_only:
        raise ValueError("`static_only` and `multi_year_only` are mutually exclusive.")

    if isinstance(iso3_codes, str):
        iso3_codes = [iso3_codes]
    if isinstance(years, int):
        years = [years]

    # --- Keyword Logic for years ---
    # We must resolve 'first'/'last' here because the generic filter logic
    # below does not know about product-specific time ranges.
    if isinstance(years, str) and years in ('first', 'last'):
        if product_name is None:
            raise ValueError(
                f"You cannot use the relative year keyword '{years}' without "
                "specifying a `product_name`."
            )
        # This will return a concrete list like [2020]
        years = resolve_product_years(product_name, years)

    # get the full manifest
    mdf = _get_cleaned_manifest()
    mdf = mdf.copy(deep=True)

    # apply filters
    with log_info_context(logger):
        if product_name is not None:
            _validate_product_name(product_name)
            mdf = mdf[mdf['product_name'] == product_name].copy()

        elif keywords is not None:
            mdf = _filter_manifest_by_keyword(mdf, keywords)
            if mdf.empty:
                return mdf

        if iso3_codes is not None:
            _validate_isos(iso3_codes)
            mdf = mdf[mdf['iso3'].isin(iso3_codes)].copy()

        # Only filter by years if years is NOT None and NOT 'all'.
        # If years is 'all', we implicitly select all years (no filter).
        if years is not None and years != 'all':
            _validate_years(years)
            mdf = mdf[mdf['year'].isin(years)].copy()

        # Note: We apply static/multi-year filters AFTER explicit year filters.
        if static_only:
            mdf = mdf[mdf['multi_year'] == False].copy()
        elif multi_year_only:
            mdf = mdf[mdf['multi_year'] == True].copy()

        if mdf.empty:
            return mdf

        return mdf


def wp_manifest_constrained(product_name, iso3_codes, years=None):
    """
    A strict wrapper for `wp_manifest` that validates a specific download request.

    This function is NOT for data discovery. Its purpose is to validate that a
    download request is unambiguous and that all requested data is available,
    based on the WorldPopPy manifest.

    Parameters
    ----------
    product_name : str
        The exact name of the WorldPop product of interest.
    iso3_codes : str or List[str]
         One or more three-letter ISO codes indicating the countries
         of interest.
    years : int, List[Union[int, str]], or str, optional
        The specific year(s) of interest.

        - If years are provided, validates availability for those specific years.
          (Supports lists mixed with keywords, e.g. ``[2015, 'last']``).
        - If 'all': Checks availability for *every* year recorded in the manifest.
        - If 'first': Checks availability for the earliest year.
        - If 'last': Checks availability for the most recent year.
        - If None, validates that the product is static and has no year dimension.

    Returns
    -------
    pandas.DataFrame
        The filtered manifest, if the request is valid.

    Raises
    ------
    ValueError
        If the request is flawed (e.g., missing `years` for a multi-year product)
        or if data is not available for all requested countries and/or years.
    """

    # --- Handle user arguments ---
    # Resolve years='all'/'first'/'last' immediately
    # This translates 'all' -> [2000, 2001...] or None, allowing the
    # strict validation logic below to proceed unchanged.
    years = resolve_product_years(product_name, years)

    if isinstance(iso3_codes, str):
        iso3_codes = [iso3_codes]
    if isinstance(years, int):
        years = [years]

    requested_years = set(years) if years else set()
    target_iso_set = set(iso3_codes)

    # Get the "ground truth" for the product
    info = get_product_info(product_name)
    available_years,available_isos = info['years'], info['iso3_codes']
    is_multi_year = info['is_multi_year']

    # Check available countries
    if unknown_isos := target_iso_set - available_isos:
        raise ValueError(
            f"Product '{product_name}' is not available for all requested countries. "
            f"Invalid: {unknown_isos}. (Available for {len(available_isos)} countries)."
        )

    # --- Check available time and assign final_query_years ---
    # Placeholder for the final, validated years to be used in the query
    final_query_years = None  # noqa

    if is_multi_year:
        # Product is multi-year, so `years` is ambiguous and required
        if not years:
            raise ValueError(
                f"Product '{product_name}' is multi-year. You must provide `years`. "
                f"Available: {sorted(available_years)}"
            )

        # Check against the set of available years
        if unknown_years := requested_years - available_years:
            raise ValueError(
                f"Product '{product_name}' is not available for all requested years. "
                f"Invalid: {unknown_years}. Available: {sorted(available_years)}"
            )

        final_query_years = requested_years

    else:
        # Product is static, so `years` is unambiguous
        if not available_years:
            # Static product with no recorded year
            if requested_years:
                raise ValueError(
                    f"Product '{product_name}' is static and has no year. "
                    "`years` must be None."
                )
            final_query_years = None  # This handles the year.isnull() case

        else:
            # Static product with a single recorded year
            single_year = list(available_years)[0]

            if requested_years:  # user has passed `years`
                if requested_years != {single_year}:
                    raise ValueError(
                        f"Product '{product_name}' is static, only available for "
                        f"year {single_year}. You requested {sorted(requested_years)}."
                    )

            # The year is either validated (if provided) or inferred (if None provided)
            final_query_years = {single_year}

    # --- Load full manifest ---
    mdf = _get_cleaned_manifest()

    # --- Build query ---
    query_parts = ["product_name == @product_name", "iso3 in @target_iso_set"]

    if final_query_years:
        query_parts.append("year in @final_query_years")
    else:
        query_parts.append("year.isnull()")

    final_query = " & ".join(query_parts)
    filtered_mdf = mdf.query(final_query)

    # --- Check available *combinations* of countries and years ---
    num_expected = len(target_iso_set)
    if final_query_years:
        num_expected *= len(final_query_years)

    if len(filtered_mdf) != num_expected:
        # Argument logic was valid, but the data is sparse
        raise ValueError(
            f"Incomplete data. Product '{product_name}' is not available for "
            f"all requested country-year combinations. Expected {num_expected} files, "
            f"found {len(filtered_mdf)}. Please use `wp_manifest` to explore availability."
        )

    return filtered_mdf


def show_supported_data_products(
    iso3_codes=None, years=None, keywords=None, static_only=False
):
    """
    Display supported WorldPop data products, with optional filtering.

    Parameters
    ----------
    iso3_codes : str or List[str], optional
        One or more three-letter ISO codes indicating the countries for which to
        show supported data products.
    years : int or List[int] or str, optional
        For annual data products, either one or more years (int or List[int]) for
        which to show results, or the 'all' keyword (str).

        - If specific years are provided, products are filtered to match those years.
        - If 'all' or None is provided, all products (including static ones) are considered.

    keywords : str or List[str], optional
        A single search term (str) or a list of search terms.
        If None or empty, the original DataFrame is returned.
    static_only : bool, optional
        If True, only static data products will be shown.

    Returns
    -------
    None
        This function prints to the console or notebook.
    """
    try:
        from IPython.display import display, HTML

        _likely_notebook = 'ipykernel' in sys.modules
    except ImportError:
        _likely_notebook = False

    if static_only and years is not None:
        raise ValueError("You cannot provide `years` when `static_only` is True.")

    ts = RAW_MANIFEST_CACHE_PATH.stat().st_mtime
    dt = datetime.fromtimestamp(ts)
    last_update_str = dt.strftime('%Y-%m-%d %H:%M:%S')
    print(f"Manifest data was last updated on: {last_update_str}.\n")

    mdf = wp_manifest(
        iso3_codes=iso3_codes,
        years=years,
        keywords=keywords,
    )

    if static_only:
        mdf = mdf[mdf['multi_year'] == False].copy()

    if mdf.empty:
        print("No data products found matching the specified filters.")
        return

    if any([iso3_codes, years, keywords]):
        print("Showing unique products matching filters:\n")

    # --- Aggregation Logic for Resolutions ---
    def _format_resolution_info(pd_series):
        # 1. Separate valid resolutions and NaNs
        uniq_vals = pd_series.unique()
        valid_nums = sorted([x for x in uniq_vals if pd.notna(x)])
        has_nan = any(pd.isna(x) for x in uniq_vals)

        # 2. Format resolution numbers: remove decimal point if integer (e.g. 3.0 -> "3")
        fmt_list = [str(int(x)) if x == int(x) else str(x) for x in valid_nums]

        # 3. Append "NaN" at summary if it existed
        if has_nan:
            fmt_list.append("NaN")

        return ", ".join(fmt_list)

    # Apply the resolution formatting
    # product_name -> "3", "3, 30", or "3, NaN"
    res_map = mdf.groupby('product_name')['arcsecs'].apply(_format_resolution_info)
    mdf['resolution'] = mdf['product_name'].map(res_map)

    # --- Select and clean-up columns for display ---
    cols = 'product_name product_notes resolution multi_year api_project data_series summary_url'.split()

    products = mdf[cols].drop_duplicates(subset='product_name')
    products.rename(
        columns={
            'product_name': 'Product name',
            'product_notes': 'Product notes',
            'resolution': 'Res. (arcsec)',
            'multi_year': 'Multi-year?',
            'api_project': 'Project',
            'data_series': 'Data series',
            'summary_url': 'Example',
        },
        inplace=True,
    )
    products = products.set_index('Product name').sort_index()

    if _likely_notebook:
        # Create the base styler
        styled = products.style.set_properties(
            **{'text-align': 'left', 'white-space': 'pre-wrap'}
        )
        styled = styled.set_table_styles(
            [dict(selector='th', props=[('text-align', 'left')])]
        )

        if DEBUG:
            # format the 'summary_url'
            styled = styled.format({"Example": format_url_to_emoji})
        else:
            # drop the 'summary_url'
            products.drop('Example', axis=1, inplace=True)
        display(styled)
    else:
        # always drop the 'summary_url' in console display
        products.drop('Example', axis=1, inplace=True)
        try:
            from tabulate import tabulate

            print(tabulate(products, headers='keys', tablefmt='psql'))
        except ImportError:
            print(products)


@lru_cache(maxsize=1)
def _get_cleaned_manifest():
    """
    Wrapper around `_get_raw_manifest` which performs data cleaning
    and validation.

    This function returns the *final*, user-facing manifest for the
    `worldpoppy` package.
    """

    # --- Ingest raw manifest ---
    mdf = _get_raw_manifest()

    # Try to enforce correct, nullable data type
    try:
        mdf["year"] = mdf["year"].astype("Int64")
    except Exception as e:
        logger.error(f"Failed to cast manifest dtypes: {e}")
        # log and continue, since this is not a fatal error

    # --- Assign product names ---
    # 1. Extract last part (slug) of the full API path
    mdf['api_slug'] = mdf.api_path.str.split('/').apply(lambda arr: arr[-1])

    # 2. Assign curated base-names to all API slugs
    mdf['base_name'] = mdf['api_slug'].map(PRODUCT_BASE_NAME_MAP)

    # 3. Map band names for ESA land-cover data to human-readable aliases
    mdf['band_alias'] = mdf.band.map(ESA_LAND_COVER_ALIAS_MAP)

    # 4. Concatenate
    #    a. Start by setting the product_name to the base_name
    mdf['product_name'] = mdf['base_name']

    #    b. Find all rows that have a valid 'band_alias'
    banded_rows = mdf['band_alias'].notna()

    #    c. For *only* those rows, concatenate the final name
    #       e.g., 'dist_esalc_g1' + '_' + 'cultivated'
    mdf.loc[banded_rows, 'product_name'] = \
        mdf['base_name'] + '_' + mdf['band_alias']

    # 5. Apply fallbacks
    #    If any product failed mapping (base_name is NaN), use its API slug
    mdf['product_name'] = mdf['product_name'].fillna(mdf['api_slug'])

    # --- Assign short, curated product notes ---
    # (Used in `show_supported_data_products`)
    notes_lookup = _build_final_notes_map(mdf)
    mdf['product_notes'] = mdf['product_name'].map(notes_lookup)

    # --- Mark multi-year products ---
    num_years = mdf.groupby(['product_name', 'iso3']).year.transform('nunique')
    mdf['multi_year'] = num_years > 1

    # --- Check for mixed time-types ---
    #  a. Ensure that datasets recorded under the same
    #     product are either all multi_year or all static.
    ttype_by_prod = mdf.groupby('product_name').multi_year
    mixed_ttypes = ttype_by_prod.nunique() > 1
    bad_prod_names = list(mixed_ttypes[mixed_ttypes].index)
    for name in bad_prod_names:
        logger.warning(f"Dropping data for product '{name}' due to mixed time types.")
        mdf = mdf[mdf.product_name != name].copy()

    #  b. Ensure that datasets recorded under the same *static*
    #     product either all have the same year or pd.NA (but no mix)
    static_mdf = mdf[mdf.multi_year==False]
    year_by_prod = static_mdf.groupby('product_name').year
    mixed_vals = year_by_prod.unique().apply(len) > 1  # this is correct for pd.NA
    bad_prod_names = list(mixed_vals[mixed_vals].index)
    for name in bad_prod_names:
        logger.warning(f"Dropping data for static product '{name}' due to mixed year values.")
        mdf = mdf[mdf.product_name != name].copy()

    # --- Infer data series and apparent raster resolution ---
    mdf["data_series"] = mdf.remote_path.apply(infer_data_series)
    mdf['arcsecs'] = mdf.api_series_desc.apply(infer_resolution_from_description)

    # --- Validate & clean-up ---
    # Check remaining manifest data
    _validate_manifest(mdf)

    # --- MISSING CONFIG WARNINGS ---
    # We run this at the very end to catch new API content.
    _check_missing_config(mdf)

    # --- Clean Columns ---
    # Drop processing columns that are not needed
    drop_cols = "base_name band band_alias".split()
    mdf.drop(drop_cols, axis=1, inplace=True)

    # Re-order columns
    maj_cols = [
        "wpy_id",
        "product_name",
        "iso3",
        "year",
        "multi_year",
        "product_notes",
        "data_series",
        "arcsecs",
        "dataset_name",
        "remote_path",
        "remote_name",
        "summary_url",
        "api_path",
        "api_slug",
        "api_entry_title",
        "api_project",
        "api_series_category",
        "api_series_desc",
        "api_source",
    ]

    # Account for additional columns that might be present
    other_cols = sorted([col for col in mdf.columns if col not in maj_cols])
    mdf = mdf.reindex(columns=maj_cols + other_cols)

    return mdf


def _get_raw_manifest():
    """
    [TODO]

    Thin wrapper around `build_raw_manifest_from_api`.
    """

    # trigger a re-crawl and r-processing if the cache is empty
    build_raw_manifest_from_api(force_rebuild=False)

    if not RAW_MANIFEST_CACHE_PATH.is_file():
        raise FileNotFoundError(
            "Fatal error: No API crawl results found on disk. "
            "Please check your internet connection and permissions. "
            f"Expected at: {RAW_MANIFEST_CACHE_PATH}"
        )

    raw_mdf = pd.read_feather(RAW_MANIFEST_CACHE_PATH)
    return raw_mdf


def _filter_manifest_by_keyword(mdf, keywords=None):
    """
    Filter a manifest DataFrame by one or more keywords.

    This performs a two-level, case-insensitive search:

    1.  **Inner Logic (OR):** For each *individual* keyword, it searches
        across all human-readable text columns. A match is found if the
        keyword appears in *any* of those columns.
    2.  **Outer Logic (AND):** The function only returns rows that are a
        match for *all* keywords provided.

    For example, `keywords=['population', 'global1']` will find all rows that
    contain 'population' (in any matched field) AND 'global1' (in any matched
    field).

    Parameters
    ----------
    mdf : pandas.DataFrame
        The manifest DataFrame to filter.
    keywords : str or List[str], optional
        A single search term (str) or a list of search terms.
        If None or empty, the original DataFrame is returned.

    Returns
    -------
    pandas.DataFrame
        The filtered manifest DataFrame. May be empty if no matches are found.
    """

    if not keywords:
        return mdf

    # --- Normalise keywords input ---
    if isinstance(keywords, str):
        keywords_list = [keywords]
    else:
        keywords_list = list(keywords)

    # clean the list, just in case
    keywords_list = [k.lower() for k in keywords_list if k and isinstance(k, str)]

    if not keywords_list:
        return mdf

    # --- Search using a two-level (AND / OR) logic  ---
    SEARCH_COLUMNS = [
        'product_name',
        'product_notes',
        'api_project',
        'data_series',
    ]

    # Start with an all-True mask. We will "AND" this
    # with the result for each keyword.
    final_mask = pd.Series(True, index=mdf.index)

    # "Outer" loop: (AND logic)
    # We must find a match for *every* keyword.
    for kw in keywords_list:

        # "Inner" loop: (OR logic)
        # Start with an all-False mask for this *one* keyword.
        # We only need to find it in *one* column.
        keyword_mask = pd.Series(False, index=mdf.index)

        for col in SEARCH_COLUMNS:
            if col in mdf.columns:
                # astype(str) robustly handles NaNs, Nones, or numbers
                col_contains_kw = mdf[col].astype(str).str.lower().str.contains(kw)
                keyword_mask = keyword_mask | col_contains_kw

        # Now, AND the result for this keyword with our final mask
        final_mask = final_mask & keyword_mask

    return mdf[final_mask]


# --- Manifest-dependent helper functions ---

@lru_cache()
def get_product_info(product_name):
    """
    Retrieve coverage and type information for a specific data product.

    This function queries the manifest to determine if a product is part of a
    multi-year time series and returns the sets of available years and
    countries (ISO3 codes).

    Parameters
    ----------
    product_name : str
        The exact, curated name of the data product to query (e.g., 'pop_g1').

    Returns
    -------
    dict
        A dictionary containing the following keys:

        - **is_multi_year** (bool):
          True if the product is a multi-year time series, False otherwise.

        - **years** (set[int]):
          A set of all unique years (non-nullable integers) for which this
          product has data. For static products, this set may be empty or
          contain a single year (the year of data recording).

        - **iso3_codes** (set[str]):
          A set of all unique ISO3 codes indicating the countries for which
          this product has data.

    Note
    ----
    This function returns the *union* of all available years and countries.
    It does *not* guarantee that data exists for every combination of
    year and country (i.e., the data matrix may be sparse).
    """
    _validate_product_name(product_name)

    mdf = _get_cleaned_manifest()
    mdf_prod = mdf[mdf.product_name == product_name]

    info = dict(
        # We can trust the results below since "mixed-type"
        # products are already filtered out by get_wp_manifest
        years=set(mdf_prod['year'].dropna().astype(int)),
        iso3_codes=set(mdf_prod['iso3'].dropna()),
        is_multi_year=mdf_prod.iloc[0]['multi_year']
    )

    return info


@lru_cache()
def get_all_isos():
    """
    Gets all unique ISO3 codes from the manifest.
    """
    mdf = _get_cleaned_manifest()
    return sorted(mdf["iso3"].dropna().unique())


@lru_cache()
def get_all_years():
    """
    Gets all unique years from the manifest.
    """
    mdf = _get_cleaned_manifest()
    return sorted(mdf["year"].dropna().unique())


@lru_cache()
def get_all_product_names():
    """
    Gets all unique product names from the manifest.
    """
    mdf = _get_cleaned_manifest()
    return sorted(mdf["product_name"].dropna().unique())


@lru_cache()
def get_all_dataset_names():
    """
    Gets all unique dataset names (filename stems) from the manifest.
    """
    uniq = _get_cleaned_manifest()['dataset_name'].dropna().unique()
    return sorted(uniq)


@lru_cache()
def get_static_product_names():
    """
    Gets all unique static product names from the manifest.
    """
    mdf = _get_cleaned_manifest()
    uniq = set(mdf[~mdf.multi_year]['product_name'])
    return sorted(uniq)


@lru_cache()
def get_multi_year_product_names():
    """
    Gets all unique muli-year product names from the manifest.
    """
    mdf = _get_cleaned_manifest()
    uniq = set(mdf[mdf.multi_year]['product_name'])
    return sorted(uniq)


def resolve_product_years(product_name, years):
    """
    Resolve a user's 'years' argument (including keywords) into a concrete list
    of years or None, consistent with the worldpoppy manifest.

    Logic:

    - If years is None: Return None.
    - If years is 'all':
        - Multi-year product: Return all available years (List[int]).
        - Static product (no year): Return None.
    - If years is a list/tuple (e.g. [2010, 'last']):
        - Resolves integers as-is.
        - Resolves 'first'/'last' to concrete years.
        - Returns a sorted, unique list of integers.
    - If years is a single int or 'first'/'last': Treated as a list of length 1.

    Parameters
    ----------
    product_name : str
        The exact name of the WorldPop product.
    years : int, List[Union[int, str]], str or None
        The years argument to resolve. Supports integers and keywords
        ('all', 'first', 'last').

    Returns
    -------
    List[int] or None
        The concrete list of years for the downloader, or None for static
        products without a recorded year.
    """
    if years is None:
        return None

    # 1. Normalise input to a list
    if isinstance(years, (int, str)):
        input_list = [years]
    else:
        input_list = list(years)

    # 2. Check for 'all' (Special Case)
    # If 'all' is present anywhere, it overrides specific requests.
    if 'all' in input_list:
        # We need manifest info to resolve 'all'
        info = get_product_info(product_name)
        available_years = info['years']

        if not available_years:
            # Static product -> None
            return None
        return sorted(list(available_years))

    # 3. Check if we have any keywords that require manifest lookup
    has_keywords = any(isinstance(y, str) for y in input_list)

    if not has_keywords:
        # Optimisation: If list is all ints, return sorted/unique immediately
        # without querying the manifest (validation happens downstream).
        return sorted(list(set(input_list)))

    # 4. Resolve Keywords
    info = get_product_info(product_name)
    available_years = info['years']

    # Handle Yearless/Static products requested with specific keywords
    if not available_years:
        raise ValueError(
            f"Product '{product_name}' is not linked to any year. "
            f"Cannot resolve keywords in {input_list}."
        )

    sorted_avail = sorted(list(available_years))
    resolved_set = set()

    for y in input_list:
        if isinstance(y, int):
            resolved_set.add(y)
        elif y == 'first':
            resolved_set.add(sorted_avail[0])
        elif y == 'last':
            resolved_set.add(sorted_avail[-1])
        else:
            raise ValueError(f"Invalid year argument: '{y}'")

    return sorted(list(resolved_set))


def _build_final_notes_map(mdf):
    """
    Build the final `quick_notes` map from two sources.

    It merges:

    1. For NON-BANDED products: Uses the `PRODUCT_NOTES_MAP`.
    2. For BANDED products: Uses the `ESA_LAND_COVER_DESC_MAP`.

    This provides a single, clean note for every unique product_name.
    """
    final_notes = {}

    # 1. Handle BANDED products first
    # The note for a banded product *is* its band description.
    band_mask = pd.isnull(mdf.band_alias)==False
    banded_df = mdf[band_mask]
    if not banded_df.empty:
        banded_names = banded_df.drop_duplicates('product_name').set_index(
            'product_name'
        )['band']

        final_notes.update(banded_names.map(ESA_LAND_COVER_DESC_MAP).to_dict())

    # 2. Handle NON-BANDED products
    non_banded_df = mdf[~band_mask]
    if not non_banded_df.empty:
        # We need to map product_name -> api_slug
        non_banded_lookup = non_banded_df.drop_duplicates('product_name').set_index(
            'product_name'
        )['api_slug']
        # Now map api_slug -> raw quick note
        non_banded_notes = non_banded_lookup.map(PRODUCT_NOTES_MAP)
        final_notes.update(non_banded_notes.to_dict())

    return final_notes


def _check_missing_config(mdf):
    """
    Check for WorldPop data series that are missing configurations in the
    product_definitions.toml file.

    Note: This function is primarily for the package maintainer to identify
    new data series released by WorldPop that need curation.
    """
    def _warn_if_missing(items, context_msg):
        if len(items) > 0:
            unique_items = sorted(list(set(items)))
            logger.warning(
                f"CONFIG WARNING: Found {len(unique_items)} {context_msg} "
                f"in product_definitions.toml.\n"
                f"Missing: {unique_items}"
            )

    # Check for missing Base Names
    # Rows where the base_name column is NaN (meaning the map lookup failed)
    missing_slugs = mdf.loc[mdf['base_name'].isna(), 'api_slug']
    _warn_if_missing(
        missing_slugs, "data series without a curated 'base_name'"
    )

    # Check for missing Band Aliases
    # Rows that *have* a band ID but failed to map to an alias
    missing_aliases = mdf.loc[mdf['band'].notna() & mdf['band_alias'].isna(), 'band']
    _warn_if_missing(
        missing_aliases, "bands without a 'band_alias'"
    )

    # Check for missing Band Descriptions
    # This requires checking the keys of the description map directly,
    # as the description is not stored in the DataFrame.
    all_bands = set(mdf['band'].dropna())
    defined_descriptions = set(ESA_LAND_COVER_DESC_MAP.keys())
    missing_descriptions = all_bands - defined_descriptions
    _warn_if_missing(
        missing_descriptions, "bands without a 'band_description'"
    )

    # Check for missing Product Notes
    # We only check products that HAVE a valid base_name to avoid redundant noise.
    valid_base = mdf['base_name'].notna()
    missing_notes = mdf.loc[mdf['product_notes'].isna() & valid_base, 'product_name']
    _warn_if_missing(
        missing_notes,
        "products without a description in 'product_notes'"
    )


def _validate_manifest(mdf):
    # --- FATAL ERRORS ---
    if mdf["remote_path"].isnull().any() or mdf["remote_name"].isnull().any():
        raise ManifestValidationError(
            "Fatal: Manifest contains rows with missing remote file paths/names."
        )

    if mdf.duplicated(["dataset_name", "iso3"]).any():
        raise ManifestValidationError(
            "Fatal: Manifest contains duplicated dataset names at the country level."
        )

    if mdf['wpy_id'].duplicated().any():
        raise ManifestValidationError(
            "Fatal: Manifest contains duplicated 'wpy_id' (`worldpoppy` IDs). "
            "This should be a unique primary key."
        )

    prod_check1 = np.all(mdf.groupby('product_name').data_series.nunique() == 1)
    prod_check2 = np.all(mdf.groupby('product_name').api_project.nunique() == 1)

    if not (prod_check1 & prod_check2):
        raise ManifestValidationError(
            "Fatal: Each `worldpoppy` product name should be associated with "
            "one product type (e.g., 'global1') and one 'project' category (e.g., 'Covariates')."
        )

    # --- NON-FATAL WARNINGS ---
    # Check inferred resolution
    # If arcsecs is NaN, our regex failed to parse the description.
    if mdf['arcsecs'].isna().any():
        bad_prods = mdf.loc[mdf['arcsecs'].isna(), 'product_name'].unique()
        logger.warning(
            f"MANIFEST QUALITY: Could not infer resolution (arcsecs) for {len(bad_prods)} "
            f"products. Check regex in `infer_resolution_from_description`. "
            f"Products: {sorted(bad_prods)[:5]}..."
        )

    # Check inferred data series
    # If data_series is 'unknown', our URL matching failed.
    if (mdf['data_series'] == 'unknown').any():
        bad_prods = mdf.loc[mdf['data_series'] == 'unknown', 'product_name'].unique()
        logger.warning(
            f"MANIFEST QUALITY: Could not infer 'data_series' (Global 1 vs 2) for "
            f"{len(bad_prods)} products. Check `infer_data_series`. "
            f"Products: {sorted(bad_prods)[:5]}..."
        )

    # Check raw API metadata
    # If these are null, WorldPop might have changed their API structure.
    if mdf['api_project'].isna().any() or mdf['api_series_desc'].isna().any():
        logger.warning(
            "MANIFEST QUALITY: Some rows are missing 'project' or 'api_series_desc'. "
            "The WorldPop API structure may have changed."
        )


def _validate_product_name(product_name):
    if product_name not in get_all_product_names():
        raise ValueError(
            f"Product '{product_name}' not found. Use "
            "`show_supported_data_products()` for details."  # TODO
        )


def _validate_isos(iso3_codes):
    """
    Validate a list of ISO codes against the manifest.
    """
    if unknown_isos := set(iso3_codes) - set(get_all_isos()):
        raise ValueError(
            f"Country code(s) not supported: {unknown_isos}. "
            f'You can list all supported country codes as follows:\n\n'
            f'>>> from worldpoppy.manifest_new import get_all_isos\n'
            f'>>> print(get_all_isos())'
        )


def _validate_years(years):
    """
    Validate a list of years against the manifest.
    """
    available_years = set(get_all_years())
    if unknown_years := set(years) - available_years:
        raise ValueError(
            f'No supported data for the following years: '
            f'{unknown_years}. You can list the years for which supported data is '
            f'available follows:\n\n'
            f'>>> from worldpoppy.manifest_new import get_all_years\n'
            f'>>> print(get_all_years())'
        )
