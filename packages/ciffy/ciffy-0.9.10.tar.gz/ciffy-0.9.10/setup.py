"""
Setup script for ciffy C extension.

Metadata is defined in pyproject.toml. This file only handles:
1. C extension compilation
2. Hash table generation before build (downloads CCD if needed)

For CUDA support, see setup_cuda.py which must be run separately:
    pip install -e .                              # builds C extension
    python setup_cuda.py build_ext --inplace      # builds CUDA extension
"""

from setuptools import setup, Extension
from setuptools.command.build_ext import build_ext
from setuptools.command.sdist import sdist
import os
import sys
import subprocess
import shutil
import gzip
import numpy


# URL for the PDB Chemical Component Dictionary
CCD_URL = "https://files.wwpdb.org/pub/pdb/data/monomers/components.cif.gz"


def download_ccd(dest_path):
    """Download and decompress the CCD file."""
    import urllib.request

    print(f"Downloading CCD from {CCD_URL}...")
    gz_path = dest_path + ".gz"

    try:
        urllib.request.urlretrieve(CCD_URL, gz_path)
        print("Decompressing CCD...")
        with gzip.open(gz_path, 'rb') as f_in:
            with open(dest_path, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)
        os.remove(gz_path)
        print(f"CCD downloaded to {dest_path}")
        return True
    except Exception as e:
        print(f"Failed to download CCD: {e}")
        if os.path.exists(gz_path):
            os.remove(gz_path)
        return False


def get_ccd_path():
    """Get path to CCD file, downloading if necessary."""
    # Check environment variable first
    ccd_path = os.environ.get("CIFFY_CCD_PATH")
    if ccd_path and os.path.exists(ccd_path):
        return ccd_path

    # Use centralized cache location
    cache_dir = os.path.expanduser("~/.cache/ciffy")
    ccd_path = os.path.join(cache_dir, "components.cif")

    if os.path.exists(ccd_path):
        return ccd_path

    # Download to cache directory
    os.makedirs(cache_dir, exist_ok=True)
    if download_ccd(ccd_path):
        return ccd_path

    return None


def generate_hash_tables(force=False):
    """Run the hash table generator.

    Args:
        force: If True, regenerate even if files exist (for sdist builds)
    """
    hash_dir = os.path.join(os.path.dirname(__file__), 'ciffy', 'src', 'hash')
    biochem_dir = os.path.join(os.path.dirname(__file__), 'ciffy', 'biochemistry')

    # All files generated by codegen/generate.py
    required_hash_files = [
        'atom.c', 'element.c', 'entity.c', 'ion.c', 'molecule.c', 'residue.c', 'reverse.h'
    ]
    required_python_files = [
        '_generated_atoms.py', '_generated_dihedrals.py', '_generated_elements.py',
        '_generated_residues.py', '_generated_zmatrix.py'
    ]

    def check_generated_files_exist():
        """Check if all required generated files exist."""
        hash_ok = all(os.path.exists(os.path.join(hash_dir, f)) for f in required_hash_files)
        python_ok = all(os.path.exists(os.path.join(biochem_dir, f)) for f in required_python_files)
        return hash_ok and python_ok

    def get_missing_files():
        """Get list of missing generated files."""
        missing = []
        for f in required_hash_files:
            if not os.path.exists(os.path.join(hash_dir, f)):
                missing.append(f'src/hash/{f}')
        for f in required_python_files:
            if not os.path.exists(os.path.join(biochem_dir, f)):
                missing.append(f'biochemistry/{f}')
        return missing

    codegen_dir = os.path.join(os.path.dirname(__file__), 'codegen')
    if not os.path.exists(codegen_dir):
        print("Warning: codegen package not found, skipping hash generation")
        return

    # Check if generated files already exist (users installing from PyPI)
    if check_generated_files_exist() and not force:
        print("Using pre-generated files")
        return

    # Need to generate - get CCD file
    ccd_path = get_ccd_path()
    if not ccd_path:
        if check_generated_files_exist():
            print("Warning: CCD not available, using existing generated files")
            return
        else:
            print("ERROR: CCD file required but not found. Set CIFFY_CCD_PATH or download from:")
            print(f"  {CCD_URL}")
            return

    # Check if gperf is available (need 3.1+ for constants-prefix)
    gperf_path = None
    for path in ["/opt/homebrew/bin/gperf", "/usr/local/bin/gperf"]:
        if os.path.exists(path):
            gperf_path = path
            break
    if gperf_path is None:
        gperf_path = shutil.which("gperf")

    args = [ccd_path]
    if gperf_path is None:
        # gperf not found - check if pre-generated files exist
        if check_generated_files_exist():
            print("Warning: gperf not found, using pre-generated files")
            return
        else:
            # Fatal error - can't build without gperf or pre-generated files
            missing = get_missing_files()
            print("\n" + "=" * 70)
            print("ERROR: Cannot build ciffy - gperf is required but not installed")
            print("=" * 70)
            print("\nThe C extension requires generated files that are created using gperf.")
            print("Pre-generated files are not available.")
            print(f"\nMissing files ({len(missing)}):")
            for f in missing[:10]:  # Show first 10
                print(f"  - {f}")
            if len(missing) > 10:
                print(f"  ... and {len(missing) - 10} more")
            print("\nTo fix this, install gperf:")
            print("  - Ubuntu/Debian: sudo apt install gperf")
            print("  - Fedora/RHEL:   sudo dnf install gperf")
            print("  - macOS:         brew install gperf")
            print("  - Conda:         conda install -c conda-forge gperf")
            print("\nThen re-run: pip install -e .")
            print("=" * 70 + "\n")
            sys.exit(1)
    else:
        args.extend(["--gperf-path", gperf_path])

    print("Generating hash lookup tables...")
    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.dirname(__file__)

    # Run as module to support relative imports
    result = subprocess.run(
        [sys.executable, "-m", "codegen.generate"] + args,
        env=env,
        cwd=os.path.dirname(__file__),
        capture_output=True,
        text=True
    )

    if result.returncode != 0:
        print(f"Warning: Hash generation failed: {result.stderr}")
    else:
        print(result.stdout)

    # Final check - ensure all generated files were created
    if not check_generated_files_exist():
        missing = get_missing_files()
        print("\n" + "=" * 70)
        print("ERROR: Code generation failed")
        print("=" * 70)
        print(f"\nMissing files ({len(missing)}):")
        for f in missing:
            print(f"  - {f}")
        print("\nThis usually means gperf failed. Check that gperf is installed correctly:")
        print("  gperf --version")
        print("=" * 70 + "\n")
        sys.exit(1)


class GenerateAndBuildExt(build_ext):
    """Custom build_ext that generates hash tables before compiling."""

    def run(self):
        generate_hash_tables(force=False)
        super().run()

        # On macOS, fix up libomp linkage to use @rpath instead of absolute path
        # This avoids conflicts when PyTorch (with its own libomp) is also loaded
        if sys.platform == 'darwin':
            self._fix_libomp_rpath()

    def _fix_libomp_rpath(self):
        """Change libomp reference from absolute path to @rpath on macOS."""
        for ext in self.extensions:
            ext_path = self.get_ext_fullpath(ext.name)
            if not os.path.exists(ext_path):
                continue

            # Check if this extension links against libomp
            try:
                result = subprocess.run(
                    ['otool', '-L', ext_path],
                    capture_output=True, text=True, timeout=10
                )
                if '/libomp.dylib' not in result.stdout:
                    continue

                # Find the absolute path to libomp
                for line in result.stdout.split('\n'):
                    if '/libomp.dylib' in line and '@rpath' not in line:
                        # Extract the path (first part before ' (')
                        old_path = line.strip().split(' (')[0]
                        if old_path:
                            print(f"Fixing libomp linkage: {old_path} -> @rpath/libomp.dylib")
                            subprocess.run(
                                ['install_name_tool', '-change', old_path,
                                 '@rpath/libomp.dylib', ext_path],
                                capture_output=True, timeout=10
                            )
                            break
            except Exception as e:
                print(f"Warning: Could not fix libomp rpath: {e}")


class GenerateAndSdist(sdist):
    """Custom sdist that ensures hash tables are generated before packaging."""

    def run(self):
        # Force regeneration for sdist to ensure latest definitions
        generate_hash_tables(force=True)
        super().run()


# ============================================================================
# Compiler configuration
# ============================================================================

def check_openmp_available():
    """
    Check if OpenMP is available by trying to compile a simple test program.

    Returns:
        Tuple of (compile_args, link_args) or (None, None) if not available
    """
    import tempfile

    if sys.platform == 'darwin':
        # macOS: need libomp from Homebrew
        compile_args = ['-Xpreprocessor', '-fopenmp']
        link_args = ['-lomp']

        # Find libomp
        for libomp_path in ['/opt/homebrew/opt/libomp/lib', '/usr/local/opt/libomp/lib']:
            if os.path.exists(libomp_path):
                link_args.append(f'-L{libomp_path}')
                include_path = libomp_path.replace('/lib', '/include')
                if os.path.exists(include_path):
                    compile_args.append(f'-I{include_path}')
                break
        else:
            # libomp not found
            return None, None
    else:
        # Linux/Windows
        compile_args = ['-fopenmp']
        link_args = ['-fopenmp']

    # Try to compile a test program
    test_code = '#include <omp.h>\nint main() { return omp_get_num_threads(); }'
    try:
        with tempfile.NamedTemporaryFile(mode='w', suffix='.c', delete=False) as f:
            f.write(test_code)
            test_file = f.name

        import sysconfig
        cc = os.environ.get('CC', sysconfig.get_config_var('CC') or 'cc')
        # Handle cases where CC might be "cc -pthread" etc.
        cc = cc.split()[0]

        result = subprocess.run(
            [cc] + compile_args + [test_file, '-o', '/dev/null'] + link_args,
            capture_output=True,
            timeout=30
        )
        os.unlink(test_file)
        if result.returncode == 0:
            return compile_args, link_args
    except Exception:
        pass

    return None, None


# Build compile args
extra_compile_args = ['-O3']
extra_link_args = []

# Enable profiling if CIFFY_PROFILE environment variable is set
if os.environ.get('CIFFY_PROFILE', '').lower() in ('1', 'true', 'yes'):
    extra_compile_args.append('-DCIFFY_PROFILE')
    print("Profiling enabled: building with -DCIFFY_PROFILE")

# Enable OpenMP unless CIFFY_NO_OPENMP is set
if os.environ.get('CIFFY_NO_OPENMP', '').lower() not in ('1', 'true', 'yes'):
    omp_compile, omp_link = check_openmp_available()
    if omp_compile and omp_link:
        extra_compile_args.extend(omp_compile)
        extra_link_args.extend(omp_link)

        # On macOS, use @rpath linking to avoid conflicts with PyTorch's bundled libomp
        # This allows the runtime linker to find libomp from either:
        # 1. PyTorch's lib directory (if torch is imported)
        # 2. Homebrew's libomp (fallback)
        if sys.platform == 'darwin':
            # Add header padding for install_name_tool modifications
            extra_link_args.append('-Wl,-headerpad_max_install_names')

            # Add rpaths for libomp discovery
            # PyTorch's lib directory (try to detect)
            try:
                import torch
                torch_lib = os.path.join(os.path.dirname(torch.__file__), 'lib')
                if os.path.exists(torch_lib):
                    extra_link_args.append(f'-Wl,-rpath,{torch_lib}')
                    print(f"  Added rpath for PyTorch's libomp: {torch_lib}")
            except ImportError:
                pass

            # Homebrew libomp as fallback
            for libomp_path in ['/opt/homebrew/opt/libomp/lib', '/usr/local/opt/libomp/lib']:
                if os.path.exists(libomp_path):
                    extra_link_args.append(f'-Wl,-rpath,{libomp_path}')
                    break

        print("OpenMP enabled for parallel Z-matrix construction")
    else:
        print("OpenMP not available (install libomp on macOS: brew install libomp)")
        print("Building without OpenMP - Z-matrix construction will be single-threaded")
else:
    print("OpenMP disabled via CIFFY_NO_OPENMP")

# ============================================================================
# C extension module
# ============================================================================

c_sources = [
    'ciffy/src/module.c',
    'ciffy/src/pyutils.c',
    # CIF I/O module
    'ciffy/src/cif/io.c',
    'ciffy/src/cif/parser.c',
    'ciffy/src/cif/writer.c',
    'ciffy/src/cif/registry.c',
    # Internal coordinates C extension
    'ciffy/src/internal/geometry.c',
    'ciffy/src/internal/batch.c',
    'ciffy/src/internal/graph.c',
    'ciffy/src/internal/internal_module.c',
]

# Validate source files exist
missing_sources = [src for src in c_sources if not os.path.exists(src)]
if missing_sources:
    print(f"ERROR: Missing source files: {missing_sources}")
    print("Make sure you're building from the ciffy root directory.")
    sys.exit(1)

ext_module = Extension(
    name="ciffy._c",
    sources=c_sources,
    include_dirs=[numpy.get_include(), 'ciffy/src'],
    extra_compile_args=extra_compile_args,
    extra_link_args=extra_link_args,
    language='c',  # Explicitly specify C (not C++)
)

# ============================================================================
# Build extensions list
# ============================================================================

# The C extension is always built with standard setuptools
ext_modules = [ext_module]
cmdclass = {
    'build_ext': GenerateAndBuildExt,
    'sdist': GenerateAndSdist,
}

# CUDA extension is built separately via setup_cuda.py
# This avoids conflicts between setuptools C compiler and PyTorch's BuildExtension
# Users with CUDA should run:
#   pip install -e .                              # builds C extension
#   python setup_cuda.py build_ext --inplace      # builds CUDA extension

setup(
    ext_modules=ext_modules,
    cmdclass=cmdclass,
)
