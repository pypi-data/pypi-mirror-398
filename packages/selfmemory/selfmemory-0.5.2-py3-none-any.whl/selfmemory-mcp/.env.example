# SelfMemory MCP Server Configuration
# Unified configuration for both OAuth MCP server and API MCP server
# Copy this file to .env and configure for your deployment

# ====================================
# Core Configuration
# ====================================

# SelfMemory API Configuration
# Default: localhost for development
# Docker: http://selfmemory-server:8081
SELFMEMORY_API_HOST=http://127.0.0.1:8081

# MCP Server Configuration
MCP_SERVER_HOST=0.0.0.0
MCP_SERVER_PORT=5055

# ====================================
# MODE CONFIGURATION
# ====================================

# Set to true for Platform Mode (requires API key, MongoDB)
# Set to false for Open Source Mode (uses local Ollama, Qdrant)
SELFMEMORY_PLATFORM_MODE=false

# ====================================
# OAuth 2.1 Configuration (Required for OAuth MCP Server)
# ====================================

# Hydra OAuth URLs
HYDRA_ADMIN_URL=http://127.0.0.1:4445
HYDRA_PUBLIC_URL=http://127.0.0.1:4444
MCP_SERVER_URL=http://127.0.0.1:5055

# Kratos URLs (required by server package imports)
KRATOS_PUBLIC_URL=http://127.0.0.1:4433
KRATOS_ADMIN_URL=http://127.0.0.1:4434

# ====================================
# Platform Mode Settings (when SELFMEMORY_PLATFORM_MODE=true)
# ====================================

# MongoDB Configuration (Platform Mode)
# Default: localhost for development
# Docker: mongodb://mongo:27017/selfmemory
MONGODB_URI=mongodb://127.0.0.1:27017/selfmemory

# API Key for Platform Mode authentication
# SELFMEMORY_API_KEY=

# ====================================
# Open Source Mode Settings (when SELFMEMORY_PLATFORM_MODE=false)
# ====================================

# Ollama Configuration (Open Source Mode)
# Default: localhost for development
# Docker: http://ollama:11434
OLLAMA_BASE_URL=http://127.0.0.1:11434
EMBEDDING_MODEL=nomic-embed-text

# Qdrant Configuration (Open Source Mode)
# Default: localhost for development
# Docker: qdrant (host) and 6333 (port)
QDRANT_HOST=127.0.0.1
QDRANT_PORT=6333

# ====================================
# Optional: OpenAI Configuration
# ====================================

# Alternative to Ollama (can be used in both modes)
OPENAI_API_KEY=

# ====================================
# Optional: Logging Configuration
# ====================================

# Logging Configuration
LOG_LEVEL=INFO
DEBUG=false

# Environment: development or production
# - development: Logs to console (terminal)
# - production: Logs to file (default: /var/log/selfmemory-mcp/app.log)
ENVIRONMENT=development

# Log directory for production file-based logging
# Only used when ENVIRONMENT=production
# LOG_DIR=/var/log/selfmemory-mcp

# ====================================
# Optional: OpenTelemetry Configuration
# ====================================

# Set OTEL_ENABLED=true to send logs/traces to SigNoz
OTEL_ENABLED=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
