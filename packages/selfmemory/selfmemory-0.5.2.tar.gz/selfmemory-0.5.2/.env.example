# SelfMemory Server Configuration
# SERVER CONFIGURATION
# -----------------------------------------------
# Host and port for the FastAPI server
SELFMEMORY_SERVER_HOST=0.0.0.0
SELFMEMORY_SERVER_PORT=8081

# -----------------------------------------------
# APPLICATION CONFIGURATION
# -----------------------------------------------
# Environment: development, staging, or production
ENVIRONMENT=development

# URLs for frontend and backend
FRONTEND_URL=http://localhost:3000
BACKEND_URL=http://localhost:8081

# Allowed CORS origins (comma-separated list)
# For production, list specific domains only
# For development, include localhost variants
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# Timezone configuration
TIMEZONE=UTC
DEFAULT_DISPLAY_TIMEZONE=UTC

# -----------------------------------------------
# DATABASE CONFIGURATION (MongoDB)
# -----------------------------------------------
# MongoDB connection URI
MONGODB_URI=mongodb://localhost:27017/selfmemory

# Database connection settings
MONGODB_TIMEOUT=30
MONGODB_MAX_POOL_SIZE=100

# Transaction settings
MONGODB_TRANSACTION_TIMEOUT=5
MONGODB_RETRY_WRITES=true
MONGODB_WRITE_CONCERN=majority

# -----------------------------------------------
# VECTOR STORE CONFIGURATION (Qdrant)
# -----------------------------------------------
# Vector store provider (e.g., "qdrant")
VECTOR_STORE_PROVIDER=qdrant

# Qdrant settings
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=selfmemory_memories

# -----------------------------------------------
# EMBEDDING CONFIGURATION
# -----------------------------------------------
# Embedding provider (e.g., "ollama")
EMBEDDING_PROVIDER=ollama

# Embedding model
EMBEDDING_MODEL=nomic-embed-text

# Ollama base URL
OLLAMA_BASE_URL=http://localhost:11434

# -----------------------------------------------
# LLM CONFIGURATION (Optional - for intelligent memory extraction)
# -----------------------------------------------
# Configure an LLM to enable automatic fact extraction from conversations.
# When configured, the system will:
#   1. Extract key facts from user conversations
#   2. Intelligently merge, update, or remove duplicate memories
#   3. Improve memory quality and reduce redundancy
#
# Supported providers: openai, anthropic, ollama
# For vLLM (OpenAI-compatible): use provider=openai with custom base_url

# LLM provider (openai, anthropic, ollama)
LLM_PROVIDER=openai

# LLM model name (use your vLLM deployment model name)
LLM_MODEL=llm_model

# LLM API key (required for authentication)
LLM_API_KEY=your-api-key-here

# LLM base URL (for vLLM or custom OpenAI-compatible endpoints)
LLM_BASE_URL=http://localhost:8000/v1

# LLM generation parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=200

# -----------------------------------------------
# CHATLAB TOOL CALLING CONFIGURATION
# -----------------------------------------------
# Enable function calling for ChatLab (requires vLLM with tool calling support)
# Set to true to enable memory search via LLM function calls
# Requires vLLM to be started with: --enable-auto-tool-choice --tool-call-parser hermes
ENABLE_TOOL_CALLING=false

# vLLM endpoint for chat streaming (usually same as LLM_BASE_URL)
VLLM_ENDPOINT=http://localhost:8000/v1

# vLLM API key (same as LLM_API_KEY)
VLLM_API_KEY=your-api-key-here

# -----------------------------------------------
# ORY AUTHENTICATION CONFIGURATION
# -----------------------------------------------
# Ory Kratos endpoints (identity management)
# Public API is used for session validation from cookies
# Admin API is used for user management operations
KRATOS_PUBLIC_URL=http://127.0.0.1:4433
KRATOS_ADMIN_URL=http://127.0.0.1:4434

# Ory Hydra endpoints (OAuth 2.1 authorization)
# Public API is used for OAuth flows
# Admin API is used for token introspection and client management
HYDRA_PUBLIC_URL=http://127.0.0.1:4444
HYDRA_ADMIN_URL=http://127.0.0.1:4445

# -----------------------------------------------
# SECURITY CONFIGURATION
# -----------------------------------------------
# CSRF Protection
# Generate a secure random key for production:
# python -c "import secrets; print(secrets.token_urlsafe(32))"
CSRF_SECRET_KEY=your_csrf_secret_key_here_generate_with_command_above
CSRF_COOKIE_SECURE=true
CSRF_COOKIE_SAMESITE=strict

# Session Authentication
# Generate a secure random key for production:
# python -c "import secrets; print(secrets.token_urlsafe(32))"
SESSION_SECRET_KEY=your_session_secret_key_here_generate_with_command_above
# Session expiry in hours
SESSION_EXPIRY_HOURS=24

# Rate Limiting
# Enable rate limiting (recommended for production)
RATE_LIMIT_ENABLED=false
# Storage URL for rate limit data (required if rate limiting enabled)
# Use memory:// for development, redis://localhost:6379 for production
# RATE_LIMIT_STORAGE_URL=memory://

# Token Expiry
# Invitation token expiry in hours
INVITATION_TOKEN_EXPIRY_HOURS=24
# API key default expiry in days (optional, leave empty for no expiry)
# API_KEY_DEFAULT_EXPIRY_DAYS=90

# -----------------------------------------------
# ERROR HANDLING CONFIGURATION
# -----------------------------------------------
# Expose detailed error messages to API responses
# MUST be false in production for security
ERROR_EXPOSE_DETAILS=false

# -----------------------------------------------
# LOGGING CONFIGURATION
# -----------------------------------------------
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format: json or text
LOGGING_FORMAT=json

# Log sampling rate (0.0 to 1.0)
# 1.0 = log everything, 0.5 = log 50% of messages
LOGGING_SAMPLE_RATE=1.0

# -----------------------------------------------
# EMAIL/SMTP CONFIGURATION (Optional)
# -----------------------------------------------
# SMTP server settings for sending invitation emails
# Leave commented out if not using email features
# SMTP_HOST=smtp.gmail.com
# SMTP_PORT=587
# SMTP_USERNAME=your_email@gmail.com
# SMTP_PASSWORD=your_app_password
# SMTP_FROM_EMAIL=noreply@selfmemory.com
# SMTP_FROM_NAME=SelfMemory
# SMTP_USE_TLS=true
# SMTP_TIMEOUT=10

# -----------------------------------------------
# PAGINATION CONFIGURATION
# -----------------------------------------------
# Default number of items per page
PAGINATION_DEFAULT_LIMIT=10

# Maximum number of items per page
PAGINATION_MAX_LIMIT=100

# -----------------------------------------------
# HEALTH CHECK CONFIGURATION
# -----------------------------------------------
# Enable detailed health checks
HEALTH_ENABLE_DETAILED_CHECKS=true

# Health check timeout in seconds
HEALTH_TIMEOUT_SECONDS=5

# Memory threshold in MB for health warnings
HEALTH_MEMORY_THRESHOLD_MB=900

# -----------------------------------------------
# METRICS CONFIGURATION
# -----------------------------------------------
# Enable Prometheus metrics endpoint
METRICS_ENABLED=false

# -----------------------------------------------
# OPENTELEMETRY CONFIGURATION (Production Only)
# -----------------------------------------------
# Enable OpenTelemetry observability (production only)
OTEL_ENABLED=true

# Service name for identification in SigNoz
OTEL_SERVICE_NAME=selfmemory-api

# SigNoz OTLP endpoint (gRPC)
OTEL_EXPORTER_OTLP_ENDPOINT=http://192.168.1.49:4317

# Protocol: grpc or http/protobuf
OTEL_EXPORTER_OTLP_PROTOCOL=grpc

# Trace sampling strategy
OTEL_TRACES_SAMPLER=parentbased_traceidratio

# Sampling rate: 1.0 = 100% (recommended for production)
OTEL_TRACES_SAMPLER_ARG=1.0

# -----------------------------------------------
# LEGACY CONFIGURATION (for backwards compatibility)
# -----------------------------------------------
# These are kept for compatibility with older code
# but are no longer actively used in the new config system
# OLLAMA_HOST=http://localhost:11434
# DEFAULT_SEARCH_LIMIT=10
# SIMILARITY_THRESHOLD=0.7
# DUPLICATE_THRESHOLD=0.9
# DEFAULT_TIMEZONE=UTC
# SELFMEMORY_DATABASE=selfmemory
