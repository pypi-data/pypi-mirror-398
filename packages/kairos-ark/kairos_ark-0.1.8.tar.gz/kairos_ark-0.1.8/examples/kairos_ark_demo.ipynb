{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "94149388",
            "metadata": {},
            "source": [
                "# KAIROS-ARK: The Operating System for Agentic AI\n",
                "\n",
                "Welcome to the official demo notebook for **KAIROS-ARK**.\n",
                "\n",
                "This notebook demonstrates the core capabilities of the KAIROS kernel:\n",
                "1.  **Deterministic Execution** (Hello World)\n",
                "2.  **True Parallelism** (Multi-threaded implementation)\n",
                "3.  **Security Policy Engine** (Kernel-level restrictions)\n",
                "4.  **Performance Benchmarks** (Throughput & Zero-Copy Memory)\n",
                "\n",
                "> **Note:** This runs entirely natively in Rust. No Python logic is executed in the scheduler hot path."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e576da87",
            "metadata": {},
            "source": [
                "## 1. Installation\n",
                "\n",
                "First, we install the package from PyPI."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c352a719",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install kairos-ark"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8fb4188d",
            "metadata": {},
            "source": [
                "## 2. Hello World Agent\n",
                "\n",
                "Let's create a simple deterministic agent. KAIROS-ARK guarantees that running this agent with the same seed will produce **bit-for-bit identical** audit logs, every single time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9cc9c39",
            "metadata": {},
            "outputs": [],
            "source": [
                "from kairos_ark import Agent\n",
                "import json\n",
                "\n",
                "# 1. Initialize Agent with a fixed seed for determinism\n",
                "agent = Agent(seed=42)\n",
                "\n",
                "# 2. Define simple tools (nodes)\n",
                "# Note: Handlers in this demo are parameterless for simplicity\n",
                "agent.add_node(\"fetch_data\", lambda: {\"data\": \"raw_input_from_sensor\"})\n",
                "agent.add_node(\"process_data\", lambda: {\"status\": \"processed\", \"value\": \"RAW_INPUT_FROM_SENSOR\"})\n",
                "\n",
                "# 3. Connect the workflow graph\n",
                "agent.connect(\"fetch_data\", \"process_data\")\n",
                "\n",
                "# 4. Execute starting from 'fetch_data'\n",
                "print(\"ðŸš€ Executing Workflow...\")\n",
                "results = agent.execute(\"fetch_data\")\n",
                "\n",
                "print(\"\\nâœ… Execution Complete!\")\n",
                "print(\"Results:\", json.dumps(results, indent=2))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee67b9a5",
            "metadata": {},
            "source": [
                "## 3. True Parallel Execution\n",
                "\n",
                "Standard Python `asyncio` loops are single-threaded (GIL-bound). KAIROS-ARK provides a multi-threaded executor to achieve **true parallel fan-out** for blocking tasks.\n",
                "\n",
                "Here, we simulate 3 blocking tasks running simultaneously."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e937ffc",
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# Define a blocking task that sleeps\n",
                "def heavy_task(name):\n",
                "    print(f\"[{name}] Starting...\")\n",
                "    time.sleep(1.0) # Sleep for 1 second\n",
                "    print(f\"[{name}] Done!\")\n",
                "    return f\"{name}_result\"\n",
                "\n",
                "# Add parallel nodes\n",
                "agent.add_node(\"task_a\", lambda: heavy_task(\"A\"))\n",
                "agent.add_node(\"task_b\", lambda: heavy_task(\"B\"))\n",
                "agent.add_node(\"task_c\", lambda: heavy_task(\"C\"))\n",
                "\n",
                "print(\"\\nâš¡ Starting Parallel Execution (Expect ~1.0s total time, NOT 3.0s)...\")\n",
                "start_time = time.time()\n",
                "\n",
                "# Use run_parallel helper to bypass the GIL for Python tasks\n",
                "results = agent.run_parallel([\"task_a\", \"task_b\", \"task_c\"])\n",
                "\n",
                "end_time = time.time()\n",
                "print(f\"\\nâ±ï¸ Total Time: {end_time - start_time:.4f} seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "86e953f9",
            "metadata": {},
            "source": [
                "## 4. Kernel-Level Security Policy\n",
                "\n",
                "One of KAIROS-ARK's unique features is its **Policy Engine**. You can restrict what an agent can do (network access, file system) at the kernel level."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b1d755f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "from kairos_ark import Policy, Cap\n",
                "\n",
                "# 1. Register a tool that *requires* Network Access\n",
                "agent.register_tool(\n",
                "    \"sensitive_web_tool\",\n",
                "    lambda: \"This should be blocked\",\n",
                "    required_capabilities=[Cap.NET_ACCESS]  # Requires Network\n",
                ")\n",
                "\n",
                "# 2. Define a Policy that *blocks* Network Access\n",
                "policy = Policy(\n",
                "    allowed_capabilities=[Cap.LLM_CALL],  # Only allow LLM, NO Network\n",
                "    forbidden_content=[\"API_KEY\"]\n",
                ")\n",
                "\n",
                "# 3. Enforce the Policy\n",
                "agent.set_policy(policy)\n",
                "print(\"\\nðŸ›¡ï¸  Policy enforced: Network Access is BLOCKED\")\n",
                "\n",
                "# 4. Check if the tool is allowed\n",
                "allowed, reason = agent.check_tool_capability(\"sensitive_web_tool\")\n",
                "\n",
                "if not allowed:\n",
                "    print(f\"âœ… Security System Working: {reason}\")\n",
                "else:\n",
                "    print(\"âŒ Security Check Failed: Tool was allowed (Unexpected)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4012cbb5",
            "metadata": {},
            "source": [
                "## 5. Performance Benchmarks\n",
                "\n",
                "Let's put the Rust kernel to the test."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "332c856a",
            "metadata": {},
            "source": [
                "### 5.1 High-Throughput Test\n",
                "We will create a chain of 1,000 nodes and execute them to measure the raw overhead of the scheduler."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "84687d66",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reset agent\n",
                "agent.clear()\n",
                "agent = Agent(seed=123)\n",
                "\n",
                "count = 1000\n",
                "print(f\"Creating {count} nodes...\")\n",
                "start_setup = time.time()\n",
                "\n",
                "# Build linear chain\n",
                "for i in range(count):\n",
                "    agent.add_node(f\"node_{i}\", lambda: \"ok\")\n",
                "    if i > 0:\n",
                "        agent.connect(f\"node_{i-1}\", f\"node_{i}\")\n",
                "\n",
                "setup_time = time.time() - start_setup\n",
                "print(f\"Setup Time: {setup_time:.4f}s\")\n",
                "\n",
                "print(f\"Executing {count} nodes chain...\")\n",
                "start_exec = time.time()\n",
                "\n",
                "agent.execute(\"node_0\")\n",
                "\n",
                "exec_time = time.time() - start_exec\n",
                "\n",
                "print(f\"Execution Time: {exec_time:.4f}s\")\n",
                "print(f\"Throughput: {count / exec_time:.2f} nodes/sec\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b89d600d",
            "metadata": {},
            "source": [
                "### 5.2 Zero-Copy Shared Memory\n",
                "KAIROS-ARK has a built-in shared memory pool for passing large objects (like images or embeddings) between nodes without serialization overhead. \n",
                "\n",
                "Here we check writing 50MB of data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e2312c36",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# Create 50MB of dummy data (Default shared memory limit is 64MB)\n",
                "data_size = 50 * 1024 * 1024 # 50 MB\n",
                "print(f\"Allocating {data_size / 1024 / 1024} MB of data...\")\n",
                "large_data = b\"x\" * data_size\n",
                "\n",
                "start_write = time.time()\n",
                "\n",
                "# Write directly to kernel shared memory (returns a lightweight handle ID)\n",
                "handle_id = agent.kernel.write_shared(large_data)\n",
                "\n",
                "write_time = time.time() - start_write\n",
                "print(f\"Write Time: {write_time:.6f}s (Handle ID: {handle_id})\")\n",
                "\n",
                "# Define a node that receives only the handle ID, not the data payload\n",
                "def process_large_data():\n",
                "    # In a real app, this node could pass the handle to another process or \n",
                "    # read only a slice of the data without copying everything.\n",
                "    return {\"status\": \"read_complete\", \"handle\": handle_id}\n",
                "\n",
                "agent.add_node(\"process_large\", process_large_data)\n",
                "res = agent.execute(\"process_large\")\n",
                "\n",
                "print(\"Read Result:\", res[0][\"output\"])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
