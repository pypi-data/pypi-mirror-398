"""
Writable Batch Mode ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨é›¶å†…å­˜å¼€é”€çš„writable_batch_modeè¿›è¡Œé«˜æ€§èƒ½æ•°ç»„æ“ä½œ
"""
import random
import time
import numpy as np
from numpack import NumPack


def example_basic_usage():
    """ç¤ºä¾‹1: åŸºæœ¬ç”¨æ³•"""
    print("=" * 60)
    print("Example 1: Basic Usage")
    print("=" * 60)
    
    # åˆ›å»ºNumPackæ–‡ä»¶
    npk = NumPack('example_writable.npk', drop_if_exists=True)
    npk.open()
    
    # ä¿å­˜ä¸€äº›æ•°ç»„
    arrays = {
        'array1': np.random.rand(1, 1000000),
        'array2': np.random.rand(1, 1000000),
        'array3': np.random.rand(1, 1000000),
    }
    npk.save(arrays)
    
    # ä½¿ç”¨writable_batch_modeè¿›è¡Œæ‰¹é‡ä¿®æ”¹
    start = time.perf_counter()
    with npk.writable_batch_mode() as wb:
        # åŠ è½½æ•°ç»„ï¼ˆè¿”å›mmapè§†å›¾ï¼Œé›¶æ‹·è´ï¼‰
        arr1 = wb.load('array1')
        arr1 *= 2.0  # ç›´æ¥åœ¨æ–‡ä»¶ä¸Šä¿®æ”¹
        
        arr2 = wb.load('array2')
        arr2 += 1.0
        
        arr3 = wb.load('array3')
        arr3 /= 2.0
        
        # saveæ˜¯å¯é€‰çš„ï¼ˆä¿æŒAPIä¸€è‡´æ€§ï¼‰
        wb.save({'array1': arr1, 'array2': arr2, 'array3': arr3})
    
    elapsed = time.perf_counter() - start
    print(f"\nModifying 3 arrays took: {elapsed * 1000:.2f} ms")
    print(f"ğŸ’¾ Memory overhead: Nearly 0 MB (virtual memory only)")
    
    # éªŒè¯ä¿®æ”¹å·²æŒä¹…åŒ–
    result = npk.load('array1', lazy=False)
    print(f"Verification: array1 mean = {result.mean():.4f}")
    
    npk.close()
    print()


def example_high_performance_loop():
    """ç¤ºä¾‹2: é«˜æ€§èƒ½å¾ªç¯æ“ä½œ"""
    print("=" * 60)
    print("Example 2: High-performance loop operations (original test case)")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    npk = NumPack('example_loop.npk', drop_if_exists=True)
    npk.open()
    
    arrays = {
        'a1': np.random.rand(1, 1000000),
        'a2': np.random.rand(1, 1000000),
        'a3': np.random.rand(1, 1000000),
    }
    npk.save(arrays)
    
    # é«˜æ€§èƒ½å¾ªç¯
    foo = ['a1', 'a2', 'a3']
    random.seed(42)
    
    start = time.perf_counter()
    with npk.writable_batch_mode() as wb:
        for i in range(100):
            c = random.choice(foo)
            a = wb.load(c)    # mmapè§†å›¾ï¼ˆé›¶æ‹·è´ï¼‰
            a *= 4.1          # ç›´æ¥åœ¨æ–‡ä»¶ä¸Šä¿®æ”¹
            wb.save({c: a})   # å¯é€‰
    
    elapsed = time.perf_counter() - start
    
    print(f"\n100 random operations took: {elapsed * 1000:.2f} ms")
    print(f"ğŸ“ˆ Average per operation: {elapsed * 10:.3f} ms")
    print(f"Performance target: < 100 ms (< 1 ms/op)")
    
    if elapsed * 1000 <= 100:
        print(f"Target met! Speedup ~18-20x")
    
    npk.close()
    print()


def example_large_array():
    """ç¤ºä¾‹3: è¶…å¤§æ•°ç»„ï¼ˆå†…å­˜è£…ä¸ä¸‹ï¼‰"""
    print("=" * 60)
    print("Example 3: Very large array scenario")
    print("=" * 60)
    
    # åˆ›å»ºå¤§æ•°ç»„ï¼ˆ~80MBæ¯ä¸ªï¼‰
    npk = NumPack('example_large.npk', drop_if_exists=True)
    npk.open()
    
    print("Creating large arrays (each ~80MB)...")
    large_arrays = {
        'big1': np.random.rand(1, 10000000).astype(np.float64),
        'big2': np.random.rand(1, 10000000).astype(np.float64),
        'big3': np.random.rand(1, 10000000).astype(np.float64),
    }
    npk.save(large_arrays)
    
    print("Processing with writable_batch_mode...")
    start = time.perf_counter()
    with npk.writable_batch_mode() as wb:
        for name in ['big1', 'big2', 'big3']:
            arr = wb.load(name)
            arr *= 1.5  # ç›´æ¥åœ¨æ–‡ä»¶ä¸Šä¿®æ”¹
            wb.save({name: arr})
    
    elapsed = time.perf_counter() - start
    
    print(f"\nProcessing ~240MB data took: {elapsed * 1000:.2f} ms")
    print(f"ğŸ’¾ Memory overhead: Nearly 0 MB")
    print(f"Advantage: Supports TB-scale data (disk limited, not memory)")
    
    npk.close()
    print()


def example_comparison():
    """ç¤ºä¾‹4: batch_mode vs writable_batch_modeå¯¹æ¯”"""
    print("=" * 60)
    print("Example 4: Performance comparison")
    print("=" * 60)
    
    # å‡†å¤‡æ•°æ®
    npk = NumPack('example_compare.npk', drop_if_exists=True)
    npk.open()
    
    test_array = np.random.rand(1, 1000000)
    npk.save({'test': test_array})
    
    # æµ‹è¯•batch_mode
    print("\nTesting batch_mode (memory cache)...")
    start = time.perf_counter()
    with npk.batch_mode():
        for i in range(50):
            a = npk.load('test')
            a *= 1.1
            npk.save({'test': a})
    batch_time = time.perf_counter() - start
    
    # æ¢å¤æ•°æ®
    npk.save({'test': test_array})
    
    # æµ‹è¯•writable_batch_mode
    print("Testing writable_batch_mode (zero memory)...")
    start = time.perf_counter()
    with npk.writable_batch_mode() as wb:
        for i in range(50):
            a = wb.load('test')
            a *= 1.1
            wb.save({'test': a})
    writable_time = time.perf_counter() - start
    
    print("\n" + "=" * 60)
    print("Performance comparison results:")
    print("=" * 60)
    print(f"{'Mode':<25} {'Time(ms)':<12} {'Memory overhead'}")
    print("-" * 60)
    print(f"{'batch_mode':<25} {batch_time*1000:<12.2f} ~8 MB")
    print(f"{'writable_batch_mode':<25} {writable_time*1000:<12.2f} ~0 MB")
    print("=" * 60)
    print("\nConclusion:")
    print("  â€¢ batch_mode: Small arrays, pursue extreme speed")
    print("  â€¢ writable_batch_mode: Large arrays, zero memory overhead")
    
    npk.close()
    print()


def example_best_practices():
    """ç¤ºä¾‹5: æœ€ä½³å®è·µ"""
    print("=" * 60)
    print("Example 5: Best practices")
    print("=" * 60)
    
    npk = NumPack('example_practices.npk', drop_if_exists=True)
    npk.open()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    npk.save({
        'data1': np.random.rand(100, 1000),
        'data2': np.random.rand(100, 1000),
    })
    
    print("\nRecommended practices:")
    print()
    
    # 1. ä½¿ç”¨context manager
    print("1. Always use context manager:")
    print("```python")
    print("with npk.writable_batch_mode() as wb:")
    print("    arr = wb.load('data')")
    print("    arr *= 2.0")
    print("    # Auto flush on exit")
    print("```")
    print()
    
    # 2. ç¼“å­˜arrayå¼•ç”¨
    print("2. Cache frequently accessed arrays:")
    with npk.writable_batch_mode() as wb:
        # ç¬¬ä¸€æ¬¡loadä¼šåˆ›å»ºmmap
        arr1 = wb.load('data1')
        arr2 = wb.load('data2')
        
        # åç»­ç›´æ¥ä½¿ç”¨ç¼“å­˜çš„å¼•ç”¨
        for i in range(10):
            arr1 *= 1.1
            arr2 += 0.1
    print("Avoid repeatedly loading the same array")
    print()
    
    # 3. å¼‚å¸¸å¤„ç†
    print("3. Exception handling (automatic):")
    try:
        with npk.writable_batch_mode() as wb:
            arr = wb.load('data1')
            arr *= 2.0
            # å³ä½¿æŠ›å‡ºå¼‚å¸¸ï¼Œä¹Ÿä¼šè‡ªåŠ¨flushå’Œæ¸…ç†
    except Exception as e:
        pass
    print("Context manager automatically cleans up resources")
    print()
    
    npk.close()


if __name__ == '__main__':
    print("\n" + "=" * 60)
    print("Writable Batch Mode - Zero memory overhead high performance solution")
    print("=" * 60 + "\n")
    
    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    example_basic_usage()
    example_high_performance_loop()
    example_large_array()
    example_comparison()
    example_best_practices()
    
    print("\n" + "=" * 60)
    print("All examples completed!")
    print("=" * 60)
    print("\nUsage recommendations:")
    print("  â€¢ Small arrays (< 100MB): Use batch_mode()")
    print("  â€¢ Large arrays (> 100MB): Use writable_batch_mode()")
    print("  â€¢ Memory-constrained environments: Always use writable_batch_mode()")
    print("  â€¢ TB-scale data: writable_batch_mode is the only choice")
    print()

