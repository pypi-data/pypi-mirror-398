from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Annotated

import typer

# Engines supported by the skeleton generator.
_SUPPORTED_ENGINES = {
    "duckdb",
    "postgres",
    "bigquery",
    "databricks_spark",
    "snowflake_snowpark",
}


@dataclass(frozen=True)
class _InitContext:
    project_dir: Path
    project_name: str
    profile_name: str
    engine: str


def _build_profiles_yaml(ctx: _InitContext) -> str:
    engine_block = {
        "duckdb": [
            "  # DuckDB profile example. See docs/Profiles.md#engines-and-sections for details.",
            "  duckdb:",
            "    path: \"{{ env('FF_DUCKDB_PATH', '.local/dev.duckdb') }}\"  # Path to your DuckDB database file.",  # Noqa E501
        ],
        "postgres": [
            "  # Postgres profile example. See docs/Profiles.md#engines-and-sections "
            "    for required keys.",
            "  postgres:",
            "    dsn: \"{{ env('FF_PG_DSN') }}\"  # Full Postgres DSN, e.g. postgresql://user:pass@host/db",
            "    db_schema: \"{{ env('FF_PG_SCHEMA', 'analytics') }}\"",
        ],
        "bigquery": [
            "  # BigQuery profile example. See docs/Profiles.md#engines-and-sections.",
            "  bigquery:",
            "    project: \"{{ env('FF_BQ_PROJECT') }}\"  # Optional if your ADC "
            "    default project is set.",
            "    dataset: \"{{ env('FF_BQ_DATASET') }}\"  # Target dataset for models.",
            "    location: \"{{ env('FF_BQ_LOCATION', 'US') }}\"  # Must match dataset location.",
            "    use_bigframes: true  # Run Python models through BigQuery DataFrames (BigFrames).",
            "    allow_create_dataset: false  # Set true to auto-create the dataset on first run.",
        ],
        "databricks_spark": [
            "  # Databricks Spark profile example. See docs/Profiles.md#engines-and-sections.",
            "  databricks_spark:",
            "    master: \"{{ env('FF_SPARK_MASTER') }}\"  # e.g. spark://host:7077 or a Databricks cluster URL.",  # Noqa E501
            "    app_name: \"{{ env('FF_SPARK_APP_NAME', 'fft-project') }}\"",
            "    warehouse_dir: \"{{ env('FF_SPARK_WAREHOUSE', '/tmp/fft-warehouse') }}\"",
            "    use_hive_metastore: false",
            "    extra_conf: {}  # Provide Spark conf overrides here.",
            "    catalog: \"{{ env('FF_SPARK_CATALOG', '') }}\"  # Unity catalog (optional).",
            "    database: \"{{ env('FF_SPARK_DATABASE', 'default') }}\"",
            "    table_format: \"{{ env('FF_SPARK_TABLE_FORMAT', 'parquet') }}\"",
            "    table_options: {}",
        ],
        "snowflake_snowpark": [
            "  # Snowflake Snowpark profile example. See docs/Profiles.md#engines-and-sections.",
            "  snowflake_snowpark:",
            "    account: \"{{ env('FF_SF_ACCOUNT') }}\"",
            "    user: \"{{ env('FF_SF_USER') }}\"",
            "    password: \"{{ env('FF_SF_PASSWORD') }}\"",
            "    warehouse: \"{{ env('FF_SF_WAREHOUSE') }}\"",
            "    database: \"{{ env('FF_SF_DATABASE') }}\"",
            "    schema: \"{{ env('FF_SF_SCHEMA', 'PUBLIC') }}\"",
            "    role: \"{{ env('FF_SF_ROLE') }}\"",
            "    allow_create_schema: true",
        ],
    }[ctx.engine]

    lines = [
        "# Profiles generated by `fft init`.",
        "# Update these placeholders as described in docs/Profiles.md.",
        f"{ctx.profile_name}:",
        f"  engine: {ctx.engine}",
        *engine_block,
        "",
        "# Default in-memory profile for quick experiments.",
        "default:",
        "  engine: duckdb",
        "  duckdb:",
        '    path: ":memory:"',
        "",
    ]
    return "\n".join(lines)


def _build_project_yaml(ctx: _InitContext) -> str:
    return "\n".join(
        [
            "# Project configuration generated by `fft init`.",
            "# Read docs/Project_Config.md for the complete reference.",
            f"name: {ctx.project_name}",
            'version: "0.1"',
            "models_dir: models",
            "",
            "docs:",
            "  # Adjust `dag_dir` to change where `fft dag --html` writes documentation "
            "(docs/Technical_Overview.md#auto-docs-and-lineage).",
            "  dag_dir: site/dag",
            "",
            "# Project-level variables accessible via {{ var('key') }} inside models.",
            "# Example:",
            "#   vars:",
            '#     run_date: "2024-01-01"',
            "vars: {}",
            "",
            "# Optional project-wide hooks that run before/after the pipeline or per model.",
            "# See docs/Hooks.md for examples (SQL + Python) and selector usage.",
            "hooks:",
            "  on_run_start: []",
            "  on_run_end: []",
            "  before_model: []",
            "  after_model: []",
            "",
            "# Optional storage & incremental defaults applied per model name.",
            "# See docs/Project_Config.md#models for field meanings.",
            "models:",
            "  storage: {}",
            "  incremental: {}",
            "",
            "# Optional seed storage overrides (e.g., external locations per seed).",
            "# See docs/Project_Config.md#seeds for supported keys.",
            "seeds:",
            "  storage: {}",
            "",
            "# Declare project-wide data quality checks under `tests`. "
            "See docs/Data_Quality_Tests.md.",
            "tests: []",
            "",
        ]
    )


def _build_sources_yaml() -> str:
    return "\n".join(
        [
            "# Source declarations describe external tables. See docs/Sources.md for details.",
            "version: 1",
            "# sources:",
            "  # Example:",
            "  # - name: raw",
            "  #   schema: staging",
            "  #   tables:",
            "  #     - name: users",
            "  #       identifier: seed_users",
            "",
        ]
    )


def _build_packages_yaml() -> str:
    return "\n".join(
        [
            "# Packages bring in external models and macros. See docs/Packages.md.",
            "packages:",
            "  # - name: shared_macros",
            '  #   path: "../shared_macros"',
            '  #   models_dir: "models"',
            "",
        ]
    )


def _write_file(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def _build_root_readme(ctx: _InitContext) -> str:
    return "\n".join(
        [
            "# FastFlowTransform project scaffold",
            "",
            "This project was created with `fft init`.",
            "",
            "What lives here:",
            "- models/: SQL (`*.ff.sql`) and Python (`*.ff.py`) models.",
            "  - models/macros/: Jinja SQL macros loaded automatically.",
            "  - models/macros_py/: Python helpers exposed as Jinja globals/filters.",
            "- seeds/: CSV/Parquet inputs for reproducible seeds (see docs/Quickstart.md).",
            "- sources.yml: External tables for source('group','table').",
            "- profiles.yml: Engine connections; defaults come from docs/Profiles.md.",
            "- packages.yml: Optional shared models/macros (docs/Packages.md).",
            "- tests/unit/: YAML specs for `fft utest` (docs/Unit_Tests.md).",
            "- tests/dq/: Custom data-quality tests for `fft test` (docs/Data_Quality_Tests.md).",
            "- hooks/: SQL or Python hooks referenced from project.yml (docs/Hooks.md).",
            "- docs/: Notes plus generated DAG site when using `fft dag --html`.",
            "",
            "Next steps:",
            "1. Update `profiles.yml` with real connection details (docs/Profiles.md).",
            "2. Add sources in `sources.yml` and author models under `models/` "
            "   (docs/Config_and_Macros.md).",
            "3. Wire packages (optional) in `packages.yml` if you reuse shared "
            "   models/macros (docs/Packages.md).",
            "4. Seed sample data with `fft seed` and execute models "
            "   with `fft run` (docs/Quickstart.md).",
            "",
        ]
    )


def init(
    project_dir: Annotated[
        Path,
        typer.Argument(
            help="Directory to create (must not exist). For example: ./my_project",
        ),
    ],
    name: Annotated[
        str | None,
        typer.Option("--name", help="Project name; defaults to the target directory name."),
    ] = None,
    engine: Annotated[
        str,
        typer.Option(
            "--engine",
            help=(
                "Executor engine for the default profile. "
                "Supported values: duckdb, postgres, bigquery, "
                "databricks_spark, snowflake_snowpark."
            ),
        ),
    ] = "duckdb",
    profile_name: Annotated[
        str,
        typer.Option("--profile-name", help="Profile name to generate inside profiles.yml."),
    ] = "dev",
) -> None:
    resolved_engine = engine.lower().strip()
    if resolved_engine not in _SUPPORTED_ENGINES:
        typer.secho(
            (
                f"Unsupported engine '{engine}'. "
                "Choose one of: {', '.join(sorted(_SUPPORTED_ENGINES))}."
            ),
            fg="red",
        )
        raise typer.Exit(2)

    project_dir = project_dir.resolve()
    project_name = name or project_dir.name

    try:
        project_dir.mkdir(parents=True, exist_ok=False)
    except FileExistsError as err:
        typer.secho(
            f"Cannot initialise project: directory '{project_dir}' already exists. "
            "Choose a new path or remove the existing directory first.",
            fg="red",
        )
        raise typer.Exit(1) from err

    ctx = _InitContext(
        project_dir=project_dir,
        project_name=project_name,
        profile_name=profile_name,
        engine=resolved_engine,
    )

    for sub in (
        "models",
        "models/macros",
        "models/macros_py",
        "seeds",
        "tests/unit",
        "tests/dq",
        "hooks",
        "docs",
    ):
        (project_dir / sub).mkdir(parents=True, exist_ok=True)

    _write_file(project_dir / "project.yml", _build_project_yaml(ctx))
    _write_file(project_dir / "profiles.yml", _build_profiles_yaml(ctx))
    _write_file(project_dir / "sources.yml", _build_sources_yaml())
    _write_file(project_dir / "packages.yml", _build_packages_yaml())
    _write_file(project_dir / "README.md", _build_root_readme(ctx))

    typer.secho(f"Project skeleton created at {project_dir}", fg="green")


def register(app: typer.Typer) -> None:
    app.command(
        help=(
            "Create a FastFlowTransform project skeleton (non-interactive).\n\n"
            "Examples:\n"
            "  fft init ./analytics --name analytics --engine duckdb\n"
            "  fft init ~/projects/warehouse --engine postgres --profile-name prod\n"
        )
    )(init)


__all__ = ["init", "register"]
