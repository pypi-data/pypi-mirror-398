"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane import models, utils
from cribl_control_plane.types import BaseModel
from cribl_control_plane.utils import validate_open_enum
from enum import Enum
import pydantic
from pydantic import field_serializer
from pydantic.functional_validators import PlainValidator
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class InputSystemStateType(str, Enum):
    SYSTEM_STATE = "system_state"


class InputSystemStateConnectionTypedDict(TypedDict):
    output: str
    pipeline: NotRequired[str]


class InputSystemStateConnection(BaseModel):
    output: str

    pipeline: Optional[str] = None


class InputSystemStateMode(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine."""

    # Smart
    SMART = "smart"
    # Always On
    ALWAYS = "always"


class InputSystemStateCompression(str, Enum, metaclass=utils.OpenEnumMeta):
    r"""Codec to use to compress the persisted data"""

    # None
    NONE = "none"
    # Gzip
    GZIP = "gzip"


class InputSystemStatePqControlsTypedDict(TypedDict):
    pass


class InputSystemStatePqControls(BaseModel):
    pass


class InputSystemStatePqTypedDict(TypedDict):
    mode: NotRequired[InputSystemStateMode]
    r"""With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine."""
    max_buffer_size: NotRequired[float]
    r"""The maximum number of events to hold in memory before writing the events to disk"""
    commit_frequency: NotRequired[float]
    r"""The number of events to send downstream before committing that Stream has read them"""
    max_file_size: NotRequired[str]
    r"""The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc."""
    max_size: NotRequired[str]
    r"""The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc."""
    path: NotRequired[str]
    r"""The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>"""
    compress: NotRequired[InputSystemStateCompression]
    r"""Codec to use to compress the persisted data"""
    pq_controls: NotRequired[InputSystemStatePqControlsTypedDict]


class InputSystemStatePq(BaseModel):
    mode: Annotated[
        Optional[InputSystemStateMode], PlainValidator(validate_open_enum(False))
    ] = InputSystemStateMode.ALWAYS
    r"""With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine."""

    max_buffer_size: Annotated[
        Optional[float], pydantic.Field(alias="maxBufferSize")
    ] = 1000
    r"""The maximum number of events to hold in memory before writing the events to disk"""

    commit_frequency: Annotated[
        Optional[float], pydantic.Field(alias="commitFrequency")
    ] = 42
    r"""The number of events to send downstream before committing that Stream has read them"""

    max_file_size: Annotated[Optional[str], pydantic.Field(alias="maxFileSize")] = (
        "1 MB"
    )
    r"""The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc."""

    max_size: Annotated[Optional[str], pydantic.Field(alias="maxSize")] = "5GB"
    r"""The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc."""

    path: Optional[str] = "$CRIBL_HOME/state/queues"
    r"""The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>"""

    compress: Annotated[
        Optional[InputSystemStateCompression], PlainValidator(validate_open_enum(False))
    ] = InputSystemStateCompression.NONE
    r"""Codec to use to compress the persisted data"""

    pq_controls: Annotated[
        Optional[InputSystemStatePqControls], pydantic.Field(alias="pqControls")
    ] = None

    @field_serializer("mode")
    def serialize_mode(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemStateMode(value)
            except ValueError:
                return value
        return value

    @field_serializer("compress")
    def serialize_compress(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemStateCompression(value)
            except ValueError:
                return value
        return value


class InputSystemStateMetadatumTypedDict(TypedDict):
    name: str
    value: str
    r"""JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)"""


class InputSystemStateMetadatum(BaseModel):
    name: str

    value: str
    r"""JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)"""


class HostsFileTypedDict(TypedDict):
    r"""Creates events based on entries collected from the hosts file"""

    enable: NotRequired[bool]


class HostsFile(BaseModel):
    r"""Creates events based on entries collected from the hosts file"""

    enable: Optional[bool] = True


class InterfacesTypedDict(TypedDict):
    r"""Creates events for each of the host’s network interfaces"""

    enable: NotRequired[bool]


class Interfaces(BaseModel):
    r"""Creates events for each of the host’s network interfaces"""

    enable: Optional[bool] = True


class DisksAndFileSystemsTypedDict(TypedDict):
    r"""Creates events for physical disks, partitions, and file systems"""

    enable: NotRequired[bool]


class DisksAndFileSystems(BaseModel):
    r"""Creates events for physical disks, partitions, and file systems"""

    enable: Optional[bool] = True


class HostInfoTypedDict(TypedDict):
    r"""Creates events based on the host system’s current state"""

    enable: NotRequired[bool]


class HostInfo(BaseModel):
    r"""Creates events based on the host system’s current state"""

    enable: Optional[bool] = True


class InputSystemStateRoutesTypedDict(TypedDict):
    r"""Creates events based on entries collected from the host’s network routes"""

    enable: NotRequired[bool]


class InputSystemStateRoutes(BaseModel):
    r"""Creates events based on entries collected from the host’s network routes"""

    enable: Optional[bool] = True


class DNSTypedDict(TypedDict):
    r"""Creates events for DNS resolvers and search entries"""

    enable: NotRequired[bool]


class DNS(BaseModel):
    r"""Creates events for DNS resolvers and search entries"""

    enable: Optional[bool] = True


class UsersAndGroupsTypedDict(TypedDict):
    r"""Creates events for local users and groups"""

    enable: NotRequired[bool]


class UsersAndGroups(BaseModel):
    r"""Creates events for local users and groups"""

    enable: Optional[bool] = True


class FirewallTypedDict(TypedDict):
    r"""Creates events for Firewall rules entries"""

    enable: NotRequired[bool]


class Firewall(BaseModel):
    r"""Creates events for Firewall rules entries"""

    enable: Optional[bool] = True


class ServicesTypedDict(TypedDict):
    r"""Creates events from the list of services"""

    enable: NotRequired[bool]


class Services(BaseModel):
    r"""Creates events from the list of services"""

    enable: Optional[bool] = True


class ListeningPortsTypedDict(TypedDict):
    r"""Creates events from list of listening ports"""

    enable: NotRequired[bool]


class ListeningPorts(BaseModel):
    r"""Creates events from list of listening ports"""

    enable: Optional[bool] = True


class LoggedInUsersTypedDict(TypedDict):
    r"""Creates events from list of logged-in users"""

    enable: NotRequired[bool]


class LoggedInUsers(BaseModel):
    r"""Creates events from list of logged-in users"""

    enable: Optional[bool] = True


class CollectorsTypedDict(TypedDict):
    hostsfile: NotRequired[HostsFileTypedDict]
    r"""Creates events based on entries collected from the hosts file"""
    interfaces: NotRequired[InterfacesTypedDict]
    r"""Creates events for each of the host’s network interfaces"""
    disk: NotRequired[DisksAndFileSystemsTypedDict]
    r"""Creates events for physical disks, partitions, and file systems"""
    metadata: NotRequired[HostInfoTypedDict]
    r"""Creates events based on the host system’s current state"""
    routes: NotRequired[InputSystemStateRoutesTypedDict]
    r"""Creates events based on entries collected from the host’s network routes"""
    dns: NotRequired[DNSTypedDict]
    r"""Creates events for DNS resolvers and search entries"""
    user: NotRequired[UsersAndGroupsTypedDict]
    r"""Creates events for local users and groups"""
    firewall: NotRequired[FirewallTypedDict]
    r"""Creates events for Firewall rules entries"""
    services: NotRequired[ServicesTypedDict]
    r"""Creates events from the list of services"""
    ports: NotRequired[ListeningPortsTypedDict]
    r"""Creates events from list of listening ports"""
    login_users: NotRequired[LoggedInUsersTypedDict]
    r"""Creates events from list of logged-in users"""


class Collectors(BaseModel):
    hostsfile: Optional[HostsFile] = None
    r"""Creates events based on entries collected from the hosts file"""

    interfaces: Optional[Interfaces] = None
    r"""Creates events for each of the host’s network interfaces"""

    disk: Optional[DisksAndFileSystems] = None
    r"""Creates events for physical disks, partitions, and file systems"""

    metadata: Optional[HostInfo] = None
    r"""Creates events based on the host system’s current state"""

    routes: Optional[InputSystemStateRoutes] = None
    r"""Creates events based on entries collected from the host’s network routes"""

    dns: Optional[DNS] = None
    r"""Creates events for DNS resolvers and search entries"""

    user: Optional[UsersAndGroups] = None
    r"""Creates events for local users and groups"""

    firewall: Optional[Firewall] = None
    r"""Creates events for Firewall rules entries"""

    services: Optional[Services] = None
    r"""Creates events from the list of services"""

    ports: Optional[ListeningPorts] = None
    r"""Creates events from list of listening ports"""

    login_users: Annotated[
        Optional[LoggedInUsers], pydantic.Field(alias="loginUsers")
    ] = None
    r"""Creates events from list of logged-in users"""


class InputSystemStateDataCompressionFormat(str, Enum, metaclass=utils.OpenEnumMeta):
    NONE = "none"
    GZIP = "gzip"


class InputSystemStatePersistenceTypedDict(TypedDict):
    enable: NotRequired[bool]
    r"""Spool metrics to disk for Cribl Edge and Search"""
    time_window: NotRequired[str]
    r"""Time span for each file bucket"""
    max_data_size: NotRequired[str]
    r"""Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted."""
    max_data_time: NotRequired[str]
    r"""Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted."""
    compress: NotRequired[InputSystemStateDataCompressionFormat]
    dest_path: NotRequired[str]
    r"""Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_state"""


class InputSystemStatePersistence(BaseModel):
    enable: Optional[bool] = False
    r"""Spool metrics to disk for Cribl Edge and Search"""

    time_window: Annotated[Optional[str], pydantic.Field(alias="timeWindow")] = "10m"
    r"""Time span for each file bucket"""

    max_data_size: Annotated[Optional[str], pydantic.Field(alias="maxDataSize")] = "1GB"
    r"""Maximum disk space allowed to be consumed (examples: 420MB, 4GB). When limit is reached, older data will be deleted."""

    max_data_time: Annotated[Optional[str], pydantic.Field(alias="maxDataTime")] = "24h"
    r"""Maximum amount of time to retain data (examples: 2h, 4d). When limit is reached, older data will be deleted."""

    compress: Annotated[
        Optional[InputSystemStateDataCompressionFormat],
        PlainValidator(validate_open_enum(False)),
    ] = InputSystemStateDataCompressionFormat.NONE

    dest_path: Annotated[Optional[str], pydantic.Field(alias="destPath")] = (
        "$CRIBL_HOME/state/system_state"
    )
    r"""Path to use to write metrics. Defaults to $CRIBL_HOME/state/system_state"""

    @field_serializer("compress")
    def serialize_compress(self, value):
        if isinstance(value, str):
            try:
                return models.InputSystemStateDataCompressionFormat(value)
            except ValueError:
                return value
        return value


class InputSystemStateTypedDict(TypedDict):
    type: InputSystemStateType
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[InputSystemStateConnectionTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[InputSystemStatePqTypedDict]
    interval: NotRequired[float]
    r"""Time, in seconds, between consecutive state collections. Default is 300 seconds (5 minutes)."""
    metadata: NotRequired[List[InputSystemStateMetadatumTypedDict]]
    r"""Fields to add to events from this input"""
    collectors: NotRequired[CollectorsTypedDict]
    persistence: NotRequired[InputSystemStatePersistenceTypedDict]
    disable_native_module: NotRequired[bool]
    r"""Enable to use built-in tools (PowerShell) to collect events instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-system-state/#advanced-tab)"""
    description: NotRequired[str]


class InputSystemState(BaseModel):
    type: InputSystemStateType

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[InputSystemStateConnection]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[InputSystemStatePq] = None

    interval: Optional[float] = 300
    r"""Time, in seconds, between consecutive state collections. Default is 300 seconds (5 minutes)."""

    metadata: Optional[List[InputSystemStateMetadatum]] = None
    r"""Fields to add to events from this input"""

    collectors: Optional[Collectors] = None

    persistence: Optional[InputSystemStatePersistence] = None

    disable_native_module: Annotated[
        Optional[bool], pydantic.Field(alias="disableNativeModule")
    ] = False
    r"""Enable to use built-in tools (PowerShell) to collect events instead of native API (default) [Learn more](https://docs.cribl.io/edge/sources-system-state/#advanced-tab)"""

    description: Optional[str] = None
