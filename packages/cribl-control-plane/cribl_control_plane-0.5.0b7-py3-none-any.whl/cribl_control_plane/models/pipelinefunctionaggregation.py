"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl_control_plane.types import BaseModel
from enum import Enum
import pydantic
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class PipelineFunctionAggregationID(str, Enum):
    r"""Function ID"""

    AGGREGATION = "aggregation"


class PipelineFunctionAggregationAddTypedDict(TypedDict):
    value: str
    r"""JavaScript expression to compute the value (can be constant)"""
    name: NotRequired[str]


class PipelineFunctionAggregationAdd(BaseModel):
    value: str
    r"""JavaScript expression to compute the value (can be constant)"""

    name: Optional[str] = None


class PipelineFunctionAggregationConfTypedDict(TypedDict):
    aggregations: List[str]
    r"""Aggregate function to perform on events. Example: sum(bytes).where(action=='REJECT').as(TotalBytes)"""
    passthrough: NotRequired[bool]
    r"""Pass through the original events along with the aggregation events"""
    preserve_group_bys: NotRequired[bool]
    r"""Preserve the structure of the original aggregation event's groupby fields"""
    sufficient_stats_only: NotRequired[bool]
    r"""Output only statistics that are sufficient for the supplied aggregations"""
    metrics_mode: NotRequired[bool]
    r"""Enable to output the aggregates as metrics. When disabled, aggregates are output as events."""
    prefix: NotRequired[str]
    r"""A prefix that is prepended to all of the fields output by this Aggregations Function"""
    time_window: NotRequired[str]
    r"""The time span of the tumbling window for aggregating events. Must be a valid time string (such as 10s)."""
    groupbys: NotRequired[List[str]]
    r"""Optional: One or more fields to group aggregates by. Supports wildcard expressions. Warning: Using wildcard '*' causes all fields in the event to be included, which can result in high cardinality and increased memory usage. Exclude fields that can result in high cardinality before using wildcards. Example: !_time, !_numericValue, *"""
    flush_event_limit: NotRequired[float]
    r"""The maximum number of events to include in any given aggregation event"""
    flush_mem_limit: NotRequired[str]
    r"""The memory usage limit to impose upon aggregations. Defaults to 80% of the process memory; value configured above default limit is ignored. Accepts numerals with units like KB and MB (example: 128MB)."""
    cumulative: NotRequired[bool]
    r"""Enable to retain aggregations for cumulative aggregations when flushing out an aggregation table event. When disabled (the default), aggregations are reset to 0 on flush."""
    search_agg_mode: NotRequired[str]
    r"""Allows Cribl Search-specific aggregation configuration"""
    add: NotRequired[List[PipelineFunctionAggregationAddTypedDict]]
    r"""Set of key-value pairs to evaluate and add/set"""
    should_treat_dots_as_literals: NotRequired[bool]
    r"""Treat dots in dimension names as literals. This is useful for top-level dimensions that contain dots, such as 'service.name'."""
    flush_on_input_close: NotRequired[bool]
    r"""Flush aggregations when an input stream is closed. If disabled, Time Window Settings control flush behavior."""


class PipelineFunctionAggregationConf(BaseModel):
    aggregations: List[str]
    r"""Aggregate function to perform on events. Example: sum(bytes).where(action=='REJECT').as(TotalBytes)"""

    passthrough: Optional[bool] = False
    r"""Pass through the original events along with the aggregation events"""

    preserve_group_bys: Annotated[
        Optional[bool], pydantic.Field(alias="preserveGroupBys")
    ] = False
    r"""Preserve the structure of the original aggregation event's groupby fields"""

    sufficient_stats_only: Annotated[
        Optional[bool], pydantic.Field(alias="sufficientStatsOnly")
    ] = False
    r"""Output only statistics that are sufficient for the supplied aggregations"""

    metrics_mode: Annotated[Optional[bool], pydantic.Field(alias="metricsMode")] = False
    r"""Enable to output the aggregates as metrics. When disabled, aggregates are output as events."""

    prefix: Optional[str] = None
    r"""A prefix that is prepended to all of the fields output by this Aggregations Function"""

    time_window: Annotated[Optional[str], pydantic.Field(alias="timeWindow")] = "10s"
    r"""The time span of the tumbling window for aggregating events. Must be a valid time string (such as 10s)."""

    groupbys: Optional[List[str]] = None
    r"""Optional: One or more fields to group aggregates by. Supports wildcard expressions. Warning: Using wildcard '*' causes all fields in the event to be included, which can result in high cardinality and increased memory usage. Exclude fields that can result in high cardinality before using wildcards. Example: !_time, !_numericValue, *"""

    flush_event_limit: Annotated[
        Optional[float], pydantic.Field(alias="flushEventLimit")
    ] = None
    r"""The maximum number of events to include in any given aggregation event"""

    flush_mem_limit: Annotated[Optional[str], pydantic.Field(alias="flushMemLimit")] = (
        None
    )
    r"""The memory usage limit to impose upon aggregations. Defaults to 80% of the process memory; value configured above default limit is ignored. Accepts numerals with units like KB and MB (example: 128MB)."""

    cumulative: Optional[bool] = False
    r"""Enable to retain aggregations for cumulative aggregations when flushing out an aggregation table event. When disabled (the default), aggregations are reset to 0 on flush."""

    search_agg_mode: Annotated[Optional[str], pydantic.Field(alias="searchAggMode")] = (
        None
    )
    r"""Allows Cribl Search-specific aggregation configuration"""

    add: Optional[List[PipelineFunctionAggregationAdd]] = None
    r"""Set of key-value pairs to evaluate and add/set"""

    should_treat_dots_as_literals: Annotated[
        Optional[bool], pydantic.Field(alias="shouldTreatDotsAsLiterals")
    ] = False
    r"""Treat dots in dimension names as literals. This is useful for top-level dimensions that contain dots, such as 'service.name'."""

    flush_on_input_close: Annotated[
        Optional[bool], pydantic.Field(alias="flushOnInputClose")
    ] = True
    r"""Flush aggregations when an input stream is closed. If disabled, Time Window Settings control flush behavior."""


class PipelineFunctionAggregationTypedDict(TypedDict):
    id: PipelineFunctionAggregationID
    r"""Function ID"""
    conf: PipelineFunctionAggregationConfTypedDict
    filter_: NotRequired[str]
    r"""Filter that selects data to be fed through this Function"""
    description: NotRequired[str]
    r"""Simple description of this step"""
    disabled: NotRequired[bool]
    r"""If true, data will not be pushed through this function"""
    final: NotRequired[bool]
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""
    group_id: NotRequired[str]
    r"""Group ID"""


class PipelineFunctionAggregation(BaseModel):
    id: PipelineFunctionAggregationID
    r"""Function ID"""

    conf: PipelineFunctionAggregationConf

    filter_: Annotated[Optional[str], pydantic.Field(alias="filter")] = "true"
    r"""Filter that selects data to be fed through this Function"""

    description: Optional[str] = None
    r"""Simple description of this step"""

    disabled: Optional[bool] = None
    r"""If true, data will not be pushed through this function"""

    final: Optional[bool] = None
    r"""If enabled, stops the results of this Function from being passed to the downstream Functions"""

    group_id: Annotated[Optional[str], pydantic.Field(alias="groupId")] = None
    r"""Group ID"""
