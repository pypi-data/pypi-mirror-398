"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .itemstypeconnections import ItemsTypeConnections, ItemsTypeConnectionsTypedDict
from .itemstypenotificationmetadata import (
    ItemsTypeNotificationMetadata,
    ItemsTypeNotificationMetadataTypedDict,
)
from .pqtype import PqType, PqTypeTypedDict
from .tlssettingsserversidetype import (
    TLSSettingsServerSideType,
    TLSSettingsServerSideTypeTypedDict,
)
from cribl_control_plane.types import BaseModel
from enum import Enum
import pydantic
from typing import List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class InputCriblLakeHTTPType(str, Enum):
    CRIBL_LAKE_HTTP = "cribl_lake_http"


class SplunkHecMetadataTypedDict(TypedDict):
    enabled: NotRequired[bool]
    default_dataset: NotRequired[str]
    allowed_indexes_at_token: NotRequired[List[str]]


class SplunkHecMetadata(BaseModel):
    enabled: Optional[bool] = None

    default_dataset: Annotated[
        Optional[str], pydantic.Field(alias="defaultDataset")
    ] = None

    allowed_indexes_at_token: Annotated[
        Optional[List[str]], pydantic.Field(alias="allowedIndexesAtToken")
    ] = None


class ElasticsearchMetadataTypedDict(TypedDict):
    enabled: NotRequired[bool]
    default_dataset: NotRequired[str]


class ElasticsearchMetadata(BaseModel):
    enabled: Optional[bool] = None

    default_dataset: Annotated[
        Optional[str], pydantic.Field(alias="defaultDataset")
    ] = None


class AuthTokensExtTypedDict(TypedDict):
    token: str
    description: NotRequired[str]
    metadata: NotRequired[List[ItemsTypeNotificationMetadataTypedDict]]
    r"""Fields to add to events referencing this token"""
    splunk_hec_metadata: NotRequired[SplunkHecMetadataTypedDict]
    elasticsearch_metadata: NotRequired[ElasticsearchMetadataTypedDict]


class AuthTokensExt(BaseModel):
    token: str

    description: Optional[str] = None

    metadata: Optional[List[ItemsTypeNotificationMetadata]] = None
    r"""Fields to add to events referencing this token"""

    splunk_hec_metadata: Annotated[
        Optional[SplunkHecMetadata], pydantic.Field(alias="splunkHecMetadata")
    ] = None

    elasticsearch_metadata: Annotated[
        Optional[ElasticsearchMetadata], pydantic.Field(alias="elasticsearchMetadata")
    ] = None


class InputCriblLakeHTTPTypedDict(TypedDict):
    type: InputCriblLakeHTTPType
    port: float
    r"""Port to listen on"""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[ItemsTypeConnectionsTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[PqTypeTypedDict]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    auth_tokens: NotRequired[List[str]]
    r"""Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted."""
    tls: NotRequired[TLSSettingsServerSideTypeTypedDict]
    max_active_req: NotRequired[float]
    r"""Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput."""
    max_requests_per_socket: NotRequired[int]
    r"""Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited)."""
    enable_proxy_header: NotRequired[bool]
    r"""Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction."""
    capture_headers: NotRequired[bool]
    r"""Add request headers to events, in the __headers field"""
    activity_log_sample_rate: NotRequired[float]
    r"""How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc."""
    request_timeout: NotRequired[float]
    r"""How long to wait for an incoming request to complete before aborting it. Use 0 to disable."""
    socket_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0."""
    keep_alive_timeout: NotRequired[float]
    r"""After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes)."""
    enable_health_check: NotRequired[bool]
    r"""Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy"""
    ip_allowlist_regex: NotRequired[str]
    r"""Messages from matched IP addresses will be processed, unless also matched by the denylist"""
    ip_denylist_regex: NotRequired[str]
    r"""Messages from matched IP addresses will be ignored. This takes precedence over the allowlist."""
    cribl_api: NotRequired[str]
    r"""Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable."""
    elastic_api: NotRequired[str]
    r"""Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable."""
    splunk_hec_api: NotRequired[str]
    r"""Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable."""
    splunk_hec_acks: NotRequired[bool]
    metadata: NotRequired[List[ItemsTypeNotificationMetadataTypedDict]]
    r"""Fields to add to events from this input"""
    auth_tokens_ext: NotRequired[List[AuthTokensExtTypedDict]]
    description: NotRequired[str]


class InputCriblLakeHTTP(BaseModel):
    type: InputCriblLakeHTTPType

    port: float
    r"""Port to listen on"""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[ItemsTypeConnections]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[PqType] = None

    host: Optional[str] = "0.0.0.0"
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    auth_tokens: Annotated[Optional[List[str]], pydantic.Field(alias="authTokens")] = (
        None
    )
    r"""Shared secrets to be provided by any client (Authorization: <token>). If empty, unauthorized access is permitted."""

    tls: Optional[TLSSettingsServerSideType] = None

    max_active_req: Annotated[Optional[float], pydantic.Field(alias="maxActiveReq")] = (
        256
    )
    r"""Maximum number of active requests allowed per Worker Process. Set to 0 for unlimited. Caution: Increasing the limit above the default value, or setting it to unlimited, may degrade performance and reduce throughput."""

    max_requests_per_socket: Annotated[
        Optional[int], pydantic.Field(alias="maxRequestsPerSocket")
    ] = 0
    r"""Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited)."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Extract the client IP and port from PROXY protocol v1/v2. When enabled, the X-Forwarded-For header is ignored. Disable to use the X-Forwarded-For header for client IP extraction."""

    capture_headers: Annotated[
        Optional[bool], pydantic.Field(alias="captureHeaders")
    ] = False
    r"""Add request headers to events, in the __headers field"""

    activity_log_sample_rate: Annotated[
        Optional[float], pydantic.Field(alias="activityLogSampleRate")
    ] = 100
    r"""How often request activity is logged at the `info` level. A value of 1 would log every request, 10 every 10th request, etc."""

    request_timeout: Annotated[
        Optional[float], pydantic.Field(alias="requestTimeout")
    ] = 0
    r"""How long to wait for an incoming request to complete before aborting it. Use 0 to disable."""

    socket_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0."""

    keep_alive_timeout: Annotated[
        Optional[float], pydantic.Field(alias="keepAliveTimeout")
    ] = 5
    r"""After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 second, maximum 600 seconds (10 minutes)."""

    enable_health_check: Annotated[
        Optional[bool], pydantic.Field(alias="enableHealthCheck")
    ] = False
    r"""Expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy"""

    ip_allowlist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipAllowlistRegex")
    ] = "/.*/"
    r"""Messages from matched IP addresses will be processed, unless also matched by the denylist"""

    ip_denylist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipDenylistRegex")
    ] = "/^$/"
    r"""Messages from matched IP addresses will be ignored. This takes precedence over the allowlist."""

    cribl_api: Annotated[Optional[str], pydantic.Field(alias="criblAPI")] = "/cribl"
    r"""Absolute path on which to listen for the Cribl HTTP API requests. Only _bulk (default /cribl/_bulk) is available. Use empty string to disable."""

    elastic_api: Annotated[Optional[str], pydantic.Field(alias="elasticAPI")] = (
        "/elastic"
    )
    r"""Absolute path on which to listen for the Elasticsearch API requests. Only _bulk (default /elastic/_bulk) is available. Use empty string to disable."""

    splunk_hec_api: Annotated[Optional[str], pydantic.Field(alias="splunkHecAPI")] = (
        "/services/collector"
    )
    r"""Absolute path on which listen for the Splunk HTTP Event Collector API requests. Use empty string to disable."""

    splunk_hec_acks: Annotated[
        Optional[bool], pydantic.Field(alias="splunkHecAcks")
    ] = False

    metadata: Optional[List[ItemsTypeNotificationMetadata]] = None
    r"""Fields to add to events from this input"""

    auth_tokens_ext: Annotated[
        Optional[List[AuthTokensExt]], pydantic.Field(alias="authTokensExt")
    ] = None

    description: Optional[str] = None
