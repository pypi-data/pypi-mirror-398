//! Database driver with connection pooling, transactions, and query execution.
//!
//! This crate provides the sqlx-based database layer for Oxyde. It manages connection
//! pools, transactions, and executes SQL generated by oxyde-query.
//!
//! # Architecture
//!
//! ```text
//! SQL + Values → bind parameters → execute via sqlx → rows → JSON/MessagePack
//! ```
//!
//! ## Global Registries
//!
//! - `ConnectionRegistry`: Named pools (e.g., "default", "analytics")
//! - `TransactionRegistry`: Active transactions by tx_id
//!
//! Both are `OnceCell<T>` statics for safe concurrent access.
//!
//! # Pool Management
//!
//! ```rust,ignore
//! init_pool("default", "postgresql://...", settings).await?;
//! init_pool("analytics", "postgresql://...", settings).await?;
//! close_pool("analytics").await?;
//! close_all_pools().await?;
//! ```
//!
//! # Query Execution
//!
//! ```rust,ignore
//! // Outside transaction (with optional type hints for faster decoding)
//! let rows = execute_query("default", sql, values, col_types.as_ref()).await?;
//!
//! // Inside transaction
//! let rows = execute_in_transaction(tx_id, sql, values).await?;
//! ```
//!
//! # Transaction API
//!
//! ```rust,ignore
//! let tx_id = begin_transaction("default").await?;
//! execute_in_transaction(tx_id, sql1, values1).await?;
//! execute_in_transaction(tx_id, sql2, values2).await?;
//! commit_transaction(tx_id).await?;  // or rollback_transaction(tx_id)
//! ```
//!
//! # Validation Strategy
//!
//! - **Input (Python → Rust → DB)**: Data validated in Python via Pydantic v2.
//!   Rust trusts the data and executes SQL without re-validation.
//!
//! - **Output (DB → Rust → Python)**: Rows validated in oxyde-core-py via
//!   pydantic-core validators registered from Python.
//!
//! # Database Support
//!
//! - **PostgreSQL**: Full support (pools, transactions, RETURNING, FOR UPDATE)
//! - **SQLite**: Full support (WAL mode, PRAGMAs, RETURNING 3.35+)
//! - **MySQL**: Full support (pools, transactions, no RETURNING)
//!
//! # SQLite PRAGMAs
//!
//! Applied via `after_connect` hook:
//! - `journal_mode=WAL` (10-20x faster concurrent writes)
//! - `synchronous=NORMAL` (balance speed/safety)
//! - `cache_size=10000` (~10MB cache)
//! - `busy_timeout=5000` (5s lock wait)

use once_cell::sync::OnceCell;
use sea_query::Value;
use sqlx::{
    mysql::MySqlPoolOptions,
    postgres::PgPoolOptions,
    sqlite::{SqliteConnectOptions, SqlitePoolOptions},
};
use std::collections::HashMap;
use std::str::FromStr;
use std::time::Instant;
use tracing::{debug, info, warn};

// Module declarations
mod error;
mod exec;
mod pool;
mod settings;
mod transaction;

use transaction::with_conn;
pub mod backend;
mod bind;
mod convert;
mod explain;

// Import exec traits for internal use
use exec::{ConnExec, PoolExec};

// Public re-exports
pub use error::{DriverError, Result};
pub use explain::{ExplainFormat, ExplainOptions};
pub use pool::{DatabaseBackend, DbPool};
pub use settings::PoolSettings;

// PyO3 direct conversion (when feature enabled)
#[cfg(feature = "pyo3")]
pub use convert::{
    decode_mysql_cell_to_py,
    decode_pg_cell_to_py,
    decode_sqlite_cell_to_py,
    extract_mysql_columns,
    extract_pg_columns,
    extract_sqlite_columns,
    mysql_rows_to_pylist,
    pg_rows_to_pylist,
    sqlite_rows_to_pylist,
    // Batched conversion support
    StreamingColumnMeta,
};

// Internal imports - use aliases to avoid conflict with pub use
#[cfg(not(feature = "pyo3"))]
use bind::{bind_mysql, bind_postgres, bind_sqlite};
#[cfg(feature = "pyo3")]
pub use bind::{bind_mysql, bind_postgres, bind_sqlite};
use convert::{convert_pg_rows, convert_sqlite_rows, ColumnarResult};
use explain::{
    build_mysql_explain_sql, build_postgres_explain_sql, build_sqlite_explain_sql,
    extract_mysql_json_plan, extract_postgres_json_plan, extract_text_plan, rows_to_objects,
};
use pool::{ConnectionRegistry, PoolHandle};
use transaction::{DbConn, TransactionInner, TransactionRegistry, TransactionState};

static REGISTRY: OnceCell<ConnectionRegistry> = OnceCell::new();
static TRANSACTION_REGISTRY: OnceCell<TransactionRegistry> = OnceCell::new();
static CLEANUP_TASK: OnceCell<tokio::sync::Mutex<Option<tokio::task::JoinHandle<()>>>> =
    OnceCell::new();

fn registry() -> &'static ConnectionRegistry {
    REGISTRY.get_or_init(ConnectionRegistry::new)
}

fn transaction_registry() -> &'static TransactionRegistry {
    TRANSACTION_REGISTRY.get_or_init(TransactionRegistry::new)
}

fn ensure_cleanup_task() {
    let task_mutex = CLEANUP_TASK.get_or_init(|| tokio::sync::Mutex::new(None));

    tokio::spawn(async move {
        let mut guard = task_mutex.lock().await;

        // Check if already running
        if let Some(handle) = guard.as_ref() {
            if !handle.is_finished() {
                return;
            }
        }

        // Start new cleanup task
        let handle = tokio::spawn(async {
            loop {
                let interval = transaction_registry().get_cleanup_interval().await;
                tokio::time::sleep(interval).await;

                let removed = transaction_registry().cleanup_stale_transactions().await;
                if removed > 0 {
                    info!(
                        "Cleaned up {} stale transactions (interval: {:?})",
                        removed, interval
                    );
                }
            }
        });

        *guard = Some(handle);
    });
}

pub async fn init_pool(name: &str, url: &str, settings: PoolSettings) -> Result<()> {
    init_pool_inner(name, url, settings, false).await
}

pub async fn init_pool_overwrite(name: &str, url: &str, settings: PoolSettings) -> Result<()> {
    init_pool_inner(name, url, settings, true).await
}

async fn init_pool_inner(
    name: &str,
    url: &str,
    settings: PoolSettings,
    overwrite: bool,
) -> Result<()> {
    info!(
        "Initializing pool '{}' with URL {} (overwrite={})",
        name, url, overwrite
    );

    validate_settings(&settings)?;

    let backend = match backend_from_url(url) {
        Some(backend) => backend,
        None => {
            return Err(DriverError::ConnectionError(format!(
                "Unsupported database URL: {}",
                url
            )))
        }
    };

    let pool = match backend {
        DatabaseBackend::Postgres => {
            let options = apply_common_settings_pg(PgPoolOptions::new(), &settings);
            options
                .connect(url)
                .await
                .map(DbPool::Postgres)
                .map_err(|e| DriverError::ConnectionError(format!("Failed to connect: {}", e)))?
        }
        DatabaseBackend::MySql => {
            let options = apply_common_settings_mysql(MySqlPoolOptions::new(), &settings);
            options
                .connect(url)
                .await
                .map(DbPool::MySql)
                .map_err(|e| DriverError::ConnectionError(format!("Failed to connect: {}", e)))?
        }
        DatabaseBackend::Sqlite => {
            // Clone PRAGMA settings for use in after_connect closure
            let journal_mode_opt = settings.sqlite_journal_mode.clone();
            let synchronous_opt = settings.sqlite_synchronous.clone();
            let cache_size_opt = settings.sqlite_cache_size;
            let busy_timeout_opt = settings.sqlite_busy_timeout;

            let mut options = apply_common_settings_sqlite(SqlitePoolOptions::new(), &settings);

            // Apply PRAGMA settings to each connection in the pool
            options = options.after_connect(move |conn, _meta| {
                let journal_mode = journal_mode_opt.clone();
                let synchronous = synchronous_opt.clone();
                let cache_size = cache_size_opt;
                let busy_timeout = busy_timeout_opt;

                Box::pin(async move {
                    // journal_mode and synchronous are persistent (saved to DB file)
                    if let Some(mode) = journal_mode {
                        let pragma = format!("PRAGMA journal_mode = {}", mode);
                        sqlx::query(&pragma).execute(&mut *conn).await?;
                    }

                    if let Some(sync) = synchronous {
                        let pragma = format!("PRAGMA synchronous = {}", sync);
                        sqlx::query(&pragma).execute(&mut *conn).await?;
                    }

                    // cache_size and busy_timeout are per-connection (must be set for each connection)
                    if let Some(size) = cache_size {
                        let pragma = format!("PRAGMA cache_size = {}", size);
                        sqlx::query(&pragma).execute(&mut *conn).await?;
                    }

                    if let Some(timeout) = busy_timeout {
                        let pragma = format!("PRAGMA busy_timeout = {}", timeout);
                        sqlx::query(&pragma).execute(&mut *conn).await?;
                    }

                    Ok(())
                })
            });

            // Parse URL and enable automatic database file creation
            let connect_opts = SqliteConnectOptions::from_str(url)
                .map_err(|e| DriverError::ConnectionError(format!("Invalid SQLite URL: {}", e)))?
                .create_if_missing(true);

            let pool = options
                .connect_with(connect_opts)
                .await
                .map_err(|e| DriverError::ConnectionError(format!("Failed to connect: {}", e)))?;

            info!("SQLite pool created with PRAGMA settings (create_if_missing=true)");

            DbPool::Sqlite(pool)
        }
    };

    let handle = PoolHandle::new(backend, pool);

    if overwrite {
        // Close old pool if exists
        if let Some(old_handle) = registry().insert_or_replace(name.to_string(), handle).await {
            info!("Closing old pool '{}' during overwrite", name);
            old_handle.close().await;
        }
    } else if let Err(err) = registry().insert(name.to_string(), handle.clone()).await {
        handle.close().await;
        return Err(err);
    }

    // Update transaction registry settings for this pool
    transaction_registry()
        .update_settings(name, &settings)
        .await;

    info!("Pool '{}' initialised successfully", name);
    Ok(())
}

pub async fn close_pool(name: &str) -> Result<()> {
    info!("Closing pool '{}'", name);
    let handle = registry().remove(name).await?;
    handle.close().await;
    Ok(())
}

pub async fn close_all_pools() -> Result<()> {
    info!("Closing all pools");

    // First, rollback all active transactions
    let rolled_back = transaction_registry().rollback_all().await;
    if rolled_back > 0 {
        info!(
            "Rolled back {} active transactions during shutdown",
            rolled_back
        );
    }

    // Then close all connection pools
    let handles = registry().take_all().await;
    for (name, handle) in handles {
        info!("Closing pool '{}'", name);
        handle.close().await;
    }
    Ok(())
}

pub async fn pool_backend(name: &str) -> Result<DatabaseBackend> {
    registry().get(name).await.map(|handle| handle.backend)
}

/// Get a clone of the connection pool by name.
/// Used by oxyde-core-py for direct PyO3 conversion.
#[cfg(feature = "pyo3")]
pub async fn get_pool(name: &str) -> Result<DbPool> {
    registry().get(name).await.map(|handle| handle.clone_pool())
}

pub async fn begin_transaction(pool_name: &str) -> Result<u64> {
    info!("Beginning transaction on pool '{}'", pool_name);
    let handle = registry().get(pool_name).await?;
    let backend = handle.backend;
    let now = std::time::Instant::now();

    // Acquire connection and begin transaction
    let conn = transaction::begin_on_pool(&handle.clone_pool(), backend).await?;

    let tx_inner = TransactionInner {
        _pool_name: pool_name.to_string(),
        _backend: backend,
        conn: Some(conn),
        state: TransactionState::Active,
        created_at: now,
        last_activity: now,
    };

    let tx_id = transaction_registry().insert(tx_inner).await;

    // Ensure cleanup task is running
    ensure_cleanup_task();

    Ok(tx_id)
}

pub async fn execute_query_in_transaction(
    tx_id: u64,
    sql: &str,
    params: &[Value],
    col_types: Option<&HashMap<String, String>>,
) -> Result<Vec<HashMap<String, serde_json::Value>>> {
    let registry = transaction_registry();
    let arc = registry
        .get(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    tx.update_activity();

    let conn = tx
        .conn
        .as_mut()
        .ok_or(DriverError::TransactionClosed(tx_id))?;
    conn.query(sql, params, col_types).await
}

/// Execute SELECT query in transaction returning columnar format (columns, rows).
pub async fn execute_query_columnar_in_transaction(
    tx_id: u64,
    sql: &str,
    params: &[Value],
    col_types: Option<&HashMap<String, String>>,
) -> Result<ColumnarResult> {
    let registry = transaction_registry();
    let arc = registry
        .get(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    tx.update_activity();

    let conn = tx
        .conn
        .as_mut()
        .ok_or(DriverError::TransactionClosed(tx_id))?;
    conn.query_columnar(sql, params, col_types).await
}

pub async fn execute_statement_in_transaction(
    tx_id: u64,
    sql: &str,
    params: &[Value],
) -> Result<u64> {
    let registry = transaction_registry();
    let arc = registry
        .get(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    tx.update_activity();

    let conn = tx
        .conn
        .as_mut()
        .ok_or(DriverError::TransactionClosed(tx_id))?;
    conn.execute(sql, params).await
}

pub async fn commit_transaction(tx_id: u64) -> Result<()> {
    info!("Committing transaction {}", tx_id);
    let registry = transaction_registry();
    let arc = registry
        .remove(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    if let Some(conn) = tx.conn.as_mut() {
        with_conn!(conn, |c| {
            sqlx::query("COMMIT")
                .execute(c.as_mut())
                .await
                .map_err(|e| DriverError::ExecutionError(format!("COMMIT failed: {}", e)))
                .map(|_| ())?
        });
    }
    tx.state = TransactionState::Committed;
    tx.conn.take();
    Ok(())
}

pub async fn rollback_transaction(tx_id: u64) -> Result<()> {
    info!("Rolling back transaction {}", tx_id);
    let registry = transaction_registry();
    let arc = registry
        .remove(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    if let Some(conn) = tx.conn.as_mut() {
        with_conn!(conn, |c| {
            sqlx::query("ROLLBACK")
                .execute(c.as_mut())
                .await
                .map_err(|e| DriverError::ExecutionError(format!("ROLLBACK failed: {}", e)))
                .map(|_| ())?
        });
    }
    tx.state = TransactionState::RolledBack;
    tx.conn.take();
    Ok(())
}

pub async fn create_savepoint(tx_id: u64, savepoint_name: &str) -> Result<()> {
    info!(
        "Creating savepoint '{}' in transaction {}",
        savepoint_name, tx_id
    );
    let registry = transaction_registry();
    let arc = registry
        .get(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    if let Some(conn) = tx.conn.as_mut() {
        let sql = format!("SAVEPOINT {}", savepoint_name);
        with_conn!(conn, |c| {
            sqlx::query(&sql)
                .execute(c.as_mut())
                .await
                .map_err(|e| DriverError::ExecutionError(format!("SAVEPOINT failed: {}", e)))
                .map(|_| ())?
        });
    }
    Ok(())
}

pub async fn rollback_to_savepoint(tx_id: u64, savepoint_name: &str) -> Result<()> {
    info!(
        "Rolling back to savepoint '{}' in transaction {}",
        savepoint_name, tx_id
    );
    let registry = transaction_registry();
    let arc = registry
        .get(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    if let Some(conn) = tx.conn.as_mut() {
        let sql = format!("ROLLBACK TO SAVEPOINT {}", savepoint_name);
        with_conn!(conn, |c| {
            sqlx::query(&sql)
                .execute(c.as_mut())
                .await
                .map_err(|e| {
                    DriverError::ExecutionError(format!("ROLLBACK TO SAVEPOINT failed: {}", e))
                })
                .map(|_| ())?
        });
    }
    Ok(())
}

pub async fn release_savepoint(tx_id: u64, savepoint_name: &str) -> Result<()> {
    info!(
        "Releasing savepoint '{}' in transaction {}",
        savepoint_name, tx_id
    );
    let registry = transaction_registry();
    let arc = registry
        .get(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }
    if let Some(conn) = tx.conn.as_mut() {
        let sql = format!("RELEASE SAVEPOINT {}", savepoint_name);
        with_conn!(conn, |c| {
            sqlx::query(&sql)
                .execute(c.as_mut())
                .await
                .map_err(|e| {
                    DriverError::ExecutionError(format!("RELEASE SAVEPOINT failed: {}", e))
                })
                .map(|_| ())?
        });
    }
    Ok(())
}

/// Check if profiling is enabled via OXYDE_PROFILE env var
fn is_profiling_enabled() -> bool {
    std::env::var("OXYDE_PROFILE")
        .map(|v| v == "1")
        .unwrap_or(false)
}

pub async fn execute_query(
    pool_name: &str,
    sql: &str,
    params: &[Value],
    col_types: Option<&HashMap<String, String>>,
) -> Result<Vec<HashMap<String, serde_json::Value>>> {
    debug!(
        "Executing query on '{}': {} ({} params, col_types: {})",
        pool_name,
        sql,
        params.len(),
        col_types.is_some()
    );

    let profile = is_profiling_enabled();
    let handle = registry().get(pool_name).await?;
    let pool = handle.clone_pool();

    let start = Instant::now();
    let results = pool.query(sql, params, col_types).await?;
    let elapsed_us = start.elapsed().as_micros();

    if profile {
        eprintln!(
            "[OXYDE_PROFILE] execute_query ({}, {} rows): total={} µs",
            pool.backend_name(),
            results.len(),
            elapsed_us
        );
    }
    debug!(
        "Query on '{}' ({}) returned {} rows",
        pool_name,
        pool.backend_name(),
        results.len()
    );
    Ok(results)
}

/// Execute a SELECT query and return results in columnar format.
/// This is more memory-efficient than execute_query for large result sets:
/// - Column names stored once instead of per-row
/// - No HashMap overhead per row
/// - Smaller msgpack serialization
pub async fn execute_query_columnar(
    pool_name: &str,
    sql: &str,
    params: &[Value],
    col_types: Option<&HashMap<String, String>>,
) -> Result<ColumnarResult> {
    debug!(
        "Executing columnar query on '{}': {} ({} params)",
        pool_name,
        sql,
        params.len()
    );

    let profile = is_profiling_enabled();
    let handle = registry().get(pool_name).await?;
    let pool = handle.clone_pool();

    let start = Instant::now();
    let results = pool.query_columnar(sql, params, col_types).await?;
    let elapsed_us = start.elapsed().as_micros();

    if profile {
        eprintln!(
            "[OXYDE_PROFILE] execute_query_columnar ({}, {} rows): total={} µs",
            pool.backend_name(),
            results.1.len(),
            elapsed_us
        );
    }
    Ok(results)
}

pub async fn execute_statement(pool_name: &str, sql: &str, params: &[Value]) -> Result<u64> {
    debug!(
        "Executing statement on '{}': {} ({} params)",
        pool_name,
        sql,
        params.len()
    );

    let handle = registry().get(pool_name).await?;
    let pool = handle.clone_pool();
    let affected = pool.execute(sql, params).await?;

    debug!(
        "Statement on '{}' ({}) affected {} rows",
        pool_name,
        pool.backend_name(),
        affected
    );
    Ok(affected)
}

/// Execute INSERT and return generated IDs (supports any PK type: i64, UUID, String, etc.)
///
/// # Arguments
/// * `pool_name` - Database pool name
/// * `sql` - INSERT SQL statement
/// * `params` - Query parameters
/// * `pk_column` - Primary key column name (defaults to "id" if None)
pub async fn execute_insert_returning(
    pool_name: &str,
    sql: &str,
    params: &[Value],
    pk_column: Option<&str>,
) -> Result<Vec<serde_json::Value>> {
    let pk_col = pk_column.unwrap_or("id");
    debug!(
        "Executing INSERT RETURNING on '{}': {} ({} params, pk={})",
        pool_name,
        sql,
        params.len(),
        pk_col
    );

    let handle = registry().get(pool_name).await?;
    match handle.clone_pool() {
        DbPool::Postgres(pool) => {
            // PostgreSQL: Use SQL as-is if it has RETURNING, else add RETURNING {pk_col}
            let has_returning = sql.to_uppercase().contains("RETURNING");
            let returning_sql = if has_returning {
                sql.to_string()
            } else {
                format!("{} RETURNING \"{}\"", sql, pk_col)
            };

            let query = bind_postgres(sqlx::query(&returning_sql), params)?;
            let rows = query.fetch_all(&pool).await.map_err(|e| {
                DriverError::ExecutionError(format!("INSERT RETURNING failed: {}", e))
            })?;

            // Extract PK values using batch row conversion
            let row_maps = convert_pg_rows(rows);
            let ids: Vec<serde_json::Value> = row_maps
                .into_iter()
                .filter_map(|row_map| row_map.get(pk_col).cloned().filter(|v| !v.is_null()))
                .collect();

            debug!(
                "INSERT on '{}' (Postgres) returned {} IDs",
                pool_name,
                ids.len()
            );
            Ok(ids)
        }
        DbPool::MySql(pool) => {
            // MySQL: Execute INSERT, then compute ID range from last_insert_id
            // Note: MySQL doesn't support RETURNING, so we can only get numeric auto-increment IDs
            let query = bind_mysql(sqlx::query(sql), params)?;
            let result = query
                .execute(&pool)
                .await
                .map_err(|e| DriverError::ExecutionError(format!("INSERT failed: {}", e)))?;

            let rows_affected = result.rows_affected() as i64;
            let last_id = result.last_insert_id() as i64;

            // MySQL last_insert_id() returns the FIRST auto-generated ID
            // Generate ID range: [first_id .. first_id + rows)
            let ids: Vec<serde_json::Value> = if rows_affected > 0 && last_id > 0 {
                (last_id..last_id + rows_affected)
                    .map(|id| serde_json::Value::Number(serde_json::Number::from(id)))
                    .collect()
            } else {
                vec![]
            };

            debug!(
                "INSERT on '{}' (MySQL) affected {} rows, last_id={}, generated {} IDs",
                pool_name,
                rows_affected,
                last_id,
                ids.len()
            );
            Ok(ids)
        }
        DbPool::Sqlite(pool) => {
            // SQLite: Try RETURNING first (SQLite 3.35+), fallback to last_insert_rowid
            let has_returning = sql.to_uppercase().contains("RETURNING");
            let returning_sql = if has_returning {
                sql.to_string()
            } else {
                format!("{} RETURNING \"{}\"", sql, pk_col)
            };

            let query = bind_sqlite(sqlx::query(&returning_sql), params)?;

            // Try RETURNING first
            match query.fetch_all(&pool).await {
                Ok(rows) => {
                    // RETURNING is supported - extract PK values using batch row conversion
                    let row_maps = convert_sqlite_rows(rows);
                    let ids: Vec<serde_json::Value> = row_maps
                        .into_iter()
                        .filter_map(|row_map| row_map.get(pk_col).cloned().filter(|v| !v.is_null()))
                        .collect();

                    debug!(
                        "INSERT on '{}' (SQLite) returned {} IDs via RETURNING",
                        pool_name,
                        ids.len()
                    );
                    Ok(ids)
                }
                Err(_) => {
                    // RETURNING not supported - fallback to last_insert_rowid (only works for INTEGER PK)
                    warn!(
                        "SQLite RETURNING not supported (version < 3.35), falling back to last_insert_rowid. \
                        This only works for INTEGER PRIMARY KEY and may produce incorrect IDs with concurrent inserts."
                    );

                    let query = bind_sqlite(sqlx::query(sql), params)?;
                    let result = query.execute(&pool).await.map_err(|e| {
                        DriverError::ExecutionError(format!("INSERT failed: {}", e))
                    })?;

                    let rows_affected = result.rows_affected() as i64;
                    let last_id = result.last_insert_rowid();

                    let ids: Vec<serde_json::Value> = if rows_affected > 0 && last_id > 0 {
                        (last_id - rows_affected + 1..=last_id)
                            .map(|id| serde_json::Value::Number(serde_json::Number::from(id)))
                            .collect()
                    } else {
                        vec![]
                    };

                    debug!(
                        "INSERT on '{}' (SQLite) affected {} rows, last_id={}, generated {} IDs via fallback",
                        pool_name, rows_affected, last_id, ids.len()
                    );
                    Ok(ids)
                }
            }
        }
    }
}

/// Execute INSERT within a transaction and return generated IDs (supports any PK type)
///
/// # Arguments
/// * `tx_id` - Transaction ID
/// * `sql` - INSERT SQL statement
/// * `params` - Query parameters
/// * `pk_column` - Primary key column name (defaults to "id" if None)
pub async fn execute_insert_returning_in_transaction(
    tx_id: u64,
    sql: &str,
    params: &[Value],
    pk_column: Option<&str>,
) -> Result<Vec<serde_json::Value>> {
    let pk_col = pk_column.unwrap_or("id");
    let registry = transaction_registry();
    let arc = registry
        .get(tx_id)
        .await
        .ok_or(DriverError::TransactionNotFound(tx_id))?;
    let mut tx = arc.lock().await;
    if !tx.is_active() {
        return Err(DriverError::TransactionClosed(tx_id));
    }

    // Update activity timestamp to prevent premature cleanup
    tx.update_activity();

    let conn = tx
        .conn
        .as_mut()
        .ok_or(DriverError::TransactionClosed(tx_id))?;

    match conn {
        DbConn::Postgres(conn) => {
            // PostgreSQL: Use SQL as-is if it has RETURNING, else add RETURNING {pk_col}
            let has_returning = sql.to_uppercase().contains("RETURNING");
            let returning_sql = if has_returning {
                sql.to_string()
            } else {
                format!("{} RETURNING \"{}\"", sql, pk_col)
            };

            let query = bind_postgres(sqlx::query(&returning_sql), params)?;
            let rows = query.fetch_all(conn.as_mut()).await.map_err(|e| {
                DriverError::ExecutionError(format!("INSERT RETURNING failed: {}", e))
            })?;

            // Extract PK values using batch row conversion
            let row_maps = convert_pg_rows(rows);
            let ids: Vec<serde_json::Value> = row_maps
                .into_iter()
                .filter_map(|row_map| row_map.get(pk_col).cloned().filter(|v| !v.is_null()))
                .collect();

            debug!(
                "INSERT in transaction {} (Postgres) returned {} IDs",
                tx_id,
                ids.len()
            );
            Ok(ids)
        }
        DbConn::MySql(conn) => {
            // MySQL: Execute INSERT, then compute ID range from last_insert_id
            // Note: MySQL doesn't support RETURNING, so we can only get numeric auto-increment IDs
            let query = bind_mysql(sqlx::query(sql), params)?;
            let result = query
                .execute(conn.as_mut())
                .await
                .map_err(|e| DriverError::ExecutionError(format!("INSERT failed: {}", e)))?;

            let rows_affected = result.rows_affected() as i64;
            let last_id = result.last_insert_id() as i64;

            // MySQL last_insert_id() returns the FIRST auto-generated ID
            let ids: Vec<serde_json::Value> = if rows_affected > 0 && last_id > 0 {
                (last_id..last_id + rows_affected)
                    .map(|id| serde_json::Value::Number(serde_json::Number::from(id)))
                    .collect()
            } else {
                vec![]
            };

            debug!(
                "INSERT in transaction {} (MySQL) affected {} rows, first_id={}, generated {} IDs",
                tx_id,
                rows_affected,
                last_id,
                ids.len()
            );
            Ok(ids)
        }
        DbConn::Sqlite(conn) => {
            // SQLite: Try RETURNING first (SQLite 3.35+), fallback to last_insert_rowid
            let has_returning = sql.to_uppercase().contains("RETURNING");
            let returning_sql = if has_returning {
                sql.to_string()
            } else {
                format!("{} RETURNING \"{}\"", sql, pk_col)
            };

            let query = bind_sqlite(sqlx::query(&returning_sql), params)?;

            match query.fetch_all(conn.as_mut()).await {
                Ok(rows) => {
                    // RETURNING is supported - extract PK values using batch row conversion
                    let row_maps = convert_sqlite_rows(rows);
                    let ids: Vec<serde_json::Value> = row_maps
                        .into_iter()
                        .filter_map(|row_map| row_map.get(pk_col).cloned().filter(|v| !v.is_null()))
                        .collect();

                    debug!(
                        "INSERT in transaction {} (SQLite) returned {} IDs via RETURNING",
                        tx_id,
                        ids.len()
                    );
                    Ok(ids)
                }
                Err(_) => {
                    // RETURNING not supported - fallback to last_insert_rowid (only works for INTEGER PK)
                    warn!(
                        "SQLite RETURNING not supported (version < 3.35), falling back to last_insert_rowid. \
                        This only works for INTEGER PRIMARY KEY and may produce incorrect IDs with concurrent inserts."
                    );

                    let query = bind_sqlite(sqlx::query(sql), params)?;
                    let result = query.execute(conn.as_mut()).await.map_err(|e| {
                        DriverError::ExecutionError(format!("INSERT failed: {}", e))
                    })?;

                    let rows_affected = result.rows_affected() as i64;
                    let last_id = result.last_insert_rowid();

                    let ids: Vec<serde_json::Value> = if rows_affected > 0 && last_id > 0 {
                        (last_id - rows_affected + 1..=last_id)
                            .map(|id| serde_json::Value::Number(serde_json::Number::from(id)))
                            .collect()
                    } else {
                        vec![]
                    };

                    debug!(
                        "INSERT in transaction {} (SQLite) affected {} rows, last_id={}, generated {} IDs via fallback",
                        tx_id, rows_affected, last_id, ids.len()
                    );
                    Ok(ids)
                }
            }
        }
    }
}

pub async fn explain_query(
    pool_name: &str,
    sql: &str,
    params: &[Value],
    options: ExplainOptions,
) -> Result<serde_json::Value> {
    let backend = pool_backend(pool_name).await?;
    let explain_sql = match backend {
        DatabaseBackend::Postgres => build_postgres_explain_sql(sql, &options)?,
        DatabaseBackend::MySql => build_mysql_explain_sql(sql, &options)?,
        DatabaseBackend::Sqlite => build_sqlite_explain_sql(sql, &options)?,
    };

    let rows = execute_query(pool_name, &explain_sql, params, None).await?;

    let payload = match backend {
        DatabaseBackend::Postgres => match options.format {
            ExplainFormat::Json => extract_postgres_json_plan(rows),
            ExplainFormat::Text => extract_text_plan(rows, "QUERY PLAN"),
        },
        DatabaseBackend::MySql => match options.format {
            ExplainFormat::Json => extract_mysql_json_plan(rows),
            ExplainFormat::Text => rows_to_objects(rows),
        },
        DatabaseBackend::Sqlite => rows_to_objects(rows),
    };

    Ok(payload)
}

fn backend_from_url(url: &str) -> Option<DatabaseBackend> {
    if url.starts_with("postgres") {
        Some(DatabaseBackend::Postgres)
    } else if url.starts_with("mysql") {
        Some(DatabaseBackend::MySql)
    } else if url.starts_with("sqlite") {
        Some(DatabaseBackend::Sqlite)
    } else {
        None
    }
}

fn validate_settings(settings: &PoolSettings) -> Result<()> {
    if let (Some(min), Some(max)) = (settings.min_connections, settings.max_connections) {
        if min > max {
            return Err(DriverError::InvalidPoolSettings(
                "min_connections cannot exceed max_connections".into(),
            ));
        }
    }

    Ok(())
}

fn apply_common_settings_pg(mut options: PgPoolOptions, settings: &PoolSettings) -> PgPoolOptions {
    if let Some(max) = settings.max_connections {
        options = options.max_connections(max);
    }
    if let Some(min) = settings.min_connections {
        options = options.min_connections(min);
    }
    if let Some(timeout) = settings.acquire_timeout {
        options = options.acquire_timeout(timeout);
    }
    if let Some(timeout) = settings.idle_timeout {
        options = options.idle_timeout(timeout);
    }
    if let Some(lifetime) = settings.max_lifetime {
        options = options.max_lifetime(lifetime);
    }
    options
}

fn apply_common_settings_mysql(
    mut options: MySqlPoolOptions,
    settings: &PoolSettings,
) -> MySqlPoolOptions {
    if let Some(max) = settings.max_connections {
        options = options.max_connections(max);
    }
    if let Some(min) = settings.min_connections {
        options = options.min_connections(min);
    }
    if let Some(timeout) = settings.acquire_timeout {
        options = options.acquire_timeout(timeout);
    }
    if let Some(timeout) = settings.idle_timeout {
        options = options.idle_timeout(timeout);
    }
    if let Some(lifetime) = settings.max_lifetime {
        options = options.max_lifetime(lifetime);
    }
    if let Some(test_before) = settings.test_before_acquire {
        options = options.test_before_acquire(test_before);
    }
    options
}

fn apply_common_settings_sqlite(
    mut options: SqlitePoolOptions,
    settings: &PoolSettings,
) -> SqlitePoolOptions {
    if let Some(max) = settings.max_connections {
        options = options.max_connections(max);
    }
    if let Some(min) = settings.min_connections {
        options = options.min_connections(min);
    }
    if let Some(timeout) = settings.acquire_timeout {
        options = options.acquire_timeout(timeout);
    }
    if let Some(timeout) = settings.idle_timeout {
        options = options.idle_timeout(timeout);
    }
    if let Some(lifetime) = settings.max_lifetime {
        options = options.max_lifetime(lifetime);
    }

    options
}

#[cfg(test)]
mod tests {
    use super::*;
    use once_cell::sync::Lazy;
    use std::time::Duration;
    use tokio::sync::Mutex as AsyncMutex;

    static TEST_MUTEX: Lazy<AsyncMutex<()>> = Lazy::new(|| AsyncMutex::new(()));

    fn sqlite_settings() -> PoolSettings {
        PoolSettings {
            max_connections: Some(1),
            min_connections: Some(1),
            idle_timeout: None,
            acquire_timeout: Some(Duration::from_secs(5)),
            max_lifetime: None,
            test_before_acquire: Some(false),
            transaction_timeout: None,
            transaction_cleanup_interval: None,
            sqlite_journal_mode: None,
            sqlite_synchronous: None,
            sqlite_cache_size: None,
            sqlite_busy_timeout: None,
        }
    }

    #[tokio::test]
    async fn init_and_close_multiple_pools() {
        let _guard = TEST_MUTEX.lock().await;
        close_all_pools().await.unwrap();

        init_pool("default", "sqlite::memory:", sqlite_settings())
            .await
            .unwrap();
        init_pool("analytics", "sqlite::memory:", sqlite_settings())
            .await
            .unwrap();

        // Simple statement against each pool
        execute_statement("default", "CREATE TABLE foo (id INTEGER)", &[])
            .await
            .unwrap();
        execute_statement("analytics", "CREATE TABLE bar (id INTEGER)", &[])
            .await
            .unwrap();

        // Duplicate name should error
        assert!(matches!(
            init_pool("default", "sqlite::memory:", sqlite_settings()).await,
            Err(DriverError::PoolAlreadyExists(_))
        ));

        close_pool("default").await.unwrap();
        close_pool("analytics").await.unwrap();

        // Closing twice should error
        assert!(matches!(
            close_pool("default").await,
            Err(DriverError::PoolNotFound(_))
        ));
    }

    #[tokio::test]
    async fn execute_with_parameters_sqlite() {
        let _guard = TEST_MUTEX.lock().await;
        close_all_pools().await.unwrap();

        init_pool("default", "sqlite::memory:", sqlite_settings())
            .await
            .unwrap();

        execute_statement(
            "default",
            "CREATE TABLE foo (id INTEGER PRIMARY KEY, name TEXT)",
            &[],
        )
        .await
        .unwrap();

        execute_statement(
            "default",
            "INSERT INTO foo (id, name) VALUES (?, ?)",
            &[Value::from(1_i64), Value::from(String::from("Ada"))],
        )
        .await
        .unwrap();

        let rows = execute_query(
            "default",
            "SELECT name FROM foo WHERE id = ?",
            &[Value::from(1_i64)],
            None,
        )
        .await
        .unwrap();

        assert_eq!(rows.len(), 1);
        assert_eq!(
            rows[0].get("name"),
            Some(&serde_json::Value::String("Ada".to_string()))
        );

        close_pool("default").await.unwrap();
    }

    #[tokio::test]
    async fn transaction_commit_sqlite() {
        let _guard = TEST_MUTEX.lock().await;
        close_all_pools().await.unwrap();

        init_pool("default", "sqlite::memory:", sqlite_settings())
            .await
            .unwrap();

        execute_statement(
            "default",
            "CREATE TABLE foo (id INTEGER PRIMARY KEY, name TEXT)",
            &[],
        )
        .await
        .unwrap();

        let tx_id = begin_transaction("default").await.unwrap();
        execute_statement_in_transaction(
            tx_id,
            "INSERT INTO foo (id, name) VALUES (?, ?)",
            &[Value::from(10_i64), Value::from(String::from("Commit"))],
        )
        .await
        .unwrap();
        commit_transaction(tx_id).await.unwrap();

        let rows = execute_query(
            "default",
            "SELECT name FROM foo WHERE id = ?",
            &[Value::from(10_i64)],
            None,
        )
        .await
        .unwrap();
        assert_eq!(rows.len(), 1);
        assert_eq!(
            rows[0].get("name"),
            Some(&serde_json::Value::String("Commit".to_string()))
        );

        close_pool("default").await.unwrap();
    }

    #[tokio::test]
    async fn transaction_rollback_sqlite() {
        let _guard = TEST_MUTEX.lock().await;
        close_all_pools().await.unwrap();

        init_pool("default", "sqlite::memory:", sqlite_settings())
            .await
            .unwrap();

        execute_statement(
            "default",
            "CREATE TABLE foo (id INTEGER PRIMARY KEY, name TEXT)",
            &[],
        )
        .await
        .unwrap();

        let tx_id = begin_transaction("default").await.unwrap();
        execute_statement_in_transaction(
            tx_id,
            "INSERT INTO foo (id, name) VALUES (?, ?)",
            &[Value::from(11_i64), Value::from(String::from("Rollback"))],
        )
        .await
        .unwrap();
        rollback_transaction(tx_id).await.unwrap();

        let rows = execute_query(
            "default",
            "SELECT name FROM foo WHERE id = ?",
            &[Value::from(11_i64)],
            None,
        )
        .await
        .unwrap();
        assert!(rows.is_empty());

        close_pool("default").await.unwrap();
    }
}
