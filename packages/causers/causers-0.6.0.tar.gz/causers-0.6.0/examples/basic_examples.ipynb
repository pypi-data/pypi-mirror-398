{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# causers Basic Examples\n",
    "\n",
    "This notebook demonstrates the four main API functions in the `causers` package:\n",
    "\n",
    "1. **Linear Regression** with clustered standard errors\n",
    "2. **Logistic Regression** with clustered standard errors  \n",
    "3. **Synthetic Control** for single treated unit\n",
    "4. **Synthetic Difference-in-Differences** for panel data\n",
    "\n",
    "All examples use synthetic data with fixed random seeds for reproducibility.\n",
    "\n",
    "**Requirements**: `causers`, `polars`, `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:53:30.253539Z",
     "iopub.status.busy": "2025-12-27T15:53:30.253391Z",
     "iopub.status.idle": "2025-12-27T15:53:30.384614Z",
     "shell.execute_reply": "2025-12-27T15:53:30.384193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causers version: 0.6.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Import required packages.\"\"\"\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import causers\n",
    "\n",
    "print(f\"causers version: {causers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression with Clustered Standard Errors\n",
    "\n",
    "This example demonstrates:\n",
    "- Multiple covariate regression (3 predictors)\n",
    "- Clustered standard errors for panel/grouped data\n",
    "- Non-trivial R² (between 0 and 1)\n",
    "\n",
    "**Data Generating Process (DGP)**:\n",
    "- 100 observations across 10 clusters (10 obs per cluster)\n",
    "- True coefficients: β₁=2.0, β₂=-1.5, β₃=0.8, intercept=5.0\n",
    "- Within-cluster correlation via cluster-specific intercepts\n",
    "- Gaussian noise with σ=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:53:30.399750Z",
     "iopub.status.busy": "2025-12-27T15:53:30.399604Z",
     "iopub.status.idle": "2025-12-27T15:53:30.509989Z",
     "shell.execute_reply": "2025-12-27T15:53:30.509572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (100, 5)\n",
      "Clusters: 10\n",
      "Observations per cluster: 10\n",
      "\n",
      "==================================================\n",
      "LINEAR REGRESSION RESULTS\n",
      "==================================================\n",
      "Observations: 100\n",
      "Clusters: 10\n",
      "SE Type: analytical\n",
      "\n",
      "Coefficients:\n",
      "  x1:   1.5363 ± 0.1723  (true: 2.0)\n",
      "  x2:  -1.6280 ± 0.2134  (true: -1.5)\n",
      "  x3:   0.9113 ± 0.1609  (true: 0.8)\n",
      "  Intercept:   5.7515 ± 0.3909  (true: 5.0)\n",
      "\n",
      "R-squared: 0.6339\n",
      "\n",
      "✅ All validation checks passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/m1_drbkj7r53yw9cpj1kvwvm0000gn/T/ipykernel_71450/998715974.py:45: UserWarning: Only 10 clusters detected. Wild cluster bootstrap (bootstrap=True) is recommended when clusters < 42.\n",
      "  result = causers.linear_regression(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Linear regression with clustered standard errors.\"\"\"\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data parameters\n",
    "n_obs = 100\n",
    "n_clusters = 10\n",
    "obs_per_cluster = n_obs // n_clusters\n",
    "\n",
    "# True coefficients\n",
    "beta_1, beta_2, beta_3, intercept = 2.0, -1.5, 0.8, 5.0\n",
    "\n",
    "# Generate cluster IDs and cluster-specific intercepts\n",
    "cluster_ids = np.repeat(np.arange(n_clusters), obs_per_cluster)\n",
    "cluster_effects = np.random.normal(0, 1.5, n_clusters)  # Within-cluster correlation\n",
    "\n",
    "# Generate covariates\n",
    "x1 = np.random.normal(0, 1, n_obs)\n",
    "x2 = np.random.normal(0, 1, n_obs)\n",
    "x3 = np.random.normal(0, 1, n_obs)\n",
    "\n",
    "# Generate outcome with cluster effects and noise\n",
    "y = (intercept \n",
    "     + beta_1 * x1 \n",
    "     + beta_2 * x2 \n",
    "     + beta_3 * x3 \n",
    "     + cluster_effects[cluster_ids]  # Cluster-specific intercepts\n",
    "     + np.random.normal(0, 2.0, n_obs))  # Idiosyncratic noise\n",
    "\n",
    "# Create DataFrame\n",
    "df = pl.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"x3\": x3,\n",
    "    \"y\": y,\n",
    "    \"cluster_id\": cluster_ids.astype(int)\n",
    "})\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Clusters: {df['cluster_id'].n_unique()}\")\n",
    "print(f\"Observations per cluster: {obs_per_cluster}\")\n",
    "print()\n",
    "\n",
    "# Run regression with clustered standard errors\n",
    "result = causers.linear_regression(\n",
    "    df, \n",
    "    x_cols=[\"x1\", \"x2\", \"x3\"], \n",
    "    y_col=\"y\", \n",
    "    cluster=\"cluster_id\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 50)\n",
    "print(\"LINEAR REGRESSION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Observations: {result.n_samples}\")\n",
    "print(f\"Clusters: {result.n_clusters}\")\n",
    "print(f\"SE Type: {result.cluster_se_type}\")\n",
    "print()\n",
    "print(\"Coefficients:\")\n",
    "print(f\"  x1: {result.coefficients[0]:8.4f} ± {result.standard_errors[0]:.4f}  (true: {beta_1})\")\n",
    "print(f\"  x2: {result.coefficients[1]:8.4f} ± {result.standard_errors[1]:.4f}  (true: {beta_2})\")\n",
    "print(f\"  x3: {result.coefficients[2]:8.4f} ± {result.standard_errors[2]:.4f}  (true: {beta_3})\")\n",
    "print(f\"  Intercept: {result.intercept:8.4f} ± {result.intercept_se:.4f}  (true: {intercept})\")\n",
    "print()\n",
    "print(f\"R-squared: {result.r_squared:.4f}\")\n",
    "\n",
    "# Verify constraints for DoD\n",
    "assert 0.0 < result.r_squared < 1.0, \"R² should be strictly between 0 and 1\"\n",
    "assert all(se > 0 for se in result.standard_errors), \"All SEs should be > 0\"\n",
    "assert result.n_clusters >= 5, \"Should have at least 5 clusters\"\n",
    "print(\"\\n✅ All validation checks passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression with Clustered Standard Errors\n",
    "\n",
    "This example demonstrates:\n",
    "- Binary outcome regression (0/1)\n",
    "- Multiple covariates (2 predictors)\n",
    "- Clustered standard errors\n",
    "- Balanced classes (~50/50 split)\n",
    "\n",
    "**Data Generating Process (DGP)**:\n",
    "- 100 observations across 10 clusters\n",
    "- True coefficients: β₁=1.0, β₂=-0.5, intercept=-0.2\n",
    "- Outcome via logistic transformation: P(y=1|x) = 1/(1+exp(-xβ))\n",
    "- Class balance maintained via intercept calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:53:30.511104Z",
     "iopub.status.busy": "2025-12-27T15:53:30.511004Z",
     "iopub.status.idle": "2025-12-27T15:53:30.515815Z",
     "shell.execute_reply": "2025-12-27T15:53:30.515471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (100, 4)\n",
      "Clusters: 10\n",
      "Class balance: 44.0% positive (target: 30-70%)\n",
      "\n",
      "==================================================\n",
      "LOGISTIC REGRESSION RESULTS\n",
      "==================================================\n",
      "Observations: 100\n",
      "Clusters: 10\n",
      "SE Type: analytical\n",
      "Converged: True (6 iterations)\n",
      "\n",
      "Coefficients (log-odds):\n",
      "  x1:   1.2492 ± 0.4258  (true: 1.0)\n",
      "  x2:  -1.0098 ± 0.2344  (true: -0.5)\n",
      "  Intercept:  -0.2660 ± 0.2005  (true: -0.2)\n",
      "\n",
      "Pseudo R-squared (McFadden): 0.2402\n",
      "Log-likelihood: -52.1204\n",
      "\n",
      "✅ All validation checks passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/m1_drbkj7r53yw9cpj1kvwvm0000gn/T/ipykernel_71450/2028631674.py:43: UserWarning: Only 10 clusters detected. Score bootstrap (bootstrap=True) is recommended when clusters < 42.\n",
      "  result = causers.logistic_regression(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Logistic regression with clustered standard errors.\"\"\"\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data parameters\n",
    "n_obs = 100\n",
    "n_clusters = 10\n",
    "obs_per_cluster = n_obs // n_clusters\n",
    "\n",
    "# True coefficients (chosen for ~balanced classes)\n",
    "beta_1, beta_2, intercept = 1.0, -0.5, -0.2\n",
    "\n",
    "# Generate cluster IDs\n",
    "cluster_ids = np.repeat(np.arange(n_clusters), obs_per_cluster)\n",
    "\n",
    "# Generate covariates\n",
    "x1 = np.random.normal(0, 1, n_obs)\n",
    "x2 = np.random.normal(0, 1, n_obs)\n",
    "\n",
    "# Compute linear predictor\n",
    "linear_pred = intercept + beta_1 * x1 + beta_2 * x2\n",
    "\n",
    "# Generate binary outcome via logistic model\n",
    "prob = 1 / (1 + np.exp(-linear_pred))\n",
    "y = (np.random.uniform(0, 1, n_obs) < prob).astype(float)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pl.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y,\n",
    "    \"cluster_id\": cluster_ids.astype(int)\n",
    "})\n",
    "\n",
    "# Check class balance\n",
    "class_1_pct = y.mean() * 100\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Clusters: {df['cluster_id'].n_unique()}\")\n",
    "print(f\"Class balance: {class_1_pct:.1f}% positive (target: 30-70%)\")\n",
    "print()\n",
    "\n",
    "# Run logistic regression with clustered standard errors\n",
    "result = causers.logistic_regression(\n",
    "    df,\n",
    "    x_cols=[\"x1\", \"x2\"],\n",
    "    y_col=\"y\",\n",
    "    cluster=\"cluster_id\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 50)\n",
    "print(\"LOGISTIC REGRESSION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Observations: {result.n_samples}\")\n",
    "print(f\"Clusters: {result.n_clusters}\")\n",
    "print(f\"SE Type: {result.cluster_se_type}\")\n",
    "print(f\"Converged: {result.converged} ({result.iterations} iterations)\")\n",
    "print()\n",
    "print(\"Coefficients (log-odds):\")\n",
    "print(f\"  x1: {result.coefficients[0]:8.4f} ± {result.standard_errors[0]:.4f}  (true: {beta_1})\")\n",
    "print(f\"  x2: {result.coefficients[1]:8.4f} ± {result.standard_errors[1]:.4f}  (true: {beta_2})\")\n",
    "print(f\"  Intercept: {result.intercept:8.4f} ± {result.intercept_se:.4f}  (true: {intercept})\")\n",
    "print()\n",
    "print(f\"Pseudo R-squared (McFadden): {result.pseudo_r_squared:.4f}\")\n",
    "print(f\"Log-likelihood: {result.log_likelihood:.4f}\")\n",
    "\n",
    "# Verify constraints\n",
    "assert result.converged, \"Model should converge\"\n",
    "assert all(se > 0 for se in result.standard_errors), \"All SEs should be > 0\"\n",
    "assert result.n_clusters >= 5, \"Should have at least 5 clusters\"\n",
    "assert 30 <= class_1_pct <= 70, \"Classes should be balanced (30-70%)\"\n",
    "print(\"\\n✅ All validation checks passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Synthetic Control (Single Treated Unit)\n",
    "\n",
    "This example demonstrates:\n",
    "- Panel data structure (units × time periods)\n",
    "- Single treated unit with multiple controls\n",
    "- Pre-treatment fit quality (RMSE > 0)\n",
    "- In-space placebo standard errors\n",
    "\n",
    "**Data Generating Process (DGP)**:\n",
    "- 10 units (1 treated, 9 controls) observed over 8 periods\n",
    "- Treatment begins in period 6 (3 post-treatment periods)\n",
    "- Common time trend + unit-specific levels + noise\n",
    "- Treatment effect: ATT = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:53:30.516841Z",
     "iopub.status.busy": "2025-12-27T15:53:30.516773Z",
     "iopub.status.idle": "2025-12-27T15:53:30.536066Z",
     "shell.execute_reply": "2025-12-27T15:53:30.535661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel dimensions: 10 units × 8 periods = 80 obs\n",
      "Treated units: 1, Control units: 9\n",
      "Pre-treatment periods: 5, Post-treatment periods: 3\n",
      "\n",
      "==================================================\n",
      "SYNTHETIC CONTROL RESULTS\n",
      "==================================================\n",
      "Method: traditional\n",
      "Control units: 9\n",
      "Pre-treatment periods: 5\n",
      "Post-treatment periods: 3\n",
      "\n",
      "ATT: 4.5243 ± 0.8091  (true: 5.0)\n",
      "Pre-treatment RMSE: 0.1575\n",
      "\n",
      "Unit weights (top 3):\n",
      "  Control unit 5: 0.3733\n",
      "  Control unit 0: 0.2903\n",
      "  Control unit 3: 0.2736\n",
      "\n",
      "Solver converged: True (1000 iterations)\n",
      "\n",
      "✅ All validation checks passed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Synthetic control with single treated unit.\"\"\"\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Panel dimensions\n",
    "n_units = 10\n",
    "n_periods = 8\n",
    "n_pre = 5       # Pre-treatment periods (1-5)\n",
    "n_post = 3      # Post-treatment periods (6-8)\n",
    "treated_unit = 0  # Unit 0 is treated\n",
    "\n",
    "# True treatment effect\n",
    "true_att = 5.0\n",
    "\n",
    "# Unit-specific fixed effects (different levels)\n",
    "unit_effects = np.random.uniform(5, 15, n_units)\n",
    "\n",
    "# Time trend (common to all units)\n",
    "time_trend = np.arange(n_periods) * 0.5\n",
    "\n",
    "# Generate panel data\n",
    "data = {\"unit\": [], \"time\": [], \"outcome\": [], \"treated\": []}\n",
    "\n",
    "for unit in range(n_units):\n",
    "    for t in range(n_periods):\n",
    "        outcome = unit_effects[unit] + time_trend[t] + np.random.normal(0, 0.5)\n",
    "        \n",
    "        # Add treatment effect for treated unit in post-period\n",
    "        is_treated = (unit == treated_unit) and (t >= n_pre)\n",
    "        if is_treated:\n",
    "            outcome += true_att\n",
    "        \n",
    "        data[\"unit\"].append(unit)\n",
    "        data[\"time\"].append(t)\n",
    "        data[\"outcome\"].append(outcome)\n",
    "        data[\"treated\"].append(1 if is_treated else 0)\n",
    "\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Summary stats\n",
    "n_control = n_units - 1\n",
    "print(f\"Panel dimensions: {n_units} units × {n_periods} periods = {len(df)} obs\")\n",
    "print(f\"Treated units: 1, Control units: {n_control}\")\n",
    "print(f\"Pre-treatment periods: {n_pre}, Post-treatment periods: {n_post}\")\n",
    "print()\n",
    "\n",
    "# Run synthetic control\n",
    "result = causers.synthetic_control(\n",
    "    df,\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    outcome_col=\"outcome\",\n",
    "    treatment_col=\"treated\",\n",
    "    method=\"traditional\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 50)\n",
    "print(\"SYNTHETIC CONTROL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Method: {result.method}\")\n",
    "print(f\"Control units: {result.n_units_control}\")\n",
    "print(f\"Pre-treatment periods: {result.n_periods_pre}\")\n",
    "print(f\"Post-treatment periods: {result.n_periods_post}\")\n",
    "print()\n",
    "print(f\"ATT: {result.att:.4f} ± {result.standard_error:.4f}  (true: {true_att})\")\n",
    "print(f\"Pre-treatment RMSE: {result.pre_treatment_rmse:.4f}\")\n",
    "print()\n",
    "print(f\"Unit weights (top 3):\")\n",
    "weights_sorted = sorted(enumerate(result.unit_weights), key=lambda x: -x[1])\n",
    "for idx, weight in weights_sorted[:3]:\n",
    "    print(f\"  Control unit {idx}: {weight:.4f}\")\n",
    "print()\n",
    "print(f\"Solver converged: {result.solver_converged} ({result.solver_iterations} iterations)\")\n",
    "\n",
    "# Verify constraints\n",
    "assert result.standard_error > 0, \"SE should be > 0\"\n",
    "assert result.pre_treatment_rmse > 0, \"Pre-treatment RMSE should be > 0\"\n",
    "assert result.n_units_control >= 3, \"Should have at least 3 control units\"\n",
    "assert result.n_periods_pre >= 3, \"Should have at least 3 pre-treatment periods\"\n",
    "print(\"\\n✅ All validation checks passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthetic Difference-in-Differences\n",
    "\n",
    "This example demonstrates:\n",
    "- Panel data with multiple treated units\n",
    "- Time and unit weight optimization\n",
    "- Placebo bootstrap standard errors\n",
    "- Pre-treatment fit quality (RMSE > 0)\n",
    "\n",
    "**Data Generating Process (DGP)**:\n",
    "- 12 units (3 treated, 9 controls) observed over 6 periods\n",
    "- Treatment begins in period 4 (3 post-treatment periods)\n",
    "- Heterogeneous unit trends + common shocks + noise\n",
    "- Treatment effect: ATT = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T15:53:30.537067Z",
     "iopub.status.busy": "2025-12-27T15:53:30.537006Z",
     "iopub.status.idle": "2025-12-27T15:53:30.542785Z",
     "shell.execute_reply": "2025-12-27T15:53:30.542356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel dimensions: 12 units × 6 periods = 72 obs\n",
      "Treated units: 3, Control units: 9\n",
      "Pre-treatment periods: 3, Post-treatment periods: 3\n",
      "\n",
      "==================================================\n",
      "SYNTHETIC DID RESULTS\n",
      "==================================================\n",
      "Control units: 9\n",
      "Treated units: 3\n",
      "Pre-treatment periods: 3\n",
      "Post-treatment periods: 3\n",
      "\n",
      "ATT: 2.9655 ± 0.1958  (true: 3.0)\n",
      "Pre-treatment fit (RMSE): 0.0780\n",
      "Bootstrap iterations used: 200\n",
      "\n",
      "Solver converged: True\n",
      "Solver iterations: (200, 200)\n",
      "\n",
      "Unit weights (control): min=0.0483, max=0.2270\n",
      "Time weights (pre-period): min=0.0000, max=1.0000\n",
      "\n",
      "✅ All validation checks passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/m1_drbkj7r53yw9cpj1kvwvm0000gn/T/ipykernel_71450/2930477713.py:55: UserWarning: Time weight concentration: pre-period at index 2 has weight 100.00%. Results may be sensitive to this period.\n",
      "  result = causers.synthetic_did(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Synthetic Difference-in-Differences with multiple treated units.\"\"\"\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Panel dimensions\n",
    "n_units = 12\n",
    "n_periods = 6\n",
    "n_pre = 3       # Pre-treatment periods (0-2)\n",
    "n_post = 3      # Post-treatment periods (3-5)\n",
    "n_treated = 3   # Units 0, 1, 2 are treated\n",
    "n_control = n_units - n_treated\n",
    "\n",
    "# True treatment effect\n",
    "true_att = 3.0\n",
    "\n",
    "# Unit-specific trends (heterogeneous growth rates)\n",
    "unit_trends = np.random.uniform(0.3, 0.7, n_units)\n",
    "\n",
    "# Unit-specific intercepts\n",
    "unit_intercepts = np.random.uniform(10, 20, n_units)\n",
    "\n",
    "# Common time shocks (affects all units)\n",
    "time_shocks = np.random.normal(0, 0.3, n_periods)\n",
    "\n",
    "# Generate panel data\n",
    "data = {\"unit\": [], \"time\": [], \"outcome\": [], \"treated\": []}\n",
    "\n",
    "for unit in range(n_units):\n",
    "    for t in range(n_periods):\n",
    "        # Base outcome: intercept + trend + time shock + noise\n",
    "        outcome = (unit_intercepts[unit] \n",
    "                   + unit_trends[unit] * t \n",
    "                   + time_shocks[t]\n",
    "                   + np.random.normal(0, 0.5))\n",
    "        \n",
    "        # Add treatment effect for treated units in post-period\n",
    "        is_treated = (unit < n_treated) and (t >= n_pre)\n",
    "        if is_treated:\n",
    "            outcome += true_att\n",
    "        \n",
    "        data[\"unit\"].append(unit)\n",
    "        data[\"time\"].append(t)\n",
    "        data[\"outcome\"].append(outcome)\n",
    "        data[\"treated\"].append(1 if is_treated else 0)\n",
    "\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# Summary stats\n",
    "print(f\"Panel dimensions: {n_units} units × {n_periods} periods = {len(df)} obs\")\n",
    "print(f\"Treated units: {n_treated}, Control units: {n_control}\")\n",
    "print(f\"Pre-treatment periods: {n_pre}, Post-treatment periods: {n_post}\")\n",
    "print()\n",
    "\n",
    "# Run Synthetic DID\n",
    "result = causers.synthetic_did(\n",
    "    df,\n",
    "    unit_col=\"unit\",\n",
    "    time_col=\"time\",\n",
    "    outcome_col=\"outcome\",\n",
    "    treatment_col=\"treated\",\n",
    "    bootstrap_iterations=200,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 50)\n",
    "print(\"SYNTHETIC DID RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Control units: {result.n_units_control}\")\n",
    "print(f\"Treated units: {result.n_units_treated}\")\n",
    "print(f\"Pre-treatment periods: {result.n_periods_pre}\")\n",
    "print(f\"Post-treatment periods: {result.n_periods_post}\")\n",
    "print()\n",
    "print(f\"ATT: {result.att:.4f} ± {result.standard_error:.4f}  (true: {true_att})\")\n",
    "print(f\"Pre-treatment fit (RMSE): {result.pre_treatment_fit:.4f}\")\n",
    "print(f\"Bootstrap iterations used: {result.bootstrap_iterations_used}\")\n",
    "print()\n",
    "print(f\"Solver converged: {result.solver_converged}\")\n",
    "print(f\"Solver iterations: {result.solver_iterations}\")\n",
    "\n",
    "# Show weight distributions\n",
    "print()\n",
    "print(f\"Unit weights (control): min={min(result.unit_weights):.4f}, max={max(result.unit_weights):.4f}\")\n",
    "print(f\"Time weights (pre-period): min={min(result.time_weights):.4f}, max={max(result.time_weights):.4f}\")\n",
    "\n",
    "# Verify constraints\n",
    "assert result.standard_error > 0, \"SE should be > 0\"\n",
    "assert result.pre_treatment_fit > 0, \"Pre-treatment RMSE should be > 0\"\n",
    "assert result.n_units_control >= 3, \"Should have at least 3 control units\"\n",
    "assert result.n_periods_pre >= 3, \"Should have at least 3 pre-treatment periods\"\n",
    "assert result.bootstrap_iterations_used >= 100, \"Should use at least 100 bootstrap iterations\"\n",
    "print(\"\\n✅ All validation checks passed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
