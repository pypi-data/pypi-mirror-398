benchmark:
  name: "IOR Benchmark"
  description: "A benchmark to measure I/O performance using the IOR tool."
  workdir: "/home/luan/workdir/"
  sqlite_db: "/home/luan/iops.db"
  repetitions: 2 # global repetitions for each test case. It is ignored when rounds has its own value
  search_method: "exhaustive" # used to define the policy for test execution selection
  executor : "local" # specify the executor to use : local | slurm
  random_seed: 43  # seed for any random operations in the benchmark
  cache_exclude_vars: ["summary_file"]  # Exclude path-based derived vars
  # Budget configuration (optional)
  max_core_hours: 100.0  # Maximum CPU core-hours budget (can be overridden by --max-core-hours CLI argument)
  cores_expr: "{{ processes_per_node }}"  # Jinja expression to compute cores (defaults to 1 if not specified)



vars:
  # Swept variables (global definition) 
  processes_per_node:
    type: int
    sweep:
      mode: list
      values: [1, 4, 8]

  volume_size_gb:
    type: int
    sweep:
      mode: list
      values: [1, 4, 16]

  block_size_mb:
    type: int
    expr: "(volume_size_gb * 1024) / (processes_per_node) "

    
  summary_file:
    type: str
    expr: "{{ execution_dir }}/summary_{{ execution_id }}_{{ repetition }}.json"  
    
command:
  template: >    
    ior -w -b {{ block_size_mb }}mb -t 1mb
    -O summaryFile={{summary_file}} -O summaryFormat=JSON
    -o /home/luan/filesystem/output.ior 

  metadata:
    operation: "write"
    io_engine: "MPI-IO"
    access_pattern: "contiguous"

scripts:
  - name: "ior" 
    submit: "bash"
    script_template: |
      #!/bin/bash     
      
      set -euo pipefail # exit on error, undefined var, or failed pipe

      mpirun --oversubscribe  -np {{processes_per_node}} {{ command.template }}      
     
      echo "repetition {{ repetition }} completed."

    post:
      script: |
        #!/bin/bash
        echo "Job completed. Summary file located at {{ summary_file }}"

    parser:
      file: "{{ summary_file }}"
      metrics:
        - name: bwMiB
        - name: iops
        - name: latency
        - name: totalTime
      parser_script: ../scripts/ior_parser.py

        

output:
  sink:
    type: csv          # parquet | csv | sqlite
    path: "{{ workdir }}/results.csv"
    mode: append           # append | overwrite
    include: []            # optional, mutually exclusive with exclude
    exclude: ["benchmark.name", "benchmark.description"]            # optional, mutually exclusive with include
    table: results         # only for sqlite


# Multi-round optimization workflow
rounds:

  # Round 1: With best nodes, optimize processes per node
  - name: "optimize_processes"
    description: "Find best process count using optimal nodes from round 1"
    sweep_vars: ["processes_per_node"]
    search:
      metric: "bwMiB"
      objective: "max"

  # Round 3: Optimize volume size with best nodes and processes
  - name: "optimize_volume"
    description: "Find optimal data volume size"
    sweep_vars: ["volume_size_gb"]
    search:
      metric: "bwMiB"
      objective: "max"
