# SimpleVecDB Configuration

# Embedding Model
# Options: Any HuggingFace model ID compatible with SentenceTransformers

# Default: Snowflake/snowflake-arctic-embed-xs (384-dim, best balance, fast)
# Alternative: TaylorAI/bge-micro-v2 (384-dim, tiny, fast)

# Note: All models converted to ONNX format for performance.

EMBEDDING_MODEL=Snowflake/snowflake-arctic-embed-xs
EMBEDDING_CACHE_DIR=~/.cache/simplevecdb  # Model cache directory
# Optional: alias registry for allowed models (alias=repo_id,comma-separated)
# EMBEDDING_MODEL_REGISTRY=default=Snowflake/snowflake-arctic-embed-xs,local-bge=TaylorAI/bge-micro-v2
# Set to 0 to allow arbitrary repo IDs (default is locked)
# EMBEDDING_MODEL_REGISTRY_LOCKED=1

# Batch size for embedding inference (optional - auto-detected if not set)
# Auto-detection considers: GPU VRAM, Apple Silicon, CPU cores, architecture
# Override only if you need specific batch size for your use case
# EMBEDDING_BATCH_SIZE=256

# Embedding server controls
# EMBEDDING_SERVER_MAX_REQUEST_ITEMS=128  # Max prompts per /v1/embeddings call
# EMBEDDING_SERVER_API_KEYS=local-dev-token

# Database
DATABASE_PATH=./data/simplevecdb.db

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=53287
