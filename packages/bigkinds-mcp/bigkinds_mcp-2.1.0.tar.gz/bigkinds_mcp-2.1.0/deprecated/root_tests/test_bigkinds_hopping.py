"""BigKinds ê¸°ì‚¬ URL hopping í…ŒìŠ¤íŠ¸ - ì‹¤ì œ ê¸°ì‚¬ ë‚´ìš©/ì‚¬ì§„/ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸."""

import json

import requests
from bs4 import BeautifulSoup

from data_scrapers.bigkinds import BigKindsClient, SearchRequest


def test_raw_response():
    """API ì›ë³¸ ì‘ë‹µ ë°ì´í„° í™•ì¸."""
    print("\n" + "=" * 70)
    print("ğŸ” BigKinds API ì›ë³¸ ì‘ë‹µ ë°ì´í„° í™•ì¸")
    print("=" * 70)

    with BigKindsClient() as client:
        request = SearchRequest(
            keyword="AI",
            start_date="2024-12-01",
            end_date="2024-12-10",
            result_number=3,
        )

        response = client.search(request)

        if response.success and response.articles:
            print(f"\nâœ… {len(response.articles)}ê±´ ìˆ˜ì§‘ë¨\n")

            for i, article in enumerate(response.articles, 1):
                raw = article.raw_data or {}

                print(f"\n{'â”€' * 60}")
                print(f"ğŸ“° ê¸°ì‚¬ #{i}")
                print(f"{'â”€' * 60}")

                # í•µì‹¬ í•„ë“œ
                print(f"  ì œëª©: {raw.get('TITLE')}")
                print(f"  ë‚ ì§œ: {raw.get('DATE')}")
                print(f"  ì–¸ë¡ ì‚¬: {raw.get('PROVIDER')}")
                print(f"  ê¸°ì: {raw.get('BYLINE')}")
                print(f"  ì¹´í…Œê³ ë¦¬: {raw.get('PROVIDER_SUBJECT')}")

                # URL ê´€ë ¨
                print(f"  ğŸ”— ì›ë³¸ ê¸°ì‚¬ URL: {raw.get('PROVIDER_LINK_PAGE')}")
                print(f"  ğŸ–¼ï¸ BigKinds ì´ë¯¸ì§€: {raw.get('IMAGES')}")

                # ë³¸ë¬¸
                content = raw.get('CONTENT', '')
                if content:
                    print(f"  ğŸ“„ ë³¸ë¬¸ ({len(content)}ì): {content[:150]}...")

            return response.articles
        else:
            print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {response.error_message}")
            return []


def test_provider_link_hopping(articles):
    """PROVIDER_LINK_PAGEë¡œ ì‹¤ì œ ê¸°ì‚¬ í˜ì´ì§€ ì ‘ê·¼ í…ŒìŠ¤íŠ¸."""
    print("\n" + "=" * 70)
    print("ğŸŒ ì›ë³¸ ê¸°ì‚¬ URL (PROVIDER_LINK_PAGE) ì ‘ê·¼ í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }

    for i, article in enumerate(articles[:3], 1):
        raw = article.raw_data or {}
        url = raw.get('PROVIDER_LINK_PAGE')
        title = raw.get('TITLE', '')[:40]

        print(f"\n{'â”€' * 60}")
        print(f"ğŸ“° ê¸°ì‚¬ #{i}: {title}...")
        print(f"   ì–¸ë¡ ì‚¬: {raw.get('PROVIDER')}")
        print(f"   URL: {url}")
        print("â”€" * 60)

        if not url:
            print("   âš ï¸ URL ì—†ìŒ")
            continue

        try:
            resp = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
            print(f"   HTTP ìƒíƒœ: {resp.status_code}")
            print(f"   ìµœì¢… URL: {resp.url[:80]}...")

            if resp.status_code == 200:
                soup = BeautifulSoup(resp.text, 'html.parser')

                # ì œëª© ì¶”ì¶œ
                title_elem = soup.select_one('h1, .article-title, .news-title, #articleTitle, .view_title')
                if title_elem:
                    print(f"   ğŸ“ ì¶”ì¶œëœ ì œëª©: {title_elem.get_text(strip=True)[:60]}...")

                # ë³¸ë¬¸ ì¶”ì¶œ
                content_selectors = [
                    'article', '.article-body', '.news-content', '#articleBody',
                    '.view_content', '.article_body', '#articeBody', '.news_body'
                ]
                for selector in content_selectors:
                    content_elem = soup.select_one(selector)
                    if content_elem:
                        text = content_elem.get_text(strip=True)
                        print(f"   ğŸ“„ ë³¸ë¬¸ ({len(text)}ì): {text[:150]}...")
                        break

                # ì´ë¯¸ì§€ ì¶”ì¶œ
                images = soup.select('article img, .article-body img, .view_content img')
                if not images:
                    images = soup.select('img[src*="news"], img[src*="image"]')[:5]
                print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€ ìˆ˜: {len(images)}")
                for img in images[:3]:
                    src = img.get('src') or img.get('data-src')
                    if src and not src.startswith('data:'):
                        print(f"      - {src[:70]}...")

                # ë©”íƒ€ë°ì´í„°
                og_image = soup.select_one('meta[property="og:image"]')
                og_desc = soup.select_one('meta[property="og:description"]')
                if og_image:
                    print(f"   ğŸ“· OG Image: {og_image.get('content', '')[:70]}...")
                if og_desc:
                    print(f"   ğŸ“ OG Desc: {og_desc.get('content', '')[:100]}...")

                print("   âœ… ì ‘ê·¼ ì„±ê³µ")
            else:
                print(f"   âŒ HTTP {resp.status_code}")

        except Exception as e:
            print(f"   âŒ ì ‘ê·¼ ì‹¤íŒ¨: {e}")


def test_bigkinds_image():
    """BigKinds ì„œë²„ ì´ë¯¸ì§€ ì ‘ê·¼ í…ŒìŠ¤íŠ¸."""
    print("\n" + "=" * 70)
    print("ğŸ–¼ï¸ BigKinds ì´ë¯¸ì§€ URL ì ‘ê·¼ í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    with BigKindsClient() as client:
        request = SearchRequest(
            keyword="AI",
            start_date="2024-12-01",
            end_date="2024-12-10",
            result_number=5,
        )

        response = client.search(request)

        if response.success and response.articles:
            for i, article in enumerate(response.articles, 1):
                raw = article.raw_data or {}
                image_url = raw.get('IMAGES')
                title = raw.get('TITLE', '')[:40]

                print(f"\nğŸ“° #{i}: {title}...")
                print(f"   ì´ë¯¸ì§€ URL: {image_url}")

                if not image_url:
                    print("   âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ")
                    continue

                try:
                    resp = requests.head(image_url, timeout=10)
                    print(f"   ìƒíƒœ: {resp.status_code}")
                    print(f"   Content-Type: {resp.headers.get('Content-Type', 'N/A')}")
                    print(f"   Content-Length: {resp.headers.get('Content-Length', 'N/A')} bytes")

                    if resp.status_code == 200:
                        print("   âœ… ì´ë¯¸ì§€ ì ‘ê·¼ ê°€ëŠ¥")
                    else:
                        print(f"   âš ï¸ ì ‘ê·¼ ë¶ˆê°€ ({resp.status_code})")

                except Exception as e:
                    print(f"   âŒ ì‹¤íŒ¨: {e}")


def summary():
    """ê²°ê³¼ ìš”ì•½."""
    print("\n" + "=" * 70)
    print("ğŸ“Š BigKinds Hopping ê°€ëŠ¥ì„± ìš”ì•½")
    print("=" * 70)
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ í•„ë“œ                  â”‚ ê°€ìš©ì„±  â”‚ ì„¤ëª…                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CONTENT              â”‚ âœ… ìˆìŒ â”‚ APIì—ì„œ ì§ì ‘ ë³¸ë¬¸ ì œê³µ          â”‚
â”‚ PROVIDER_LINK_PAGE   â”‚ âœ… ìˆìŒ â”‚ ì›ë³¸ ì–¸ë¡ ì‚¬ ê¸°ì‚¬ URL           â”‚
â”‚ IMAGES               â”‚ âœ… ìˆìŒ â”‚ BigKinds ì„œë²„ ì´ë¯¸ì§€ URL       â”‚
â”‚ PROVIDER             â”‚ âœ… ìˆìŒ â”‚ ì–¸ë¡ ì‚¬ ì´ë¦„                    â”‚
â”‚ BYLINE               â”‚ âœ… ìˆìŒ â”‚ ê¸°ì ì´ë¦„                      â”‚
â”‚ DATE                 â”‚ âœ… ìˆìŒ â”‚ ë°œí–‰ì¼                         â”‚
â”‚ CATEGORY             â”‚ âœ… ìˆìŒ â”‚ ì¹´í…Œê³ ë¦¬ ì½”ë“œ                  â”‚
â”‚ IMAGES_CAPTION       â”‚ âš ï¸ ì¼ë¶€ â”‚ ì´ë¯¸ì§€ ìº¡ì…˜ (ì—†ëŠ” ê²½ìš° ë§ìŒ)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ ê²°ë¡ :
1. API ìì²´ë¡œ ë³¸ë¬¸(CONTENT) ì œê³µ â†’ Hopping ë¶ˆí•„ìš”í•  ìˆ˜ ìˆìŒ
2. ì›ë³¸ ê¸°ì‚¬ URLë¡œ hopping ê°€ëŠ¥ (PROVIDER_LINK_PAGE)
3. BigKinds ì´ë¯¸ì§€ URL ì§ì ‘ ì ‘ê·¼ ê°€ëŠ¥ (IMAGES)
4. ì¶”ê°€ ë©”íƒ€ë°ì´í„°ëŠ” ì›ë³¸ ê¸°ì‚¬ì—ì„œ ìŠ¤í¬ë˜í•‘ í•„ìš”
""")


if __name__ == "__main__":
    # 1. Raw ë°ì´í„° í™•ì¸
    articles = test_raw_response()

    # 2. ì›ë³¸ ê¸°ì‚¬ URL hopping í…ŒìŠ¤íŠ¸
    if articles:
        test_provider_link_hopping(articles)

    # 3. BigKinds ì´ë¯¸ì§€ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
    test_bigkinds_image()

    # 4. ìš”ì•½
    summary()
