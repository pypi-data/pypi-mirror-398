name: Update OSS Sustain Guard Database

on:
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight UTC to spread load
  workflow_dispatch:

concurrency:
  group: update-database
  cancel-in-progress: false

# Note: contents:write permission no longer needed since we're using Cloudflare KV instead of git commits
# permissions:
#   contents: write

jobs:
  update_database:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.13'

      - name: Install uv
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: Install dependencies
        run: uv sync

      - name: Select ecosystem batch
        run: |
          day=$(date -u +%u)
          case "$day" in
            1) batch="python javascript";;
            2) batch="ruby rust";;
            3) batch="php java";;
            4) batch="csharp go";;
            5) batch="python javascript";;
            6) batch="ruby rust";;
            0) batch="php java";;
          esac
          echo "ECOSYSTEM_BATCH=$batch" >> "$GITHUB_ENV"
          echo "Selected batch: $batch"

      - name: Run database builder for selected ecosystems
        timeout-minutes: 300
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          LIBRARIESIO_API_KEY: ${{ secrets.LIBRARIESIO_API_KEY }}
          CLOUDFLARE_WORKER_URL: ${{ secrets.CLOUDFLARE_WORKER_URL }}
          CF_WRITE_SECRET: ${{ secrets.CF_WRITE_SECRET }}
        run: |
          if [ -z "$ECOSYSTEM_BATCH" ]; then
            echo "No ecosystems selected; exiting."
            exit 0
          fi

          # Run ecosystems sequentially to respect Libraries.io rate limit (60 req/min)
          # Use --limit 5000, --max-concurrent 1 for rate limit compliance
          # Results are uploaded to Cloudflare KV instead of git commits
          # GitHub Actions will force-kill this step after 5 hours (300 minutes)
          for ecosystem in $ECOSYSTEM_BATCH; do
            echo "Processing $ecosystem..."
            uv run python builder/build_db.py \
              --ecosystems $ecosystem \
              --limit 5000 \
              --max-concurrent 1 \
              --upload-to-cloudflare

            echo "Waiting before next ecosystem..."
            sleep 10
          done

          echo "âœ… Database build complete. Results uploaded to Cloudflare KV."

      # Note: With Cloudflare KV, we no longer commit data/latest/ to git
      # Data is served directly from Cloudflare KV for faster, distributed access
      # Uncomment below if you want to keep git backup of data/latest/
      #
      # - name: Commit database changes (optional backup)
      #   if: always()
      #   run: |
      #     if ! git diff --quiet HEAD -- data/latest/; then
      #       echo "Backing up database changes to git..."
      #       git config --local user.email "action@github.com"
      #       git config --local user.name "GitHub Action"
      #       git add data/latest/ || true
      #       git commit -m "chore: database backup - $(date -u +'%Y-%m-%d')" || true
      #       git push || true
      #     fi
