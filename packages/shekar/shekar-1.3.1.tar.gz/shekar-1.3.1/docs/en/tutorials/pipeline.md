# Pipeline

The `Pipeline` class in the `shekar` library enables you to chain together multiple preprocessing steps into a single, reusable transformation flow. It is particularly useful when you want to apply several text normalization, cleaning, or masking operations in sequence. The `Pipeline` is fully compatible with all preprocessors in `shekar.preprocessing`.

## Key Features

-   **Composable**: Chain multiple transformations in a defined order.
-   **Operator Chaining**: Use the | operator for a clean, functional style.
-   **Flexible Input**: Works with single strings or batches of strings.
-   **Callable**: The pipeline object itself is callable.
-   **Decorator Support**: Apply preprocessing automatically to specific function arguments.
-   **Error Handling**: Raises clear errors for invalid inputs or configuration.

## Initialization

You can create a pipeline in two ways:

1. Using the `Pipeline` class directly
   
```python
from shekar import Pipeline
from shekar.preprocessing import EmojiRemover, PunctuationRemover

steps = [
    ("removeEmoji", EmojiRemover()),
    ("removePunct", PunctuationRemover()),
]

pipeline = Pipeline(steps)
```

2. Using the `|` operator for cleaner chaining

```python
from shekar.preprocessing import AlphabetNormalizer, SpacingNormalizer, StopWordFilter

pipeline = AlphabetNormalizer() | SpacingNormalizer() | StopWordFilter()
```

Both approaches produce identical pipelines. The `|` operator is ideal for quick and readable pipeline definitions.

## Basic Usage

Apply the pipeline to a string:

```python
text = "Ù¾Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ğŸ” Ù‚ÙØ³ÛŒØŒ Ø¹Ø§Ø¯Øª Ø¯Ø§Ø±Ù† Ø¨Ù‡ Ø¨ÛŒâ€ŒÚ©Ø³ÛŒ!"
result = pipeline.fit_transform(text)
print(result)  # Output: "Ù¾Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ  Ù‚ÙØ³ÛŒ Ø¹Ø§Ø¯Øª Ø¯Ø§Ø±Ù† Ø¨Ù‡ Ø¨ÛŒâ€ŒÚ©Ø³ÛŒ"
```

## Batch Processing

You can pass a list of strings:

```python
texts = [
    "ÛŒØ§Ø¯ØªÙ‡ Ú¯Ù„ Ø±Ø² Ù‚Ø±Ù…Ø² ğŸŒ¹ Ø¨Ù‡ ØªÙˆ Ø¯Ø§Ø¯Ù…ØŸ",
    "Ø¨Ú¯Ùˆ ÛŒÙ‡ÙˆÛŒÛŒ Ø§Ø² Ú©Ø¬Ø§ Ù¾ÛŒØ¯Ø§Øª Ø´Ø¯ØŸ"
]
results = pipeline.fit_transform(texts)
print(results)
# Output: ["ÛŒØ§Ø¯ØªÙ‡ Ú¯Ù„ Ø±Ø² Ù‚Ø±Ù…Ø²  Ø¨Ù‡ ØªÙˆ Ø¯Ø§Ø¯Ù…", "Ø¨Ú¯Ùˆ ÛŒÙ‡ÙˆÛŒÛŒ Ø§Ø² Ú©Ø¬Ø§ Ù¾ÛŒØ¯Ø§Øª Ø´Ø¯"]
```

## Callable Interface

The **`Pipeline`** object is callable and equivalent to **`fit_transform()`**:

```python
output = pipeline("ØªÙˆ Ø±Ø§ Ù…Ù† Ú†Ø´Ù…ğŸ‘€ Ø¯Ø± Ø±Ø§Ù‡Ù…!")
print(output)  # Output: "ØªÙˆ Ø±Ø§ Ù…Ù† Ú†Ø´Ù… Ø¯Ø± Ø±Ø§Ù‡Ù…"
```

## Using with Decorators

Apply the pipeline automatically to specific function arguments:

```python
@pipeline.on_args("text")
def process_text(text):
    return text

print(process_text("Ø¹Ù…Ø±ÛŒ Ø¯Ú¯Ø± Ø¨Ø¨Ø§ÛŒØ¯ Ø¨Ø¹Ø¯ Ø§Ø² ÙˆÙØ§Øª Ù…Ø§ Ø±Ø§!ğŸŒ"))
# Output: "Ø¹Ù…Ø±ÛŒ Ø¯Ú¯Ø± Ø¨Ø¨Ø§ÛŒØ¯ Ø¨Ø¹Ø¯ Ø§Ø² ÙˆÙØ§Øª Ù…Ø§ Ø±Ø§"
```

Multiple arguments:

```python
@pipeline.on_args(["text", "description"])
def clean_inputs(text, description):
    return text, description

print(clean_inputs("Ù†Ø§Ø² Ø¯Ø§Ø±Ù‡ Ú†Ùˆ ÙˆØ§ÛŒ!", "Ù…Ù‡Ø±Ù‡Ù” Ù…Ø§Ø± Ø¯Ø§Ø±Ù‡ ØªÙˆ Ø¯Ù„Ø¨Ø±ÛŒâ¤ï¸"))
# Output: ("Ù†Ø§Ø² Ø¯Ø§Ø±Ù‡ Ú†Ùˆ ÙˆØ§ÛŒ", "Ù…Ù‡Ø±Ù‡Ù” Ù…Ø§Ø± Ø¯Ø§Ø±Ù‡ ØªÙˆ Ø¯Ù„Ø¨Ø±ÛŒ")
```

## Error Handling

The pipeline raises informative errors for invalid usage:

- `ValueError`: Raised if input is neither a string nor a list of strings.
- `TypeError`: Raised if `on_args` is called with invalid types.
- `ValueError`: Raised if the specified function argument does not exist.

## Notes

- Each preprocessor must implement `__call__` and `fit_transform`.
- Pipelines are compatible with **`Normalizer`**, which itself is a subclass of **`Pipeline`**.
- Ideal for building modular, testable, and reusable text processing flows.

---

The **`Pipeline`** class provides a clean and extensible architecture for combining multiple preprocessing steps, making it a powerful component for building robust NLP workflows.