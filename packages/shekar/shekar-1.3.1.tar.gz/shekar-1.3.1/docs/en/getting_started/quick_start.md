# Quick Start Guide

Welcome to **Shekar**, a Python library for Persian Natural Language Processing. This guide will walk you through the most essential components so you can get started quickly with preprocessing, tokenization, pipelines, normalization, and embeddings.

---

## 1. Normalize Your Text

The built-in `Normalizer` class provides a ready-to-use pipeline that combines the most common filters and normalization steps, offering a default configuration that covers the majority of use cases.

```python
from shekar import Normalizer

normalizer = Normalizer()
text = "Â«ÙØ§Ø±Ø³ÛŒ Ø´ÙÚ©ÙØ± Ø§Ø³ØªÂ» Ù†Ø§Ù… Ø¯Ø§Ø³ØªØ§Ù† ÚªÙˆØªØ§Ù‡ Ø·Ù†Ø²    Ø¢Ù…ÛØ²ÛŒ Ø§Ø² Ù…Ø­Ù…Ø¯ Ø¹Ù„ÛŒ Ø¬Ù…Ø§Ù„Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ø²Ø§Ø¯Ù‡  Ù…ÛŒ   Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø¯Ø± Ø³Ø§Ù„ 1921 Ù…Ù†ØªØ´Ø±  Ø´Ø¯Ù‡ Ø§Ø³Øª Ùˆ Ø¢ØºØ§Ø²   Ú±Ø± ØªØ­ÙˆÙ„ Ø¨Ø²Ø±Ú¯ÛŒ Ø¯Ø± Ø§Ø¯ÙØ¨ÛØ§Øª Ù…Ø¹Ø§ØµØ± Ø§ÛŒØ±Ø§Ù† ğŸ‡®ğŸ‡· Ø¨Ûƒ Ø´Ù…Ø§Ø± Ù…ÛŒØ±ÙˆØ¯."

print(normalizer(text))
```

```shell
Â«ÙØ§Ø±Ø³ÛŒ Ø´Ú©Ø± Ø§Ø³ØªÂ» Ù†Ø§Ù… Ø¯Ø§Ø³ØªØ§Ù† Ú©ÙˆØªØ§Ù‡ Ø·Ù†Ø²Ø¢Ù…ÛŒØ²ÛŒ Ø§Ø² Ù…Ø­Ù…Ø¯â€ŒØ¹Ù„ÛŒ Ø¬Ù…Ø§Ù„Ø²Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯ Ú©Ù‡ Ø¯Ø± Ø³Ø§Ù„ Û±Û¹Û²Û± Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡â€ŒØ§Ø³Øª Ùˆ Ø¢ØºØ§Ø²Ú¯Ø± ØªØ­ÙˆÙ„ Ø¨Ø²Ø±Ú¯ÛŒ Ø¯Ø± Ø§Ø¯Ø¨ÛŒØ§Øª Ù…Ø¹Ø§ØµØ± Ø§ÛŒØ±Ø§Ù† Ø¨Ù‡ Ø´Ù…Ø§Ø± Ù…ÛŒâ€ŒØ±ÙˆØ¯.
```

---

## 2. Use Preprocessing Components

Import and use individual text cleaners like `EmojiRemover`, `DiacriticsRemover`, or `URLMasker`.

```python
from shekar.preprocessing import EmojiRemover

text = "Ø³Ù„Ø§Ù… ğŸŒ¹ğŸ˜Š"
print(EmojiRemover()(text))  # Output: "Ø³Ù„Ø§Ù…"
```

See the full list of components in `shekar.preprocessing`.

---

## 3. Build Custom Pipelines

Create your own pipeline by chaining any number of preprocessing steps:

```python
from shekar import Pipeline
from shekar.preprocessing import EmojiRemover, PunctuationRemover

pipeline = Pipeline([
    ("emoji", EmojiRemover()),
    ("punct", PunctuationRemover())
])

text = "Ù¾Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ğŸ” Ù‚ÙØ³ÛŒØŒ Ø¹Ø§Ø¯Øª Ø¯Ø§Ø±Ù† Ø¨Ù‡ Ø¨ÛŒâ€ŒÚ©Ø³ÛŒ!"
print(pipeline(text))  # Output: "Ù¾Ø±Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ  Ù‚ÙØ³ÛŒ Ø¹Ø§Ø¯Øª Ø¯Ø§Ø±Ù† Ø¨Ù‡ Ø¨ÛŒâ€ŒÚ©Ø³ÛŒ"
```

Supports:
- Single strings or batches
- Function decorators for auto-cleaning input arguments

---

## 4. Tokenize Text into Sentences

Use `SentenceTokenizer` to split text into sentences:

```python
from shekar import SentenceTokenizer

text = "Ù‡Ø¯Ù Ù…Ø§ Ú©Ù…Ú© Ø¨Ù‡ ÛŒÚ©Ø¯ÛŒÚ¯Ø± Ø§Ø³Øª! Ù…Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø¨Ø§ Ù‡Ù… Ú©Ø§Ø± Ú©Ù†ÛŒÙ…."
sentences = SentenceTokenizer()(text)

for s in sentences:
    print(s)
```
