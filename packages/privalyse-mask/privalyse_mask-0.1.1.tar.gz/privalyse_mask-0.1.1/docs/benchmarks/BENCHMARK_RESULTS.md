# ðŸ“Š Benchmark Results (Scientific)

Run Date: December 22, 2025

## 1. Privacy Evaluation (Recall)
**Score: 80.00%** (40/200 entities missed)

### Analysis
The current detection engine (Presidio + Spacy `en_core_web_lg`) missed 20% of the synthetic PII entities.
- **Likely Causes**:
  - Synthetic names generated by `Faker` might be unusual or lack context that Spacy expects.
  - Single-sentence context ("My name is X") is sometimes hard for NER models compared to full paragraphs.
- **Action Item**:
  - Add more context to synthetic data generation.
  - Tune Presidio's confidence thresholds.
  - Add a "Dictionary Recognizer" for common names if specific domains are known.

## 2. Utility Evaluation (Simulated LLM)
**Score: 100%** (Relative to Original)

### Analysis
The masking strategy successfully preserved the *intent* of the user queries.
- **Example**:
  - Original: "I want to book a flight to Berlin." -> Intent: `book_flight`
  - Masked: "I want to book a flight to {Location_Berlin}." -> Intent: `book_flight`
- **Conclusion**: The semantic surrogates (`{Location_...}`) are working as intended, allowing downstream tasks to function correctly.

## 3. Next Steps
1. **Improve Recall**: Investigate the 20% misses. Are they Names? Cities?
2. **Expand Utility Tests**: Add more complex tasks like "Entity Extraction" (e.g. extracting the *date* from the masked text).
